{"id":"4W3i2hyrJTVfcLq85rWgduVQ3y3BMzrSD4pVUCMqPpFhmXWpqxQ","title":"Hacker News: Front Page","displayTitle":"HN Front","url":"https://hnrss.org/frontpage?points=75","feedLink":"https://news.ycombinator.com/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":15,"items":[{"title":"The 2005 Sony Bravia ad","url":"https://www.sfgate.com/sf-culture/article/san-francisco-sony-bouncy-ball-ad-20204385.php","date":1741792364,"author":"coloneltcb","guid":221,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43344129"},{"title":"Gemini Robotics brings AI into the physical world","url":"https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/","date":1741792149,"author":"meetpateltech","guid":220,"unread":true,"content":"<div><p data-block-key=\"q2c97\">Introducing Gemini Robotics, our Gemini 2.0-based model designed for robotics</p><p data-block-key=\"3djrg\">At Google DeepMind, we've been making progress in how our Gemini models solve complex problems through multimodal reasoning across text, images, audio and video. So far however, those abilities have been largely confined to the digital realm. In order for AI to be useful and helpful to people in the physical realm, they have to demonstrate “embodied” reasoning — the humanlike ability to comprehend and react to the world around us— as well as safely take action to get things done.</p><p data-block-key=\"73qu7\">Today, we are introducing two new AI models, based on Gemini 2.0, which lay the foundation for a new generation of helpful robots.</p><p data-block-key=\"4he0s\">The first is Gemini Robotics, an advanced vision-language-action (VLA) model that was built on Gemini 2.0 with the addition of physical actions as a new output modality for the purpose of directly controlling robots. The second is Gemini Robotics-ER, a Gemini model with advanced spatial understanding, enabling roboticists to run their own programs using Gemini’s embodied reasoning (ER) abilities.</p><p data-block-key=\"dtsn7\">Both of these models enable a variety of robots to perform a wider range of real-world tasks than ever before. As part of our efforts, we’re partnering with Apptronik to build the next generation of humanoid robots with Gemini 2.0. We’re also working with a selected number of trusted testers to guide the future of Gemini Robotics-ER.</p><p data-block-key=\"im3d\">We look forward to exploring our models’ capabilities and continuing to develop them on the path to real-world applications.</p></div><div><h2 data-block-key=\"2q7pg\">Gemini Robotics: Our most advanced vision-language-action model</h2><p data-block-key=\"3d8qf\">To be useful and helpful to people, AI models for robotics need three principal qualities: they have to be general, meaning they’re able to adapt to different situations; they have to be interactive, meaning they can understand and respond quickly to instructions or changes in their environment; and they have to be dexterous, meaning they can do the kinds of things people generally can do with their hands and fingers, like carefully manipulate objects.</p><p data-block-key=\"5bthq\">While our previous work demonstrated progress in these areas, Gemini Robotics represents a substantial step in performance on all three axes, getting us closer to truly general purpose robots.</p><p data-block-key=\"at04h\">Gemini Robotics leverages Gemini's world understanding to generalize to novel situations and solve a wide variety of tasks out of the box, including tasks it has never seen before in training. Gemini Robotics is also adept at dealing with new objects, diverse instructions, and new environments. In <a href=\"https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf\" rel=\"noopener\" target=\"_blank\">our tech report</a>, we show that on average, Gemini Robotics more than doubles performance on a comprehensive generalization benchmark compared to other state-of-the-art vision-language-action models.</p></div><div><p data-block-key=\"5merb\">To operate in our dynamic, physical world, robots must be able to seamlessly interact with people and their surrounding environment, and adapt to changes on the fly.</p><p data-block-key=\"lvkr\">Because it’s built on a foundation of Gemini 2.0, Gemini Robotics is intuitively interactive. It taps into Gemini’s advanced language understanding capabilities and can understand and respond to commands phrased in everyday, conversational language and in different languages.</p><p data-block-key=\"eo201\">It can understand and respond to a much broader set of natural language instructions than our previous models, adapting its behavior to your input. It also continuously monitors its surroundings, detects changes to its environment or instructions, and adjusts its actions accordingly. This kind of control, or “steerability,” can better help people collaborate with robot assistants in a range of settings, from home to the workplace.</p></div><div><p data-block-key=\"ev4ji\">The third key pillar for building a helpful robot is acting with <a href=\"https://deepmind.google/discover/blog/advances-in-robot-dexterity/\" rel=\"noopener\" target=\"_blank\">dexterity</a>. Many everyday tasks that humans perform effortlessly require surprisingly fine motor skills and are still too difficult for robots. By contrast, Gemini Robotics can tackle extremely complex, multi-step tasks that require precise manipulation such as origami folding or packing a snack into a Ziploc bag.</p></div><div><p data-block-key=\"2co1s\">Finally, because robots come in all shapes and sizes, Gemini Robotics was also designed to easily adapt to different robot types. We trained the model primarily on data from the bi-arm robotic platform, <a href=\"https://aloha-2.github.io/\" rel=\"noopener\" target=\"_blank\">ALOHA 2</a>, but we also demonstrated that it could control a bi-arm platform, based on the Franka arms used in many academic labs. Gemini Robotics can even be specialized for more complex embodiments, such as the humanoid Apollo robot developed by Apptronik, with the goal of completing real world tasks.</p></div><div><h2 data-block-key=\"2q7pg\">Enhancing Gemini’s world understanding</h2><p data-block-key=\"f1glf\">Alongside Gemini Robotics, we’re introducing an advanced vision-language model called Gemini Robotics-ER (short for ‘“embodied reasoning”). This model enhances Gemini’s understanding of the world in ways necessary for robotics, focusing especially on spatial reasoning, and allows roboticists to connect it with their existing low level controllers.</p><p data-block-key=\"6k4gb\">Gemini Robotics-ER improves Gemini 2.0’s existing abilities like pointing and 3D detection by a large margin. Combining spatial reasoning and Gemini’s coding abilities, Gemini Robotics-ER can instantiate entirely new capabilities on the fly. For example, when shown a coffee mug, the model can intuit an appropriate two-finger grasp for picking it up by the handle and a safe trajectory for approaching it.</p><p data-block-key=\"1lam2\">Gemini Robotics-ER can perform all the steps necessary to control a robot right out of the box, including perception, state estimation, spatial understanding, planning and code generation. In such an end-to-end setting the model achieves a 2x-3x success rate compared to Gemini 2.0. And where code generation is not sufficient, Gemini Robotics-ER can even tap into the power of in-context learning, following the patterns of a handful of human demonstrations to provide a solution.</p></div><div><h2 data-block-key=\"2q7pg\">Responsibly advancing AI and robotics</h2><p data-block-key=\"16hbn\">As we explore the continuing potential of AI and robotics, we’re taking a layered, <a href=\"https://sites.google.com/corp/view/safe-robots\" rel=\"noopener\" target=\"_blank\">holistic</a> approach to addressing safety in our research, from low-level motor control to high-level semantic understanding.</p><p data-block-key=\"7s8sj\">The physical safety of robots and the people around them is a longstanding, foundational concern in the science of robotics. That's why roboticists have classic safety measures such as avoiding collisions, limiting the magnitude of contact forces, and ensuring the dynamic stability of mobile robots. Gemini Robotics-ER can be interfaced with these ‘low-level’ safety-critical controllers, specific to each particular embodiment. Building on Gemini’s core safety features, we enable Gemini Robotics-ER models to understand whether or not a potential action is safe to perform in a given context, and to generate appropriate responses.</p><p data-block-key=\"3dcnu\">To advance robotics safety research across academia and industry, we are also releasing a new dataset to evaluate and improve semantic safety in embodied AI and robotics. In previous work, we showed how a <a href=\"https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/\" rel=\"noopener\" target=\"_blank\">Robot Constitution</a> inspired by Isaac Asimov’s Three Laws of Robotics could help prompt an LLM to select safer tasks for robots. We have since developed a framework to automatically generate data-driven constitutions - rules expressed directly in natural language – to steer a robot’s behavior. This framework would allow people to create, modify and apply constitutions to develop robots that are safer and more aligned with human values. Finally, the <a href=\"https://asimov-benchmark.github.io/\" rel=\"noopener\" target=\"_blank\">new ASIMOV dataset</a> will help researchers to rigorously measure the safety implications of robotic actions in real-world scenarios.</p><p data-block-key=\"ch213\">To further assess the societal implications of our work, we collaborate with experts in our Responsible Development and Innovation team and as well as our Responsibility and Safety Council, an internal review group committed to ensure we develop AI applications responsibly. We also consult with external specialists on particular challenges and opportunities presented by embodied AI in robotics applications.</p><p data-block-key=\"cis52\">In addition to our partnership with Apptronik, our Gemini Robotics-ER model is also available to trusted testers including Agile Robots, Agility Robots, Boston Dynamics, and Enchanted Tools. We look forward to exploring our models’ capabilities and continuing to develop AI for the next generation of more helpful robots.</p></div><div><p data-block-key=\"duspu\">This work was developed by the Gemini Robotics team. For a full list of authors and acknowledgements please view <a href=\"https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf\" rel=\"noopener\" target=\"_blank\">our technical report</a>.</p></div>","contentLength":8374,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43344082"},{"title":"The DuckDB Local UI","url":"https://duckdb.org/2025/03/12/duckdb-ui.html","date":1741784161,"author":"xnx","guid":219,"unread":true,"content":"<div><p><em>TL;DR: The DuckDB team and MotherDuck are excited to announce the release of a local UI for DuckDB shipped as part of the  extension.</em></p></div><p>The DuckDB CLI provides advanced features like interactive multi-line editing, auto-complete, and progress indicators.\nHowever, it can be cumbersome for working with lengthy SQL queries, and its data exploration tools are limited.\nMany of the available third party UIs are great, but selecting, installing, and configuring one is not straightforward.\nUsing DuckDB through a UI should be as simple as using the CLI.\nAnd now it is!</p><p>Starting with <a href=\"https://github.com/duckdb/duckdb/releases/tag/v1.2.1\">DuckDB v1.2.1</a>, a full-featured local web user interface is available out-of-the-box!\nYou can start it from the terminal by launching the DuckDB CLI client with the  argument:</p><p>You can also run the following SQL command from a <a href=\"https://duckdb.org/docs/stable/clients/overview.html\">DuckDB client</a> (e.g., CLI, Python, Java, etc.):</p><p>Both of these approaches install the  extension (if it isn't installed yet),\nthen open the DuckDB UI in your browser:</p><p>The DuckDB UI uses interactive notebooks to define SQL scripts and show the results of queries.\nHowever, its capabilities go far beyond this.\nLet’s go over its main features.</p><blockquote><p>The DuckDB UI runs all your queries locally: your queries and data never leave your computer.\nIf you would like to use <a href=\"https://motherduck.com/\">MotherDuck</a> through the UI, you have to <a href=\"https://duckdb.org/2025/03/12/duckdb-ui.html#motherduck-integration\">opt-in explicitly</a>.</p></blockquote><p>Your attached databases are shown on the left.\nThis list includes in-memory databases plus any files and URLs you’ve loaded.\nYou can explore tables and views by expanding databases and schemas.</p><p>Click on a table or view to show a summary below.\nThe UI shows the number of rows, the name and type of each column, and a profile of the data in each column.</p><p>Select a column to see a more detailed summary of its data.\nYou can use the  button near the top right to inspect the first 100 rows.\nYou can also find the SQL definition of the table or view here.</p><p>You can organize your work into named notebooks.\nEach cell of the notebook can execute one or more SQL statements.\nThe UI supports syntax highlighting and autocomplete to assist with writing your queries.</p><p>You can run the whole cell, or just a selection,\nthen sort, filter, or further transform the results using the provided controls.</p><p>The right panel contains the <a href=\"https://motherduck.com/blog/introducing-column-explorer/\">Column Explorer</a>, which shows a summary of your results.\nYou can dive into each column to gain insights.</p><p>If you would like to connect to <a href=\"https://motherduck.com/\">MotherDuck</a>, you can sign into MotherDuck to persist files and tables to a <a href=\"https://motherduck.com/docs/getting-started/\">cloud data warehouse</a> crafted for using DuckDB at scale and sharing data with your team.</p><p>The DuckDB UI is under active development. Expect additions and improvements!</p><p>Like the DuckDB CLI, the DuckDB UI creates some files in the  directory in your home directory.\nThe UI puts its files in a sub-directory, :</p><ul><li>Your notebooks and some other state are stored in a DuckDB database, .</li><li>When you export data to the clipboard or a file (using the controls below the results), some tiny intermediate files (e.g. ) are generated.\nYour data is cleared from these files after the export is completed, but some near-empty files remain, one per file type.</li></ul><p>Support for the UI is implemented in a <a href=\"https://duckdb.org/docs/stable/extensions/overview.html\">DuckDB extension</a>.\nThe extension embeds a localhost HTTP server, which serves the UI browser application, and also exposes an API for communication with DuckDB.\nIn this way, the UI leverages the native DuckDB instance from which it was started, enabling full access to your local memory, compute, and file system.</p><p>Results are returned in an efficient binary form closely matching DuckDB’s in-memory representation (<a href=\"https://github.com/duckdb/duckdb/blob/v1.2.1/src/include/duckdb/common/types/data_chunk.hpp\">DataChunk</a>).\n<a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events\">Server-sent events</a> enable prompt notification of updates such as attaching databases.\nThese techniques and others make for a low-latency experience that keeps you in your flow.</p><p>In this blog post, we presented the new DuckDB UI, a powerful web interface for DuckDB.</p><p>The DuckDB UI shares many of its design principles with the DuckDB database.\nIt’s simple, fast, feature-rich, and portable, and runs locally on your computer.\nThe DuckDB UI extension is also open source: visit the <a href=\"https://github.com/duckdb/duckdb-ui\"> repository</a> if you want to dive in deeper into the extension's code.</p><blockquote><p>The repository does not contain the source code for the frontend, which is currently not available as open-source.\nReleasing it as open-source is under consideration.</p></blockquote>","contentLength":4249,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43342712"},{"title":"Peer-to-peer file transfers in the browser","url":"https://github.com/kern/filepizza","date":1741781323,"author":"keepamovin","guid":218,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43342361"},{"title":"The Future Is Niri","url":"https://ersei.net/en/blog/niri","date":1741779736,"author":"mattjhall","guid":217,"unread":true,"content":"<p>The worst  I have is that I've been using <a href=\"https://en.wikipedia.org/wiki/Tiling_window_manager\">tiling window managers</a> for thirty-five percent of my life: five years with <a href=\"https://github.com/swaywm/sway\">Sway</a> and two with <a href=\"https://github.com/i3/i3\">i3</a>. As the realization of those numbers (and my age) dawns upon me, an irresistible urge wells up in my chest, threatening to overwhelm me. I try to tamp it down, but the urge is too strong—I must .</p><p>This may be worse than finding grey hairs.</p><p>I switched to Wayland before it was cool, so a lot of stuff was broken, and I got used to it being broken, much like my entire Linux-on-modern-laptop experience. I was  with Sway, since I had gotten used to the workflow over the years. After all, it was what all the  online were using, and I was too young to make good decisions. I went about my life, going through most of high school and all of college with a tiling window manager, dismissing alternatives as straying from the  set forth by anonymous forum-goers.</p><p>Sway  me (emotionally) with a click-and-drag issue where selecting text and dragging the selection (a pretty bog-standard thing people do with their computers)  somehow to keep the selection happening after you released the mouse.</p><p>My decades of muscle memory stopped working—I felt lost, adrift on a rough sea, the hot sun bearing down on me. Would I (the bug) ever be rescued (fixed)? Only time would tell, but I was getting desperate.</p><p>At first, I thought I could handle it and someone would quickly fix the bug. Days turned into weeks, and I was losing my mind. The Sway IRC was silent to my pleads for help, and I had developed a Pavlovian response to clicking on text to highlight it—a burst of panic in my chest as I dread the mouse continuing to drag after I had let go.</p><p>Naturally, instead of figuring out what library made a breaking change and spending four hours running , I decided to throw nearly a decade of muscle-memory and workflow refinements out the window. I was getting bored of Sway anyway. Let's switch to <a href=\"https://github.com/YaLTeR/niri\">Niri</a>!</p><p>For those unaware, Niri is a scrollable-tiling window manager: each workspace is an infinitely-wide strip you can scroll side-to-side on. It's easier to show their official demo video than to try to explain it with words (you don't have to watch the whole thing):</p><p>It was new, , , and most of all, really cool. I just  to try it, transporting me back to my youth distro-hopping and window-manager-hopping(?) with reckless abandon.</p><p>It seems to be a <a href=\"https://ersei.net/en/blog/its-nixin-time\">recurring theme</a>, throwing myself into a new productivity-altering technology in March when I should be doing more important things instead.</p><p>It wasn't as bad this time around! Within a few hours, I had a setup that worked fine enough. Within a week, I had Niri working better than Sway, and I was greatly enjoying the changes (read: improvements) it brought.</p><ol><li><p>Opening a window does not alter other windows: I can keep my focus and Firefox doesn't scroll to another dimension if I open a terminal in its vicinity.</p></li><li><p>Unlike Sway, Niri supports per-window screensharing, as well as \"blackout window from appearing in screen sharing\". I've been streaming my homework and it's much nicer without needing to worry about an email notification from my bank showing up in the top corner.</p></li></ol><ol start=\"4\"><li>Niri has increased my battery life by about two hours compared to Sway.</li></ol><p>I was so excited about Niri that I tried my hand at adding a feature to its IPC for something or the other, and I greatly enjoyed it! Unlike Sway/<a href=\"https://gitlab.freedesktop.org/wlroots/wlroots\">wlroots</a>, Niri/<a href=\"https://github.com/Smithay/smithay\">Smithay</a> are written in Rust and are surprisingly accessible to hack on.</p><p>I genuinely can't see myself going back to a traditional tiling window manager, Niri just brings too many improvements to my workflow.</p><h2>The Death of the Traditional Tiling Window Manager<a href=\"https://ersei.net/en/blog/niri#the-death-of-the-traditio\" data-anchor-icon=\"#\" aria-label=\"Anchor\"></a></h2><p>Traditional tiling window managers have a side effect of forcing you to be as efficient as possible with your window layout. There is an additional cognitive load incentivizing you to optimize for the wrong thing: minimizing window reflows. If you don't find yourself constantly swapping between fullscreen and non-fullscreen views and running out of workspaces, you don't have very many windows open. Don't even get me started on tabbed/stacked layouts with nested containers, the least ergonomic Band-Aid™ for the space issue I've ever seen.</p><p>After many  years of optimizing for the wrong thing with Sway, Niri blesses me with the realization that I can have the speed of a traditional tiling window manager without the space limitations.</p><p>On Sway, I often had  workspaces open. Ever since I switched to a tiling window manager, I kept running out of space and added shortcuts to workspaces 11-20. I drilled it into myself to close windows when I was done with them, often losing my flow when I come back to the projects I closed, all to save  I feel should be infinite. With Niri, I can have three large projects open, various chat apps, a YouTube video, and three classes worth of schoolwork and never use more than five workspaces. The same setup would have me spilling into workspace  on Sway, and I would quickly get confused and forget where I put my math textbook, switching between each workspace until I find the right one, often the very last one I check!</p><p>Wow, I did not realize how much repressed anger I had at traditional tiling window managers until now.</p><p>Given the variety of screen sizes and improved processing power I do not think that the traditional tiling window manager ought to be the power-user workflow of choice. It artificially limits space, forces content reflows, and does not work well with nonstandard monitor layouts.</p><p>If you are using Sway or another Wayland traditional tiling window manager, you should try Niri. Right now. My configurations are <a href=\"https://git.sr.ht/~fd/nix-configs/tree/trunk/item/home/common/wayland/niri.kdl\">published on Sourcehut</a> if you want to have a Sway-like experience with my keybindings.</p><p>Go on then, what are you waiting for?</p>","contentLength":5728,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43342178"},{"title":"First Ammonia-Fueled Ship Hits a Snag","url":"https://spectrum.ieee.org/ammonia-fuel-2671266100","date":1741778680,"author":"pseudolus","guid":216,"unread":true,"content":"<p>The , an oil platform supply shipundergoing a pioneering retrofit to run on <a href=\"https://spectrum.ieee.org/tag/ammonia\">ammonia</a> fuel, is now scheduled to begin operations in 2026—two years later than initially planned. Once completed, it will be the first vessel capable of operating full-time on ammonia, marking a major milestone in efforts to reduce <a href=\"https://spectrum.ieee.org/tag/carbon-dioxide\">carbon dioxide</a> (CO) emissions in the maritime industry.</p><p>Industry experts attribute the delay to the complex infrastructure required to handle ammonia safely. “Ammonia is toxic, explosive, and corrosive. We must use special piping, storage tanks, and trucks outfitted with materials engineered to be both leakproof and resistant to ammonia’s corrosive properties,” says <a href=\"https://spectrum.ieee.org/port-electrification\" target=\"_self\">John Prousalidis</a>, a professor of marine engineering at the <a href=\"https://www.ntua.gr/en/\" rel=\"noopener noreferrer\" target=\"_blank\">National Technical University of Athens</a>. </p><p>A spokesperson for Wärtsilä told  that the delay has not been related to performance or safety issues, but to “ the challenges of being at the forefront of maritime decarbonization.” The spokesperson explains that the project “was </p><p>Being first comes with a set of challenges that must be overcome. One of the biggest environmental concerns with ammonia-powered ships is the potential release of nitrogen oxides. “Instead of CO, which contributes to <a href=\"https://spectrum.ieee.org/tag/global-warming\">global warming</a>, we could end up with nitrogen oxides, which are lethal to breathe,” says Prousalidis. “To avoid simply swapping one pollutant for another, ammonia propulsion systems must include emissions-control technologies to prevent harmful nitrogen oxides from entering the atmosphere,” he adds.</p><p>A promising alternative to combustion engines is ammonia-powered fuel cells like the one originally slated to power the  Fuel cells generate electricity without producing nitrogen oxide emissions. By avoiding combustion entirely, these fuel cells allow ammonia’s nitrogen content to remain in its inert form, eliminating a key health risk.</p><h2>Ammonia Fuel Delays for </h2><p>Despite the challenges, experts believe ammonia could become a mainstream maritime fuel—but not overnight. “Twenty or thirty years ago, the shipping industry made a major shift to <a href=\"https://spectrum.ieee.org/tag/natural-gas\">natural gas</a>, believing it was the fuel of the future. Now, we know it wasn’t the right step,” says Prousalidis.</p><p>Looking back at past fuel transitions, he noted that each shift—from steam to oil, and then to natural gas—took around 20 years to achieve full adoption. He expects a similar timeline for the adoption of ammonia or hydrogen. “We need to be patient while persisting in our efforts and not getting discouraged by early challenges.”</p><p>That perspective aligns with what Equinor’s vice president of renewable and low-carbon technology, Henriette Undrum, told  in 2021 when she urged the public to be patient: “We are not just solving one small problem for one ship. It’s part of the bigger picture. It will be a starting point to build up the market for zero-carbon fuels.”</p><p>“Seaports are already undergoing an energy transformation,” says Prousalidis. “It would make sense for them to operate as energy hubs—producing, storing, and trading <a href=\"https://spectrum.ieee.org/tag/alternative-fuels\">alternative fuels</a> for fuel cells and other power-generation devices.” By doing so, he says, ports could turn a profit while also breaking the stalemate and contributing to global <a href=\"https://spectrum.ieee.org/tag/decarbonization\">decarbonization</a> efforts.</p><p>Although concerns about nitrogen oxide emissions remain, companies are reportedly designing post-combustion systems, analogous to the catalytic converters in automobile exhaust systems, to filter out harmful byproducts.  A technique called selective catalytic reduction converts nitrogen oxides into nitrogen and water. Ammonia slip catalysts capture unburned ammonia and break it down into the same two inert products. </p>","contentLength":3693,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43342071"},{"title":"I stopped everything and started writing C again","url":"https://www.kmx.io/blog/why-stopped-everything-and-started-writing-C-again","date":1741765115,"author":"dvrj101","guid":215,"unread":true,"content":"<p>I've been a good student for 5 years at a French computer school. I've been a good freelance developer for 20 years. I've used Ruby on Rails exclusively however never writing my own code always for clients.</p><p>One day I learned Common Lisp. It was supposed to be a short mission I thought I could learn Common Lisp in ten days and hack a quick server management protocol. I ended up writing throw-away Common Lisp code that generated C for a fully-fledged ASN.1 parser and query system for a custom Common Lisp to C SNMP server.</p><p>Years later I wrote more and more Common Lisp code and ended up writing cl-unix-cybernetics which has the most stars on Github of all my repos there, and cl-streams and cl-cffi, and finally cl-facts which is a triple store that can be used as a Common Lisp graph database. The results were astonishing : very fast, atomic transactions, nestable transactions, compatible with unwind-protect, only 3 macros to learn and you're all set. Cl-facts was presented as a lightning talk at ELS (European Lisp Symposium) in Belgium. Slides for my talk there are available here : <a href=\"https://git.kmx.io/facts-db/cl-facts/_tree/master/doc/facts.pdf\">https://git.kmx.io/facts-db/cl-facts/_tree/master/doc/facts.pdf</a>.</p><p>Writing all these Common Lisp packages took a long time and I was loosing all my clients. I did not care, Common Lisp was awesome and a tool for future generations for sure.</p><p>However I also had a lot of echoes around me of people failing where Theo de Raadt and others had said they were wrong. Virtual machines still suck a lot of CPU and bandwidth for nothing but emulation. Containers in Linux with cgroups are still full of RCE (remote command execution) and priviledge escalation. New ones are discovered each year. The first report I got on those listed 10 or more RCE + PE (remote root on the machine). Remote root can also escape VMs probably also. You do have backups right ? So it kept me centered on OpenBSD and avoided me the hell that most DevOps faced : Terraform, Ansible and such. So I saw people angry with VMs and containers and also people angry with their very programming language. Like Clojure : who can write a strategy game with thousands of units each having their own vision of the world, without having a garbage collector running like hell ? In fact my friend went away and tried to write the game and failed. Garbage collectors suck, and all my Common Lisp projects have very limited applications just because of the garbage collector. And we all know it's a commercial argument to the jVM : it has one of the best GCs around and it did cost a lot to write correctly. I guess it was not written in a one time scratch</p><p>So I thought OK I have a killer app but no-one will run it because it's in Common Lisp. The only rational solution for performance and portability reasons, unless another tool is developed for these specific purpose like C, is C. Linux is written in C, OpenBSD is written in C, GTK+ is object-oriented pure C, GNOME is written in C. Most of the Linux desktop apps are actually written in plain old C. So why try harder ? I know C.</p><p>So I started writing my  utility library, which would become a language () with an interpreter () but could also be compiled () if we did manage to get it through at some point; and data structures emerged from UTF-8 buffers and the other way around pretty fast and all was bounds-checked at memory cost but the results were awesome. Defensive programming all the way : all bugs are reduced to zero right from the start. The system has been maintained clean of wrong bugs all of the time. There are no security implications of running KC3 code. So very fast a small interpreter was born, pumping  (an enum-tagged union of all datatypes of the language) in a REPL (read eval print loop).</p><p>3 years later I just finished a 5 layered refactor and all the tests pass again and the webserver seems to not be broken again. The language was renamed from C3 to KC3 as the original name was already taken. So what do we have ?</p><p>I had already ported the graph database () to C89 and though a couple of bugs remained at the time of import pretty much all the database was written during the Covid-19 lockdown in 2020. Everything was there : add a triple, remove a triple, the recursive query system, transactions, logging and persistence. Pixel perfect implementation of my original design in Common Lisp but in plain old C89 which I remembered quite well.</p><p>Besides the graph data base I also wrote parsers and generators to get formal semantics for all algorithmic types I know of and could write in such a short amount of time : Structs, Linked lists, Maps, Hash tables, Time, Complex, Rationals, Tuples, Code blocks, Quotes, Unquotes, Copy on write, Skip lists, Sets, etc. I have macros like I explain in my other article. I'll do a follow up with some examples of macros. I was very much inspired by the awesome work of José Valim and Elixir. See Fly.io's blog if you want to read José Valim !</p><p>I have a REPL () which parses keyboard or file input and outputs all results of a KC3 evaluation to the console (standard output). It is used for most of the second phase of unit testing KC3.</p><p>I have a webserver with an MVC framework which is producing the very webpage you're reading : .</p><p>I have 700 views on a Common Lisp article which is crazy I did not think Common Lisp had so many followers.</p><p>I have a documentation website all written using  and a vamped Markdown to HTML C implementation.</p><p>Come on Discord and join the fun.</p>","contentLength":5433,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43340731"},{"title":"Azure's Weakest Link? How API Connections Spill Secrets","url":"https://binarysecurity.no/posts/2025/03/api-connections","date":1741761787,"author":"hland","guid":214,"unread":true,"content":"<p>Binary Security found the undocumented APIs for Azure API Connections. In this post we examine the inner workings of the Connections allowing us to escalate privileges and read secrets in backend resources for services ranging from Key Vaults, Storage Blobs, Defender ATP, to Enterprise Jira and SalesForce servers.\n</p><p>During a client engagement, I was checking out their Azure Resources looking for common vulnerabilities. They were utilizing a Logic App to post some messages to Slack. Usually, we can find some tokens or other sensitive information in the workflow run history of these apps, as it is common to not mark input (and output) as sensitive. I could not find anything of the sort in this case, so I moved on from the investigation. However, by chance I saw an odd response from a request automatically made from the portal when going into the API Connection resource. It was something like:</p><div><div><pre><code>\n\n\nHTTP/2 200 OK\nContent-Length: 1893\nContent-Type: application/json; charset=utf-8\n\n\n{\n    \"kind\": \"V2\",\n    \"properties\": {\n        \"displayName\": \"Slack\",\n        \"authenticatedUser\": {},\n        \"overallStatus\": \"Connected\",\n        \"statuses\":[\n            {\n                \"status\":\"Connected\"\n            }\n        ],\n        \"connectionState\": \"Enabled\",\n        \"parameterValueSet\":{\n            \"name\":\"oauth\",\n            \"values\":{}\n        },\n        \"customParameterValues\": {},\n        \"createdTime\": \"2025-01-24T11:46:25.0499291Z\",\n        \"changedTime\": \"2025-01-24T11:46:25.0499291Z\",\n        \"api\": {\n            \"name\": \"slack\",\n            \"displayName\": \"Slack\",\n            \"description\": \"Slack is a team communication tool, that brings together all of your team communications in one place, instantly searchable and available wherever you go.\",\n            \"iconUri\": \"https://conn-afd-prod-endpoint-bmc9bqahasf3grgk.b01.azurefd.net/u/v-anadhar/UpdateSlackForPlugin/1.0.1715.3917/slack/icon.png\",\n            \"brandColor\": \"#78D4B6\",\n            \"category\": \"Standard\",\n            \"id\": \"/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/providers/Microsoft.Web/locations/norwayeast/managedApis/slack\",\n            \"type\": \"Microsoft.Web/locations/managedApis\"\n        },\n        \"testLinks\": [\n            {\n                \"requestUri\": \"https://management.azure.com:443/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/resourceGroups/Logic-app-tests/providers/Microsoft.Web/connections/slack/extensions/proxy/conversations.list?api-version=2018-07-01-preview\",\n                \"method\": \"get\"\n            }\n        ],\n        \"testRequests\": [\n            {\n                \"body\": {\n                    \"request\": {\n                        \"method\": \"get\",\n                        \"path\": \"conversations.list\"\n                    }\n                },\n                \"requestUri\": \"https://management.azure.com:443/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/resourceGroups/Logic-app-tests/providers/Microsoft.Web/connections/slack/dynamicInvoke?api-version=2018-07-01-preview\",\n                \"method\": \"POST\"\n            }\n        ],\n        \"connectionRuntimeUrl\": \"https://d84b73b612cf5960.16.common.logic-norwayeast.azure-apihub.net/apim/slack/4355f64966c34c0cbfc15d48ec41e0c3\"\n    },\n    \"id\": \"/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/resourceGroups/Logic-app-tests/providers/Microsoft.Web/connections/slack\",\n    \"name\": \"slack\",\n    \"type\": \"Microsoft.Web/connections\",\n    \"location\": \"norwayeast\"\n}\n\n</code></pre></div></div><p>Now, this might seem uninteresting at first glance, but there are two key fields in this response that really opened up a whole slew of possibilities.</p><h2>The Inherent Insecurity of API Connections</h2><p>Consider the  and  fields of the above response. It seems that they provide a sort of proxy between the Azure Management API and the actual backend server, most clearly seen by the  path. We can also see that the connection perhaps is authenticated in some way, by the  value in the . Now, naively, I would think that this means that some user, probably whoever set this up, is authenticated to this connection, and we would need his token to call through the connection, or maybe do an  dance ourselves.</p><p>What I would  expect is that anyone with Reader permissions on the connection is allowed to arbitrarily call any endpoint on the connection:</p><div><div><pre><code>\n\n\nHTTP/2 200 OK\nContent-Type: application/json\nContent-Length: 18329\n\n\"ok\": true,\n\"channels\": [\n    {\n        \"id\": \"C08B8RB5D39\",\n        \"name\": \"social\",\n        \"is_channel\": true,\n        \"is_group\": false,\n        \"is_im\": false,\n        \"is_mpim\": false,\n        \"is_private\": false,\n        \"created\": 1738674777,\n        \"is_archived\": false,\n        \"is_general\": false,\n        \"unlinked\": 0,\n        \"name_normalized\": \"social\",\n        \"is_shared\": false,\n        \"is_org_shared\": false,\n        \"is_pending_ext_shared\": false,\n        \"pending_shared\": [],\n        \"context_team_id\": \"T08BPBEC890\",\n        \"updated\": 1738674779593,\n        \"parent_conversation\": null,\n        \"creator\": \"U08C22K3HPT\",\n        \"is_ext_shared\": false,\n        \"shared_team_ids\": [\n            \"T08BPBEC890\"\n        ],\n        \"pending_connected_team_ids\": [],\n        \"is_member\": true,\n&lt;...&gt;\n\n</code></pre></div></div><p>The response is actually exactly the same as a direct query on the Slack API endpoint <a href=\"https://api.slack.com/methods/conversations.list\">conversations.list</a></p><p>While the Slack case is perhaps not the most security critical, this result begs the question: Does this work for all the other types of APIs exposed through this interface?</p><p>The answer is yes. If you have created an API Connection to any backend server, this includes other Azure resources, all Readers on that subscription can call all  requests defined on the connection. Specifically, this includes Key Vaults, SQL Databases, Jira-servers, Defender ATP, etc.</p><h2>Azure Management (ARM) API’s Security Model</h2><p>Before I show how to exploit this properly, some background on the Azure Management API is required. While we cannot know for sure how the developers at Microsoft designed the system, it seems clear to me that initially, the security model of the management API considered that Readers should be allowed to perform  requests. You would have to be  or higher to perform any changes, i.e. using any of the , , , etc methods.</p><p>This can be seen by for instance requiring a number of sensitive endpoints for  to be empty  requests, like <a href=\"https://learn.microsoft.com/en-us/rest/api/appservice/web-apps/list-host-keys\">List Host Keys</a>.</p><p>At Binary Security we have reported a number of vulnerabilities relating to the leaking of sensitive information through insecure  endpoints. The result of this is that the security model has been somewhat changed in recent times, and it is now not obvious if a Reader is allowed to call a  endpoint. This is, however, still a viable attack method, and reading the documentation is still a goldmine for exploitable bugs.</p><p>Getting back to the API Connections, it should be clear that the Management’s <code>/extensions/proxy/{action}</code> endpoints will allow all Readers to call the defined  requests. And while this is not seen as a problem in the ARM world, there is of course no guarantee that the connected API adheres to this security model.</p><h2>Creating an API Connection</h2><p>API Connections are resources in the Azure world, just like Key Vaults, SQL Databases or VMs, but they are not required to be explicitly created. They are automatically created for you when setting up Actions in a Logic App, so even if you have never heard of them before, it is quite possible that there are a lot of them hanging out in your tenant. For instance, creating a connection to your Key Vault is as easy as going to the Logic App Designer view, finding the Key Vaults actions, setting some initial values and authenticating.\n<img src=\"https://binarysecurity.no/assets/images/posts/createkeyvault-connection.png\" alt=\"Sign in to create the connection\"></p><p>This of course requires that the person setting it up, and authenticating to the Key Vault has appropriate access to the Key Vault. After signing in, it is not required to even save the Workflow, the resource is still created, and will need to be explicitly deleted if it is not needed any more.</p><p>The flows for internal Azure Resources are all similar, where you can choose between different authentication types. For external resources, the setup varies, but in all cases, some authentication information is saved within the API Connection in some way, and this is used when querying the API.</p><p>This means that the authentication used on the backend API call is always the same, and does not depend on the user or principal calling the ARM API. Crucially, the backend cannot know whether the call comes from the Logic App or from the proxy endpoint, called by any Reader on the resource.</p><p>The full list of API Connections (Connectors) can be seen <a href=\"https://learn.microsoft.com/en-us/connectors/connector-reference/\">here</a>. The proxy endpoints are not explicitly listed, but they can either be deduced from the API of the connected service, or by querying the  endpoint for that specific Connector, which exposes a Swagger definition of the API. Here we query it for the definition of the Jira Connector:</p><div><div><pre><code>\n\nHTTP/2 200 OK\n&lt;...&gt;\n\n{\n    \"/{connectionId}/3/issue/{issueIdOrKey}\": {\n        \"put\": {\n            \"description\": \"Edits an issue. A transition may be applied and issue properties updated as part of the edit. The edits to the issue's fields are defined using update and fields.\",\n            \"summary\": \"Edit Issue\",\n            \"tags\": [\n                \"Issues\"\n            ],\n            \"operationId\": \"EditIssue\",\n            \"deprecated\": false,\n            \"produces\": [\n                \"application/json\"\n            ],\n            \"consumes\": [\n                \"application/json\"\n            ],\n            \"parameters\": [\n                {\n                    \"name\": \"connectionId\",\n                    \"in\": \"path\",\n                    \"required\": true,\n                    \"type\": \"string\",\n                    \"x-ms-visibility\": \"internal\"\n                },\n                {\n                    \"name\": \"issueIdOrKey\",\n                    \"in\": \"path\",\n                    \"required\": true,\n                    \"type\": \"string\",\n                    \"x-ms-summary\": \"Issue ID or Key\",\n                    \"description\": \"Provide the Issue ID or Key for the issue you wish to edit\",\n                    \"x-ms-url-encoding\": \"single\"\n                },\n&lt;...&gt;\n\n</code></pre></div></div><p>The  in this case is the full path to the  endpoint, something like <code>/subscription/[SUBSCRIPTION_ID]/resourceGroups/[RESOURCE_GROUP]/providers/Microsoft.Web/connections/[CONNECTION_NAME]/extensions/proxy/</code>.</p><p>Armed with this knowledge, we can go searching for sensitive endpoints.</p><p>The Connector for Key Vaults is maybe the one with the highest impact. The Swagger definition includes these sensitive  endpoints</p><ul><li> for listing secrets</li><li><code>/{connectionId}/secrets/{secretName}/value</code> to retrieve the value of the secret</li></ul><p>The SQL Connector is quite similar to the Key Vault, you are basically free to read whatever you want:</p><ul><li><p><code>/{connectionId}/databases</code> -  List Databases</p></li><li><p> - List Datasets</p></li><li><p><code>/{connectionId}/datasets({dataset})/tables({table})/items</code> - Get rows from a table</p></li></ul><p>There is also a hilarious error message here, when trying to do some path traversing in the dataset name. It did not seem to be exploitable in any way, but I bet you have never seen a stacktrace exposed in an HTTP status message:</p><p>The Jira Connector also exposes effectively everything on your Jira instance:</p><ul><li><p><code>/{connectionId}/v2/project/search</code> - List projects</p></li><li><p><code>/{connectionId}/user/permission/search</code> - List users</p></li><li><p> - List issues</p></li><li><p><code>/{connectionId}/issue/{issueKey}</code> - Read an issue</p></li></ul><p>This connector is also interesting because it, of course, must be connected to your Jira instance somewhere else on the Internet. When setting up the connection, the developer gives the connection the URL of the Jira Instance. Incredibly, this is ignored in all subsequent requests, and instead, a special  header must be included in the request. This should point to your Jira instance, but there is no verification, so an attacker is free to SSRF at will. By setting this to an attacker-controlled server, the attacker will receive the API token used by the connection. This effectively also bypasses the restriction on the requests, and allows the attacker to query any endpoint with any method.</p><p>Note that this attack is only possible when using the  authentication mechanism. When using , a GUID is used to identify your Jira Instance.</p><p>All API Connections must be considered insecure as long as Readers can call the backend server. In nearly all cases I have seen, the connection exposes all information on the backend service. In addition to the ones above, this includes:</p><ul><li>Google Mail, Contacts, Calendars</li></ul><p>I think there is significant undiscovered potential in these connections. Without going into detail, I can tell you that API Connections have a significant amount of architecture hidden between the Management Server and the backend API. All calls go from ARM to a  APIM instance containing every tenant’s API Connection, utilizing a <a href=\"https://github.com/Azure/azure-tokens\">Token Store</a>. The initial authentication setup likewise goes through a  Consent server for storing tokens. If this hidden infrastructure is compromised, there will be significant cross-tenant impact as well.</p><p>Hopefully by now, you have realized the impact of a lacking security model. While these endpoints are undocumented, that only makes them harder to find, not exploit. I am confident that any security researcher who had found them would immediately have noticed the glaring security hole it puts in their tenant. Hopefully, this post will allow others to discover more insecurities in Azure, so that we can be more secure in the future.</p><ul><li>Jan 6: Report submitted to Microsoft, both a general for API Connections and one specifically for Jira.</li><li>Jan 7: API Connection case is closed by Microsoft as not valid, I submit it again with more words.</li><li>Jan 10: Microsoft confirms the API Connection vulnerability</li><li>Jan 12-17: Microsoft fixes the API Connection vulnerability by not allowing any requests through  except for .</li><li>Jan 30: Microsoft replies on the Jira ticket, saying they cannot reproduce it, which should be obvious, since now it is fixed.</li><li>Feb 12: Jira Ticket is closed</li><li>Feb 13: Microsoft replies to the API Connection case, saying it has been fixed.</li><li>Feb 20: The case is closed as a duplicate.</li></ul>","contentLength":14090,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43340505"},{"title":"Gemma 3 Technical Report [pdf]","url":"https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf","date":1741761557,"author":"meetpateltech","guid":213,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43340491"},{"title":"The Insecurity of Telecom Stacks in the Wake of Salt Typhoon","url":"https://soatok.blog/2025/03/12/on-the-insecurity-of-telecom-stacks-in-the-wake-of-salt-typhoon/","date":1741756893,"author":"zdw","guid":212,"unread":true,"content":"<p>This isn’t really a blog post about that incident, but it was the catalyst that inspired a bit of curiosity within me.</p><p>I can’t (legally) access most mobile phone companies’ networks to see what vulnerabilities I can find, but there are plenty of open source software projects related to telecommunications on GitHub. So when I heard about the Salt Typhoon hacks, I wondered, “Is any of this open source telecom software any good?”</p><p>In a previous life, I worked with companies that used <a href=\"https://github.com/asterisk/asterisk\" target=\"_blank\" rel=\"noreferrer noopener\">Asterisk</a> and <a href=\"https://github.com/signalwire/freeswitch\" target=\"_blank\" rel=\"noreferrer noopener\">FreeSWITCH</a>, but I’d never really looked into them beyond the surface-level familiarity congruent to “this uses a similar protocol as RedPhone, somewhere” (this was when <a href=\"https://soatok.blog/2025/02/18/reviewing-the-cryptography-used-by-signal/\" target=\"_blank\" rel=\"noreferrer noopener\">Signal</a> was still called TextSecure).</p><p>I don’t know much about PBX systems, SIP, or even audio encoding. Furthermore, some of the best C programmers I’ve ever met worked in telecom. Hell, some of the longest-running hacker communities have their roots in phone phreaking from the 1980s. Not to mention all the legendary engineers that trace their roots to Bell Labs.</p><p>This is all to say, I thought looking at this sort of software would be a fruitless endeavor. </p><p><em>Surely all of the low-hanging fruit would be found already?</em></p><p>Thus, I opened FreeSWITCH’s source code on GitHub and almost immediately found a vulnerability.</p><h2>Buffer Overflow in HTTP Request Handler for XMLRPC</h2><p>In <a href=\"https://github.com/signalwire/freeswitch/blob/75566bc270f7b4064eb9ff3aed68e2f752fc17ee/libs/xmlrpc-c/lib/abyss/src/handler.c#L243-L250\">this excerpt of code</a>, the HTTP request handler for the XMLRPC library bundled with FreeSWITCH writes an arbitrary-length URI to a 4096-byte stack variable called z.</p><div><pre title=\"\">char z[4096];\nchar *p,z1[26],z2[20],z3[9],u;\nconst char * z4;\nint16_t i;\nuint32_t k;\n\nif (text) {\n    sprintf(z, \"Index of %s\" CRLF, uri);\n</pre></div><p>I think it’s reasonable to assume that attackers are capable of sending a Request URI longer than 4096 characters.</p><p>Putting these observations together, it’s pretty easy to see this is a no-auth buffer overflow in their XMLRPC library. </p><blockquote><p>Turning this into remote code execution is an exercise left to the reader (mostly because I’m not really up-to-date on OS-level exploit mitigation techniques, and how to bypass them).</p></blockquote><p>This is kind of “defensive C programming practices 101” level.</p><h2>Soatok Attempts Coordinated Disclosure</h2><p>(n.b., <a href=\"https://soatok.blog/2025/01/21/too-many-people-dont-value-the-time-of-security-researchers/#:~:text=Responsible%20Disclosure%2C%20Isn%E2%80%99t\" target=\"_blank\" rel=\"noreferrer noopener\">Please stop saying “responsible” disclosure</a>.)</p><p>: I send a follow-up email to ensure they received my report.</p><p>: Andrey Volk responds:</p><p>Since the fixes are now public, I’m left to assume that “embargo has broken,” so to speak. That means I’m free to blog about this publicly.</p><p>However, I notice they haven’t tagged a new release with this security fix for FreeSWITCH users. I reply:</p><blockquote><p>Oh, wonderful. Thanks for getting back to me.</p><p>Do you have an ETA on when the release will be tagged? I don’t want to publish anything until people can easily install an updated version.</p></blockquote><p>A few hours later, Andrey responds to my email.</p><p>Brace yourselves, it’s a stupid one.</p><blockquote><p>Thank you for your interest in FreeSWITCH.</p><p>We do not have plans to make a release&nbsp;of FreeSWITCH Community till summer 2025.</p></blockquote><p>To recap: An employee of SignalWire (which develops FreeSWITCH) came right out and said they would let people who aren’t <a href=\"https://web.archive.org/web/20250226171744/https://signalwire.com/products/freeswitch-enterprise\">paying for FreeSWITCH Advantage</a> stay vulnerable until their regularly scheduled release (sometime in the Summer).</p><p>There are <a href=\"https://web.archive.org/web/20250312042655/https://www.shodan.io/search?query=freeswitch\" target=\"_blank\" rel=\"noreferrer noopener\">about 8,300 hits on Shodan for FreeSWITCH</a> as I write this. I highly doubt they’re all paying for enterprise support, so we’re talking about potentially thousands of telecom stacks around the world that SignalWire has decided to keep vulnerable until the Summer, even after they published the patches on GitHub.</p><p>While such a decision might be perfectly legal, it really does not inspire trust in the stewards of this software project to give a shit about the harm their careless coding practices inflict upon their users.</p><h2>TelecomSec: A Systemic Issue</h2><p>The worst part is, when I confided in a friend that works in telecom (after SignalWire published the fixes, of course) about this carnival-quality vulnerability management from the FreeSWITCH developers, their response was:</p><blockquote><p>December 2024 is the last time that alarms were once again raised about known SS7 vulnerabilities that have continued to exist in telephone networks for the past 17 years.</p></blockquote><p>And, to be honest, that <em>kind of took the wind out of my sails</em> so I didn’t bother looking at Asterisk or any of the other software.</p><p>I mean, why bother? I already had the answer to the question that prompted me to look in the first place: <strong>Telecom security sucks today</strong>.</p><p>The reason things sucks is largely because there’s very little (if any) money to be made in securing these systems today.</p><p>Things don’t  be this way, of course.</p><p>Maybe there’s some opportunity for some enterprising young hacker to write a FreeSWITCH competitor in Rust that has sane vulnerability management around it.</p><p>Maybe in the future, we’ll find the political will to invest in the security of America’s telecommunications infrastructure. Who knows, some of that money might even percolate towards open source software, and they can hire someone who knows how to run valgrind.</p><p>Or maybe everything will continue to suck, because incentives rule anything, and there currently aren’t any to do better.</p><p>It took me a long time to write this one up, despite it being a rather simple technical issue, because I’m sure there are eldritch horrors lurking beneath the surface of this relatively simple finding.</p><p>The vendor’s response was pretty lame, yeah. But is this vendor the lamest in their industry? I’m not so sure about that one. At least they responded within 90 days and fixed the issue on their GitHub.</p><p>But, hey, if you’re waiting on SignalWire to get around to running … maybe rebuild from source or block public HTTP access to your FreeSWITCH stack at the firewall level?</p>","contentLength":5718,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43340196"},{"title":"Show HN: XPipe, a shell connection hub for SSH, Docker, K8s, VMs, and more","url":"https://xpipe.io/","date":1741749388,"author":"crschnick","guid":208,"unread":true,"content":"<li><div>A connection hub to keep track and manage of all your remote connections in one place</div></li><li><div>A terminal launcher that can launch you into a shell session in your favorite terminal instantly</div></li><li><div>Complete SSH support, including config files, agent integrations, jump servers, tunnels, key files, smartcards, X11 forwarding, and more</div></li><li><div>Integrations for various container runtimes like Docker, Podman, Kubernetes, LXD, incus, plus environments like WSL, Cygwin, MSYS2</div></li><li><div>Support for hypervisors like Proxmox, Hyper-V, KVM, VMware workstation, and more</div></li>","contentLength":527,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43339629"},{"title":"Show HN: VSC – An open source 3D Rendering Engine in C++","url":"https://github.com/WW92030-STORAGE/VSC","date":1741748903,"author":"NormalExisting","guid":207,"unread":true,"content":"<p>Been making this rasterizer engine in C++ for the past few months, now also adding ray-tracing functionality to the system.</p><p>Simply load a model or generate a mesh, add some lights, and render.</p>","contentLength":191,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43339584"},{"title":"Beyond Diffusion: Inductive Moment Matching","url":"https://lumalabs.ai/news/inductive-moment-matching","date":1741748747,"author":"outrun86","guid":211,"unread":true,"content":"<h3>Fully unlocking the potential of rich multi-modal data</h3><div><p>There is a growing sentiment in the AI community that generative pre-training is reaching a limit. However, we argue that these limits are not due to a lack of data itself, but rather a stagnation in algorithmic innovation. The field remains dominated by just two paradigms since around mid-2020: autoregressive models for discrete signals and diffusion models for continuous signals. This stagnation has created a bottleneck that prevents us from fully unlocking the potential of rich multi-modal data, which in turn limits the progress on multimodal intelligence.</p><p>At Luma, we aim to overcome this algorithmic ceiling through the lens of efficient inference-time compute scaling. Today we are introducing a new method, Inductive Moment Matching (IMM), a pre-training technique that not only delivers superior sample quality compared to diffusion models but also offers over a tenfold increase in sampling efficiency. In contrast to consistency models (CMs), which are unstable as a pre-training technique and require special hyperparameter designs, IMM employs a single objective with enhanced stability across diverse settings.</p></div><h3>How Inductive Moment Matching Works</h3><div><p>Inference can generally be scaled along two dimensions: extending sequence length (in autoregressive models), and augmenting the number of refinement steps (in diffusion models). While adding more refinement steps significantly boosts diffusion models, simply increasing the model capacity does not yield proportional improvements. This is because diffusion models inherently require more granular steps to converge to an optimal solution, regardless of the networks’ representational power. This shows that, from an inference-time perspective, diffusion models are not optimal in utilizing the networks’ capacity.</p></div><div><p>We illustrate these limitations from an inference perspective by examining the DDIM sampler for diffusion models. In each DDIM iteration, the network first generates a prediction using the current input and timestep, then linearly interpolates this prediction toward that of the next timestep. This constrains the expressive capacity of each iteration as it is linear with respect to the next timestep, ultimately capping performance regardless of the training method employed (see figure below).</p></div><div><p>We design our new pre-training algorithm by first aiming to mitigate this inference limitation. Our new method, Inductive Moment Matching (IMM), introduces a subtle yet powerful modification: alongside the current timestep, the network also processes the target timestep to jump towards. This change enhances the flexibility of each inference iteration, paving the way for state-of-the-art performance and efficiency. We realize this improvement by incorporating maximum mean discrepancy — a robust moment matching technique that was developed more than 15 years ago.</p></div><div><p>We test IMM on various hyperparameters and model architectures. On ImageNet 256x256, IMM achieves 1.99 Frechet Inception Distance (FID) and surpasses diffusion models (2.27 FID) and Flow Matching (2.15 FID) with 30x fewer sampling steps. It similarly achieves state-of-the-art 2-step FID of 1.98 on the standard CIFAR-10 dataset for a model trained from scratch.</p></div><div><p>IMM scales with training and inference compute as well as model size. We show in the figure below FID vs. training and inference compute, and we find strong correlation between compute used and performance.</p></div><div><p>Unlike consistency models, which have been shown to have unstable training dynamics, IMM is stable to train across various hyperparameters and architectures.</p></div><div><p>Notably, IMM does not rely on denoising score matching or the score-based stochastic differential equations on which the foundations of diffusion models are built. The key driver of our performance gains is not only moment matching itself, but also our shift towards an inference-first perspective. This not only reveals the inherent limitations in current pre-training paradigms but also empowers us to develop innovative algorithms designed to break through the current limits of pre-training.</p><p>We believe that this is just the beginning of a paradigm shift towards multi-modal foundation models that transcends current boundaries and fully unlock creative intelligence.</p><p>If you are interested in the mission, <a href=\"https://lumalabs.ai/join\">join us</a>.</p></div><div><p>Linqi Zhou, Stefano Ermon, Jiaming Song. “Inductive Moment Matching”.Jiaming Song, Linqi Zhou. “Ideas in Inference-time Scaling can Benefit Generative Pre-training Algorithms”.<p>Song et al. “Denoising Diffusion Implicit Models.”&nbsp;ICLR 2021.</p>Song et al. “Consistency Models.”&nbsp;ICML 2023.<p>Lipman et al. “Flow matching for generative modeling.”&nbsp;ICLR 2023.</p>Gretton et al. “A Kernel Method for the Two-Sample Problem.” NeurIPS 2006.<p>Song et al. “Score-Based Generative Modeling through Stochastic Differential Equations.”&nbsp;ICLR 2021.</p>Kim et al. “Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion.”&nbsp;ICLR 2024.<p>Vincent. “A Connection Between Score Matching and Denoising Autoencoders.”&nbsp;Neural Computation (Vol. 23).</p>Geng et al. “Consistency Models Made Easy”. ICLR 2025.</p></div>","contentLength":5173,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43339563"},{"title":"The Startup CTO's Handbook","url":"https://github.com/ZachGoldberg/Startup-CTO-Handbook/blob/main/StartupCTOHandbook.md","date":1741731522,"author":"simonebrunozzi","guid":210,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43337703"},{"title":"Open-UI: Maintain an open standard for UI and promote its adherence and adoption","url":"https://github.com/openui/open-ui","date":1741521238,"author":"ksec","guid":209,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43308278"}],"tags":["dev","hn"]}