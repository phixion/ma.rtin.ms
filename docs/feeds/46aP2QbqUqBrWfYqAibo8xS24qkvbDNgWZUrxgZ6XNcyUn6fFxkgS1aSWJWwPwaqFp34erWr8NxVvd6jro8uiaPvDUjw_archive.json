{"id":"46aP2QbqUqBrWfYqAibo8xS24qkvbDNgWZUrxgZ6XNcyUn6fFxkgS1aSWJWwPwaqFp34erWr8NxVvd6jro8uiaPvDUjw","title":"top scoring links : kubernetes","displayTitle":"Reddit - Kubernetes","url":"https://www.reddit.com/r/kubernetes/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/kubernetes/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"Greek is Greek","url":"https://www.reddit.com/r/kubernetes/comments/1j9n9mr/greek_is_greek/","date":1741794906,"author":"/u/amarao_san","guid":342,"unread":true,"content":"<p>I'm looking at the Agones, and, given that I learn Greek language, I can't see it just as 'random nice-sound name'.</p><p>ŒëŒ≥œéŒΩŒµœÇ is plural of ŒëŒ≥œéŒΩŒ±œÇ, which is 'fight' or 'battle'. And it also prononced with stress on 'o' ah-gO-nes (ah-gO-nas), and it have soft 'g' sound, which is different from English g (and closer to Ukrainian '–≥').</p><p>Imagine someone call the software 'fights', and every one outside of English speaking world pronounce it as 'fee-g-h-t-s'.</p>","contentLength":464,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Best Practices for Multi‚ÄêCluster OIDC Auth? (Keycloak)","url":"https://www.reddit.com/r/kubernetes/comments/1j9ms78/best_practices_for_multicluster_oidc_auth_keycloak/","date":1741793655,"author":"/u/8bitjohnny","guid":338,"unread":true,"content":"<p>I am trying to figure out the ‚Äúindustry standard‚Äù way of handling OIDC auth across multiple Kubernetes clusters with Keycloak, and could use some community support.</p><p>Background: I‚Äôve got around 10 Kubernetes clusters and about 50 users, and I need to use Keycloak for OIDC to manage access. Right now I'm still in POC stage, but I‚Äôm running one Keycloak client per cluster, each client has two roles (admin and read-only), and users can be admin in some clusters and read-only in others. I am having trouble reconciling the roleBindings and their subjects in a way that feels functionally minimal. The way I see it I end up with either crazy roleBindings, crazy keycloak clients, or an unwieldly number of groups/roles, with some funky mappers thrown in.</p><p>My questions for you all:</p><ul><li>How do you handle multi-cluster RBAC when using Keycloak? How do you keep it manageable?</li><li>Would you stick to the one-client-per-cluster approach, or switch to one client with a bunch of group mappings?</li><li>If I have to expect it to be messy somewhere, where is better? Keycloak side or k8s side?</li></ul><p>Would love to hear your setups and any pitfalls you‚Äôve run into! Thanks in advance.</p>","contentLength":1158,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Setup Preview Environments with FluxCD in Kubernetes","url":"https://www.reddit.com/r/kubernetes/comments/1j9m657/how_to_setup_preview_environments_with_fluxcd_in/","date":1741792082,"author":"/u/meysam81","guid":339,"unread":true,"content":"<p>I just wrote a detailed guide on setting up GitOps-driven preview environments for your PRs using FluxCD in Kubernetes.</p><p>If you're tired of PaaS limitations or want to leverage your existing K8s infrastructure for preview deployments, this might be useful.</p><ul><li><p>Creating PR-based preview environments that deploy automatically when PRs are created</p></li><li><p>Setting up unique internet-accessible URLs for each preview environment</p></li><li><p>Automatically commenting those URLs on your GitHub pull requests</p></li><li><p>Using FluxCD's ResourceSet and ResourceSetInputProvider to orchestrate everything</p></li></ul><p>The implementation uses a simple Go app as an example, but the same approach works for any containerized application.</p><p>Let me know if you have any questions or if you've implemented something similar with different tools. Always curious to hear about alternative approaches!</p>","contentLength":827,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes as a foundation for XaaS","url":"https://www.reddit.com/r/kubernetes/comments/1j9kygu/kubernetes_as_a_foundation_for_xaas/","date":1741788610,"author":"/u/dariotranchitella","guid":341,"unread":true,"content":"<p>If you're not familiar with the term,  stands for \"Everything as a Service\". By discussing with several software companies, Kubernetes has emerged as the ideal platform to embrace this paradigm: while it solves many problems, it also introduces significant challenges which I'll try to elaborate a bit more throughout the thread.</p><p>We all know Kubernetes works (sic) on any infrastructure and (again, sic) hardware by abstracting the underlying environment and leveraging application-centric primitives. This flexibility has enabled a wide range of innovative services, such as:</p><ul><li>, provided by companies like Kong.</li><li>, exemplified by solutions from EDB.</li><li>, with platforms like OpenShift Virtualization.</li></ul><p>These services are fundamentally powered by Kubernetes, where an Operator handles the service's lifecycle, and end users consume the resulting outputs by interacting with APIs or Custom Resource Definitions (CRDs).</p><p>This model works well in multi-tenant Kubernetes clusters, where a large infrastructure is efficiently partitioned to serve multiple customers: think of Amazon RDS, or MongoDB Atlas. However, complexity arises when deploying such XaaS solutions on tenants' own environments‚Äîbe it their public cloud accounts or on-premises infrastructure.</p><p>This brings us to the concept of : each tenant may require a dedicated Kubernetes cluster for security, compliance, or regulatory reasons (e.g., SOC 2, GDPR, if you're European you should be familiar with it). The result is , where each customer potentially requires multiple clusters. This raises a critical question: <em>who is responsible for the lifecycle, maintenance, and overall management of these clusters?</em></p><p>Managed Kubernetes services like AKS, EKS, and GKE can ease some of this burden by handling the Control Plane. However, the true complexity of delivering XaaS with Kubernetes lies in managing multiple clusters effectively.</p><p>For those already facing the complexities of multi-cluster management (the proverbial  dilemma),  offers a promising solution. By creating an additional abstraction layer for cluster lifecycle management, Cluster API simplifies some aspects of scaling infrastructure. However, while Cluster API addresses certain challenges, it doesn't eliminate the complexities of deploying, orchestrating, and maintaining the \"X\" in XaaS ‚Äî the unique business logic or service architecture that must run across multiple clusters.</p><p>Beyond cluster lifecycle management, additional challenges remain ‚Äî such as handling diverse storage and networking environments. Even if these issues are addressed, organizations must still find effective ways to:</p><ul><li>Distribute software reliably to multiple clusters.</li><li>Perform rolling upgrades efficiently.</li><li>Gain visibility into logs and metrics for proactive support.</li><li>Enforce usage limits (especially for licensed software).</li><li>Simplify technical support for end users.</li></ul><p>At this stage, I'm not looking for clients but rather seeking a  interested in collaborating to build a new solution from the ground up, as well as engaging with the community members who are exploring or already explored XaaS models backed by Kubernetes and the  (Bring Your Own Cloud) approach. My goal is to develop a comprehensive suite for software vendors to deploy their services seamlessly across multiple cloud infrastructures ‚Äî even on-premises ‚Äî without relying exclusively on managed Kubernetes services.</p><p>I'm aware that companies like Replicated already provide similar solutions, but I'd love to hear about unresolved challenges, pain points, and ideas from those navigating this complex landscape.</p>","contentLength":3570,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Weekly: Share your EXPLOSIONS thread","url":"https://www.reddit.com/r/kubernetes/comments/1j9gk1g/weekly_share_your_explosions_thread/","date":1741773631,"author":"/u/gctaylor","guid":337,"unread":true,"content":"<div><p>Did anything explode this week (or recently)? Share the details for our mutual betterment.</p></div>   submitted by   <a href=\"https://www.reddit.com/user/gctaylor\"> /u/gctaylor </a>","contentLength":121,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ICYMI - Kubescape is now in incubation in the CNCF","url":"https://kubescape.io/blog/2025/02/25/kubescape-incubation/","date":1741764139,"author":"/u/oshratn","guid":340,"unread":true,"content":"<p>We are thrilled to share that Kubescape has officially been accepted as a CNCF Incubating project. This milestone is a significant achievement for the project. Kubescape began in 2021 as a fun project to scan for compliance with NSA-CISA Kubernetes hardening guidelines. What started as a security scanner, helping Devlopers and DevOps teams implement better Kubernetes security practices, evolved into a full security platform. Still helping security Kubernetes environments üòâ</p><p>From the very beginning, Kubescape was built with the cloud-native community in mind. It started as a simple CLI tool designed to check cluster configurations against NSA-CISA Kubernetes Hardening Guidance. Over time, with the support of a rapidly growing community, Kubescape has evolved into one of the most complete open-source solutions for Kubernetes security. We are proud to have contributed to its development alongside contributors in the Kubescape community, and to see so many adopters leveraging Kubescape in their day-to-day workflows.</p><p>The Kubescape community has been a driving force behind this success. It‚Äôs not just the maintainers and contributors that we celebrate but the many users who have adopted and integrated Kubescape into their environments. Companies like Intel, AWS, Bitnami, ARMO, and Energi Danmark are just a few of the organizations using Kubescape. Some use Kubescape to secure their Kubernetes clusters. Others leverage it for educational purposes. Other use cases that go beyond what we imagined when we made our first commit. We are grateful for the trust that these adopters, along with hundreds of others, have shown in Kubescape.</p><p>As we look toward the future, the Kubescape project is poised for even greater growth. Our roadmap is not just about adding more features, but about continuing to improve usability and optimizing the performance of the platform. We are excited to welcome new contributors and users into the fold as we continue on the hamster-wheel of Kubernetes security.</p><p>The Kubescape community is our foundation, and we are committed to fostering a collaborative and inclusive environment where all contributions are valued. With the incredible support of the Cloud Native Computing Foundation (CNCF) and the broader Kubernetes community, we are determined to demonstrate sustained growth, strong governance, and broad adoption on our journey toward CNCF graduation. We believe that this is just the beginning, and we are eager to see where the future takes us.</p><p>Together, with the support of these vibrant communities, Kubescape will continue to evolve and grow, offering better security, deeper insights, and an ever-expanding set of features. We invite everyone - whether you are an adopter, contributor, or newcomer - to join us in shaping the future of Kubernetes security.</p><p>We welcome your feedback and ideas for improvement. We hold <a href=\"https://kubescape.io/project/community/#monthly-meeting\">community meetings</a> on Zoom, on the first Tuesday of every month, at 14:00 GMT.</p><p>Thanks to all our contributors! Check out our <a href=\"https://github.com/kubescape/project-governance/blob/main/CONTRIBUTING.md\">CONTRIBUTING</a> file to learn how to join them.</p>","contentLength":3040,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1j9edte/icymi_kubescape_is_now_in_incubation_in_the_cncf/"}],"tags":["dev","reddit","k8s"]}