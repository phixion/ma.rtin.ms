{"id":"CSXkJZ3MdFx","title":"Dev News","displayTitle":"Dev News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":71,"items":[{"title":"Feeling Lost on My DevOps/Kubernetes Journey. What Should I Focus on Next?","url":"https://www.reddit.com/r/kubernetes/comments/1r5ty5i/feeling_lost_on_my_devopskubernetes_journey_what/","date":1771199263,"author":"/u/igottomakeit","guid":320,"unread":true,"content":"<p>Sorry in advance if this post is a bit long, but I really wanted to explain my situation clearly and get some honest advice.</p><p>I’m a fresh graduate currently looking for a job, and I’d really appreciate some guidance from more experienced people.</p><p>Even though my degree wasn’t purely computer science, I was always more drawn to CS-related topics. During university, I studied modules in Java, C, embedded systems, databases, HTML/CSS/JavaScript, etc. I also worked in different software development roles using C#, React, and other technologies. But I never really had the chance to deeply specialize in one area.</p><p>For my thesis, I intentionally chose Machine Learning because I’ve always loved the idea of extracting knowledge from data. While working on my thesis, I got introduced to Kubernetes for the first time, mainly through the MLOps/DevOps side of the project. That part felt extremely complex to me because I lacked strong Linux fundamentals, had limited Bash scripting experience, and basically zero knowledge of CI/CD pipelines.</p><p>After finishing my thesis, I decided that for the first time, I wanted to specialize seriously. I chose to focus on DevOps/Kubernetes.</p><p>I started building my own projects:</p><ul><li>Tried to build production-like use cases</li></ul><ul><li>I deployed a microservices app on Kubernetes with CI/CD using GitHub Actions</li><li>I implemented GitOps with ArgoCD</li><li>I configured monitoring with Prometheus and Grafana</li><li>I used Helm for packaging and deployments</li><li>I configured Nginx as a reverse proxy and worked with ingress concepts</li></ul><p>I also tried to use Terraform, Ansible, and AWS in one project to learn about them, but I decided to first properly finish a solid project with CI/CD, Kubernetes, ArgoCD, GitHub Actions, and networking/proxy configuration before going deeper into infrastructure provisioning.</p><p>Building these projects taught me a lot and made me more confident in job interviews. My long-term goal is to work as a DevOps/Platform engineer in a team managing production systems at scale, not just doing small projects.</p><p>But I still feel like I’m missing something. Even after a year of using Kubernetes, it still feels “new.” I can do the common tasks, but I often need to look up commands and concepts.</p><p>I realized I skipped some fundamentals:</p><ul><li>Pipes &amp; process management</li></ul><p>Sometimes I feel like I understand things when building projects, but not deeply enough to feel “solid.” I’m not sure if this is normal or a sign that I need to slow down and reinforce fundamentals.</p><ol><li>Am I doing the right thing by going back and focusing on Linux fundamentals?</li><li>Should I try to learn  tool? <ul><li>I’m comfortable with ArgoCD, should I also learn FluxCD?</li><li>I use GitHub Actions, should I also learn Jenkins and GitLab CI?</li></ul></li><li>What would be the most optimal next steps if my goal is to become a strong DevOps engineer?</li></ol><p>I genuinely want to master this field, and I’m fully ready to commit my time and focus to it. The problem isn’t motivation. it’s direction.</p><p>I sometimes feel unsure about how to structure my learning in a way that builds real depth, instead of just jumping from one tool to another without developing strong fundamentals.</p><p>I’d appreciate any advice from people who’ve been through this journey.</p>","contentLength":3196,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I’ve made a tool to keep dotfiles and system configs in sync with a Git repo","url":"https://github.com/senotrusov/etcdotica","date":1771196079,"author":"/u/senotru","guid":288,"unread":true,"content":"<p>I built a small tool called etcdotica for keeping dotfiles and small system configs in sync with a Git or other VCS repository that mirrors your machine's filesystem layout.</p><p>I used Go because it fits the job perfectly: it’s fast, pleasant to work with the filesystem API, and its explicit error handling lets me handle every error precisely and clearly.</p><p>I was not happy with many existing tools in that space.</p><p>The idea is simple: your repo looks like your system. A file at home/.bashrc maps to ~/.bashrc, while root/etc/... maps under /etc. Running the tool applies changes from the repo to the machine, and optionally collects newer edits made directly on the machine back into the repo. Deleting a file in the repo prunes it from the destination, so the state converges instead of drifting.</p><ul><li>Syncs files from a source tree to a destination directory</li><li>Collect mode to pull newer destination edits back into the repo</li><li>Prunes removed files using a tracked state file</li><li>Managed \"sections\" that insert named blocks into existing files instead of replacing them</li><li>Watch mode to apply changes continuously, suitable for a user systemd service</li><li>Safe concurrent runs via file locking</li><li>Permission control: subtract bits with umask, add bits with a simple flag to enable world readability</li><li>Automatic executable bits for selected directories like bin/</li><li>Follows source symlinks, follows destination symlinks to folders, but replaces destination symlinked files with real files</li></ul><p>The sections feature is particularly useful for shared files such as fstab or hosts. You can keep portable snippets in the repo, and they get merged into the target file, with the ability to later update or remove them as the source file gets updated or removed.</p><p>I wanted something light with predictable behavior.</p><p>A typical workflow is to clone the repo (for example ~/.dotfiles), run the tool once for user files, once with sudo for system files, and optionally keep a watch service running so edits in the repo materialize on the machine.</p><p>I'd love feedback on the idea.</p>","contentLength":2014,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1r5sq6q/ive_made_a_tool_to_keep_dotfiles_and_system/"},{"title":"Looked at the official Go client for Max Bot API. Rewrote it over the weekend","url":"https://www.reddit.com/r/golang/comments/1r5skze/looked_at_the_official_go_client_for_max_bot_api/","date":1771195718,"author":"/u/krasava_wtf","guid":287,"unread":true,"content":"<p>Had some free time this weekend, decided to try Max Bot API — a messenger by VK, positioned as a Telegram alternative. Opened the official Go client and... to put it mildly, I was shocked. Spent the first 30 minutes debugging why an inline button under a message disappears on its own. Send a message with an inline button — works fine. Edit just the text — button vanishes. Turns out </p><p>``<code>go type NewMessageBody struct { Text string</code>json:\"text,omitempty\"<code> Attachments []interface{}</code>json:\"attachments\"` // ← no omitempty! }</p><p>func NewMessage() *Message { return &amp;Message{message: &amp;schemes.NewMessageBody{ Attachments: []interface{}{}, // ← always empty slice }} } ``omitempty`, the empty slice is sent as `\"attachments\": []`. The API interprets this as \"delete all attachments\". You just want to change the text — and your buttons silently disappear. </p><p>And that's just the beginning: </p><p>- `GetChatID()` for callbacks returns 0 — the ID is available via `Message.Recipient.ChatId`, but the method ignores it. You send a response to nowhere - 3 different loggers (`log`, `slog`, `zerolog`) in one codebase — the library writes to stdout instead of returning errors. 30+ places where errors are swallowed<p> - `int64` → `int` casts — breaks on 32-bit platforms</p> - No `context.Context` in upload methods </p><p>Rewrote the client from scratch over the weekend: - Zero dependencies — stdlib only<p> - All errors are returned, nothing is logged</p> - `context.Context` everywhere<p> - Type-safe constructors for buttons and attachments</p> - Testable via `httptest.Server` </p><p>Can't understand how an entire team ships this kind of Go code. Feedback welcome. </p>","contentLength":1632,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Magnus Carlsen Wins the Freestyle (Chess960) World Championship","url":"https://www.fide.com/magnus-carlsen-wins-2026-fide-freestyle-world-championship/","date":1771193830,"author":"prophylaxis","guid":264,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47028227"},{"title":"Pocketblue – Fedora Atomic for mobile devices","url":"https://github.com/pocketblue/pocketblue","date":1771193815,"author":"/u/giannidunk","guid":325,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1r5rtih/pocketblue_fedora_atomic_for_mobile_devices/"},{"title":"I’m joining OpenAI","url":"https://steipete.me/posts/2026/openclaw","date":1771192455,"author":"mfiguiere","guid":263,"unread":true,"content":"<p><strong>tl;dr: I’m joining OpenAI to work on bringing agents to everyone. <a href=\"https://openclaw.ai/\">OpenClaw</a> will move to a foundation and stay open and independent.</strong></p><p>The last month was a whirlwind, never would I have expected that my playground project would create such waves. The internet got weird again, and it’s been incredibly fun to see how my work inspired so many people around the world.</p><p>There’s an endless array of possibilities that opened up for me, countless people trying to push me into various directions, giving me advice, asking how they can invest or what I will do. Saying it’s overwhelming is an understatement.</p><p>When I started exploring AI, my goal was to have fun and inspire people. And here we are, the lobster is taking over the world. My next mission is to build an agent that even my mum can use. That’ll need a much broader change, a lot more thought on how to do it safely, and access to the very latest models and research.</p><p>Yes, I could totally see how OpenClaw could become a huge company. And no, it’s not really exciting for me. I’m a builder at heart. I did the whole creating-a-company game already, poured 13 years of my life into it and learned a lot. What I want is to change the world, not build a large company and teaming up with OpenAI is the fastest way to bring this to everyone.</p><p>I spent last week in San Francisco talking with the major labs, getting access to people and unreleased research, and it’s been inspiring on all fronts. I want to thank all the folks I talked to this week and am thankful for the opportunities.</p><p>It’s always been important to me that OpenClaw stays open source and given the freedom to flourish. Ultimately, I felt OpenAI was the best place to continue pushing on my vision and expand its reach. The more I talked with the people there, the clearer it became that we both share the same vision.</p><p>The community around OpenClaw is something magical and OpenAI has made strong commitments to enable me to dedicate my time to it and already sponsors the project. To get this into a proper structure I’m working on making it a foundation. It will stay a place for thinkers, hackers and people that want a way to own their data, with the goal of supporting even more models and companies.</p><p>Personally I’m super excited to join OpenAI, be part of the frontier of AI research and development, and continue building with all of you.</p>","contentLength":2374,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47028013"},{"title":"kubeloom: a TUI for debugging Istio Ambient","url":"https://www.reddit.com/r/kubernetes/comments/1r5r8gg/kubeloom_a_tui_for_debugging_istio_ambient/","date":1771192386,"author":"/u/__4di__","guid":319,"unread":true,"content":"<p>I work with Istio Ambient and a fair share of other service meshes, applying them but also automating them. And in our team we used bang our heads trying to make sense of the flood of the logs from various components and making manifest modifications. So a while ago we came up with a toy tool to kinda quickly wrap our most frequent actions into a single pane of display and that eventually evolved into .</p><p>Its not perfect and has a few quirks, but I and the people using service mesh at my work find it quite useful and it's increased the speed in which we debug our policies. So, I just wanted to share it here in case any one else might find it useful!</p>","contentLength":654,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"New to GO, where do I start?","url":"https://www.reddit.com/r/golang/comments/1r5qvs1/new_to_go_where_do_i_start/","date":1771191534,"author":"/u/Otherwise-Ask4947","guid":289,"unread":true,"content":"<p>Basically what the title says. I went through documentation and tutorial parts from official website.</p><p>For reference I’m sr. Nest and Next developer, so I do have prior experience in programming.</p><p>How do I get at least on JR level? Start by building smth from scratch, or I need grasp of specific concepts?</p>","contentLength":304,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Local WebSocket: Building Real-Time Apps That Work Without the Cloud","url":"https://medium.com/@dr.e.rashidi/local-websocket-building-real-time-apps-that-work-without-the-cloud-a0f46ae14dd7","date":1771191449,"author":"/u/_Flame_Of_Udun_","guid":340,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1r5quh6/local_websocket_building_realtime_apps_that_work/"},{"title":"Chirp #5: Budgie 11 Priorities, Panel Config, and 10.10 Polish","url":"https://buddiesofbudgie.org/blog/chirp-5","date":1771190260,"author":"/u/JoshStrobl","guid":323,"unread":true,"content":"<p><a href=\"https://buddiesofbudgie.org/blog/chirp-5#osd-visibility-over-fullscreen-apps\">#</a>OSD Visibility over Fullscreen Apps</p><ul><li>Clicking an  group minimizes the whole group</li><li>Clicking an  group activates all windows in the group</li></ul><p><a href=\"https://buddiesofbudgie.org/blog/chirp-5#labwc-bridge-improvements\">#</a>labwc Bridge Improvements</p><ul><li>Support for defining multiple  keys where there is more than one key in a keybind array</li><li>Full linking of  keybinds against schema keys, so changes made in dconf or Budgie Control Center properly reflect through the bridge</li><li>An override for the  menu overlay key, since Budgie expects  rather than GNOME's default </li></ul><p><a href=\"https://buddiesofbudgie.org/blog/chirp-5#qemu-/-gnome-boxes-cursor-fix\">#</a>QEMU / gnome-boxes Cursor Fix</p><p><a href=\"https://buddiesofbudgie.org/blog/chirp-5#other-pending-pull-requests\">#</a>Other Pending Pull Requests</p><ul><li>Panels<ul><li>Support for multiple panels (different anchors / sides)<ul><li>Stretch goal: Support for panels on different outputs (no spanning) - This might happen since we will need the code in place anyways to ensure we are setting it on the primary output, but we shall see!</li></ul></li><li>Extensions: Budgie Menu, IconTasklist, Status Indicator (scoped to Battery and Volume sub-items in Preview 1), System Tray, Raven Trigger &amp; Notification Unread, Clock</li></ul></li><li>Raven</li><li>On-screen displays: Volume changing (volume lowering, raising, muting), Brightness changing</li><li>Notifications (likely not persistent / stored in Raven)</li></ul><ul><li>\"Meta-actions\" support for keybinds (trigger Alt+Tab, tiling)</li><li>Focus methods (already implemented)</li></ul><div><p>Did you know that you can financially support the Buddies of Budgie project? Buddies of Budgie was founded to provide a home for Budgie Desktop and your financial contribution can go a long way to supporting our goals for development, providing opportunities for financial compensation, leveraging no-compromise Continuous Integration and Continuous Delivery systems for Budgie 11 development, and more.</p><a href=\"https://opencollective.com/buddies-of-budgie?ref=buddiesofbudgie.org\"></a></div>","contentLength":1603,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1r5qcah/chirp_5_budgie_11_priorities_panel_config_and/"},{"title":"Has anyone gotten Cilium BGP Peer Autodiscovery to work correctly when native routing mode is enabled?","url":"https://www.reddit.com/r/kubernetes/comments/1r5q25f/has_anyone_gotten_cilium_bgp_peer_autodiscovery/","date":1771189598,"author":"/u/lacrosse1991","guid":318,"unread":true,"content":"<p>When I don't have native routing mode enabled, my kubernetes nodes are able to connect to my router using auto discovery without any issues. Once I enable native routing mode, the auto discovered peer IPs for BGP then somehow pick up a random pod cidr address and try using that instead. It's not the end of the world if I need to stop using auto discovery, although I would still like to get it working properly if possible. </p><p>I've included what I'm seeing for the BGP peers in a screenshot. </p>","contentLength":491,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EKS Setup Help","url":"https://www.reddit.com/r/kubernetes/comments/1r5pa6j/eks_setup_help/","date":1771187761,"author":"/u/Specific-Swimming518","guid":317,"unread":true,"content":"<p>I'm designing an EKS cluster setup. I will have a monitoring stack (VictoriaMetrics, Grafana, Loki), databases, and maybe stateless microservices pods. For autoscaling and provisioning, I want to use Karpenter, and I want to ask you about this logic:</p><ol><li><strong>NodePool for stateless apps</strong> with spot instances and full consolidation capabilities.</li></ol><p>As a result, I can set up the CSI EBS DaemonSet with affinity to the <a href=\"http://karpenter.sh/stateful:\"></a> label and run CSI agents only on nodes that need it. This gives me optimization because I don't run them on stateless nodes. Stateful nodes are prevented from deletion by Karpenter because there will always be resources on them.</p><p>What do you think about such a setup?</p>","contentLength":669,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Michael Abrash doubled Quake framerate","url":"https://fabiensanglard.net/quake_asm_optimizations/index.html","date":1771183571,"author":"/u/NXGZ","guid":344,"unread":true,"content":"<div>How Michael Abrash doubled Quake framerate</div><p>With the 1999 release of the Quake source code, came a <a href=\"https://github.com/id-Software/Quake/blob/master/readme.txt\">readme.txt</a> written by John Carmack. There is a particular sentence in that text that piqued my curiosity.</p><pre>Masm is also required to build the assembly language files.  It is possible to\nchange a #define and build with only C code, but the software rendering versions\nlose almost .\n</pre><p>Quake would be 50% faster thanks to its hand-crafted assembly? Let's find out if that is true, how it works, and what are the most important optimizations.</p><div>Establishing stock fps on my machine</div><p>Before doing anything with the source I needed to establish what was the framerate of the released version of  on my Pentium MMX 233MHz.</p><pre>\nC:\\winquake&gt; winquake.exe -wavonly +d_subdiv16 0 +timedemo demo1\n\n</pre><p>I disabled  because it has no C implementation (that will make C vs ASM comparison impossible). This makes the engine fallback to D_DrawSpans8 instead of D_DrawSpans16 (perspective sampling every 8 pixels instead of 16).  is the fastest audio backend (also known as <a href=\"https://fabiensanglard.net/winquake\">\"fastvid\" option in wq.bat)</a>.</p><a href=\"https://fabiensanglard.net/quake_asm_optimizations/42.3.png\"><img loading=\"lazy\" src=\"https://fabiensanglard.net/quake_asm_optimizations/42.3.png\" width=\"1600\" height=\"1200\"></a><p>Stock winquake completed  at 42.3fps.</p><p>Following the steps in <a href=\"https://fabiensanglard.net/compile_like_1997\">Let's compile like it's 1997!</a>, I built  in release mode  the ASM optimizations. I really hoped VC++6 compiler did not get significant improvement<a name=\"back_1\" href=\"https://fabiensanglard.net/quake_asm_optimizations/index.html#footnote_1\"></a> over VC++4 (the version id software used to ship winquake in 1997).</p><pre>\nC:\\winquake&gt; WinQuake_ASM.exe -wavonly +d_subdiv16 0 +timedemo demo1\n\n</pre><a href=\"https://fabiensanglard.net/quake_asm_optimizations/42.2.png\"><img loading=\"lazy\" src=\"https://fabiensanglard.net/quake_asm_optimizations/42.2.png\" width=\"1600\" height=\"1200\"></a><p>I was relieved to see <a href=\"https://fabiensanglard.net/quake_asm_optimizations/WinQuake_fab_ASM.exe\">WinQuake_ASM.exe</a> run at nearly the same framerate, 42.2 fps. I was on a good track.</p><p>As John Carmack mentioned, building without ASM only requires setting  to  in .</p><a href=\"https://fabiensanglard.net/quake_asm_optimizations/1.png\"><img loading=\"lazy\" src=\"https://fabiensanglard.net/quake_asm_optimizations/1.png\" width=\"1024\" height=\"768\"></a><p>That broke the linker because a VC6 project meant running on an Intel CPU at the time.</p><a href=\"https://fabiensanglard.net/quake_asm_optimizations/2.png\"><img loading=\"lazy\" src=\"https://fabiensanglard.net/quake_asm_optimizations/2.png\" width=\"1024\" height=\"768\"></a><p>All I had to do was to add <a href=\"https://fabiensanglard.net/quake_asm_optimizations/nonintel.c\">nointel.c</a> to the project and I had a working executable.</p><a href=\"https://fabiensanglard.net/quake_asm_optimizations/nointel.c.png\"><img loading=\"lazy\" src=\"https://fabiensanglard.net/quake_asm_optimizations/nointel.c.png\" width=\"1024\" height=\"768\"></a><div>Quake without ASM optimizations</div><pre>\nC:\\winquake&gt; WinQuake_No_ASM.exe -wavonly +d_subdiv16 0 +timedemo demo1\n\n</pre><a href=\"https://fabiensanglard.net/quake_asm_optimizations/22.7.png\"><img loading=\"lazy\" src=\"https://fabiensanglard.net/quake_asm_optimizations/22.7.png\" width=\"1600\" height=\"1200\"></a><p>Son of a BLiT! The game indeed runs at  instead of ! As John Carmack warned, Quake framerate is halved without Michael Abrash's optimizations!.</p><p>There is a lot of assembly in Quake. In total, grep found 63 functions spread across 21 files.</p><pre>$ find . -name \"*.s\" | wc -l\n21</pre><pre>$ find . -name \"*.s\" -exec grep -H \".globl C(\" {} \\;\n./server/worlda.s:.globl C(SV_HullPointContents)\n./server/math.s:.globl C(BoxOnPlaneSide)\n./client/d_copy.s:.globl C(VGA_UpdatePlanarScreen)\n./client/d_copy.s:.globl C(VGA_UpdateLinearScreen)\n./client/d_draw.s:.globl C(D_DrawSpans8)\n./client/d_draw.s:.globl C(D_DrawZSpans)\n./client/surf16.s:.globl C(R_Surf16Start)\n./client/surf16.s:.globl C(R_DrawSurfaceBlock16)\n./client/surf16.s:.globl C(R_Surf16End)\n./client/surf16.s:.globl C(R_Surf16Patch)\n./client/d_scana.s:.globl C(D_DrawTurbulent8Span)\n./client/r_drawa.s:.globl C(R_ClipEdge)\n./client/d_parta.s:.globl C(D_DrawParticle)\n./client/d_polysa.s:.globl C(D_PolysetCalcGradients)\n./client/d_polysa.s:.globl C(D_PolysetRecursiveTriangle)\n./client/d_polysa.s:.globl C(D_PolysetAff8Start)\n./client/d_polysa.s:.globl C(D_PolysetDrawSpans8)\n./client/d_polysa.s:.globl C(D_PolysetAff8End)\n./client/d_polysa.s:.globl C(D_Aff8Patch)\n./client/d_polysa.s:.globl C(D_PolysetDraw)\n./client/d_polysa.s:.globl C(D_PolysetScanLeftEdge)\n./client/d_polysa.s:.globl C(D_PolysetDrawFinalVerts)\n./client/d_polysa.s:.globl C(D_DrawNonSubdiv)\n./client/sys_wina.s:.globl C(MaskExceptions)\n./client/sys_wina.s:.globl C(unmaskexceptions)\n./client/sys_wina.s:.globl C(Sys_LowFPPrecision)\n./client/sys_wina.s:.globl C(Sys_HighFPPrecision)\n./client/sys_wina.s:.globl C(Sys_PushFPCW_SetHigh)\n./client/sys_wina.s:.globl C(Sys_PopFPCW)\n./client/sys_wina.s:.globl C(Sys_SetFPCW)\n./client/math.s:.globl C(Invert24To16)\n./client/math.s:.globl C(TransformVector)\n./client/math.s:.globl C(BoxOnPlaneSide)\n./client/d_draw16.s:.globl C(D_DrawSpans16)\n./client/r_aclipa.s:.globl C(R_Alias_clip_bottom)\n./client/r_aclipa.s:.globl C(R_Alias_clip_top)\n./client/r_aclipa.s:.globl C(R_Alias_clip_right)\n./client/r_aclipa.s:.globl C(R_Alias_clip_left)\n./client/snd_mixa.s:.globl C(SND_PaintChannelFrom8)\n./client/snd_mixa.s:.globl C(Snd_WriteLinearBlastStereo16)\n./client/r_aliasa.s:.globl C(R_AliasTransformAndProjectFinalVerts)\n./client/d_spr8.s:.globl C(D_SpriteDrawSpans)\n./client/r_edgea.s:.globl C(R_EdgeCodeStart)\n./client/r_edgea.s:.globl C(R_InsertNewEdges)\n./client/r_edgea.s:.globl C(R_RemoveEdges)\n./client/r_edgea.s:.globl C(R_StepActiveU)\n./client/r_edgea.s:.globl C(R_GenerateSpans)\n./client/r_edgea.s:.globl C(R_EdgeCodeEnd)\n./client/r_edgea.s:.globl C(R_SurfacePatch)\n./client/surf8.s:.globl C(R_Surf8Start)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip0)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip1)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip2)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip3)\n./client/surf8.s:.globl C(R_Surf8End)\n./client/surf8.s:.globl C(R_Surf8Patch)\n./client/sys_dosa.s:.globl C(MaskExceptions)\n./client/sys_dosa.s:.globl C(unmaskexceptions)\n./client/sys_dosa.s:.globl C(Sys_LowFPPrecision)\n./client/sys_dosa.s:.globl C(Sys_HighFPPrecision)\n./client/sys_dosa.s:.globl C(Sys_PushFPCW_SetHigh)\n./client/sys_dosa.s:.globl C(Sys_PopFPCW)\n./client/sys_dosa.s:.globl C(Sys_SetFPCW)\n</pre><p>As a comparison, DOOM has only two  files and three functions to speed up the engine.</p><p>A lot of these functions can be discarded from this study. Some do things that cannot be done in C like setting the floating-point unit precision or setting up the High-precision counter (). Some are not used (). Some are duplicated (one for server, one for client). Some optimizations use self-modifying code requiring markers so the  region can be updated from  to  and patched ().</p><pre>$ find . -name \"*.s\" -exec grep -H \".globl C(\" {} \\;\n./server/worlda.s:.globl C(SV_HullPointContents)\n           // Duplicate from ./client/math.s\n // DOS\n // DOS\n./client/d_draw.s:.globl C(D_DrawSpans8)\n./client/d_draw.s:.globl C(D_DrawZSpans)\n   // Experimental 16-bit rendering\n\n./client/d_scana.s:.globl C(D_DrawTurbulent8Span)\n./client/r_drawa.s:.globl C(R_ClipEdge)\n./client/d_parta.s:.globl C(D_DrawParticle)\n./client/d_polysa.s:.globl C(D_PolysetCalcGradients)\n./client/d_polysa.s:.globl C(D_PolysetRecursiveTriangle)\n\n./client/d_polysa.s:.globl C(D_PolysetDrawSpans8)\n\n./client/d_polysa.s:.globl C(D_PolysetDraw)\n./client/d_polysa.s:.globl C(D_PolysetScanLeftEdge)\n./client/d_polysa.s:.globl C(D_PolysetDrawFinalVerts)\n./client/d_polysa.s:.globl C(D_DrawNonSubdiv)\n\n./client/math.s:.globl C(TransformVector)\n./client/math.s:.globl C(BoxOnPlaneSide)\n./client/d_draw16.s:.globl C(D_DrawSpans16)\n./client/r_aclipa.s:.globl C(R_Alias_clip_bottom)\n./client/r_aclipa.s:.globl C(R_Alias_clip_top)\n./client/r_aclipa.s:.globl C(R_Alias_clip_right)\n./client/r_aclipa.s:.globl C(R_Alias_clip_left)\n./client/snd_mixa.s:.globl C(SND_PaintChannelFrom8)\n./client/snd_mixa.s:.globl C(Snd_WriteLinearBlastStereo16)\n./client/r_aliasa.s:.globl C(R_AliasTransformAndProjectFinalVerts)\n./client/d_spr8.s:.globl C(D_SpriteDrawSpans)\n\n./client/r_edgea.s:.globl C(R_InsertNewEdges)\n./client/r_edgea.s:.globl C(R_RemoveEdges)\n./client/r_edgea.s:.globl C(R_StepActiveU)\n./client/r_edgea.s:.globl C(R_GenerateSpans)\n\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip0)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip1)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip2)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip3)\n</pre><p>This still leaves 32 methods pertaining to math, sound, render, and draw. The distinction between R_ and D_ is not obvious. The R_ code is in charge of *what* to draw. The D_ code is in charge of *how* to draw it.</p><pre>\n./client/d_spr8.s:.globl C(D_SpriteDrawSpans)            // Draw sprite facing camera\n./client/d_draw.s:.globl C(D_DrawSpans8)                 // World draw  8 pixels persp\n./client/d_draw.s:.globl C(D_DrawZSpans)                 // World write to Z-Buffer\n./client/d_draw16.s:.globl C(D_DrawSpans16)              // World draw 16 pixels persp\n./client/d_scana.s:.globl C(D_DrawTurbulent8Span)\n./client/d_parta.s:.globl C(D_DrawParticle)\n./client/d_polysa.s:.globl C(D_PolysetCalcGradients)     // All the polysets are for\n./client/d_polysa.s:.globl C(D_PolysetRecursiveTriangle) // alias models rendering. \n./client/d_polysa.s:.globl C(D_PolysetDrawSpans8)        \n./client/d_polysa.s:.globl C(D_PolysetDraw)\n./client/d_polysa.s:.globl C(D_PolysetScanLeftEdge)\n./client/d_polysa.s:.globl C(D_PolysetDrawFinalVerts)\n./client/d_polysa.s:.globl C(D_DrawNonSubdiv)            // Also model drawing\n\n./client/math.s:.globl C(TransformVector)\n./client/math.s:.globl C(BoxOnPlaneSide)\n./server/worlda.s:.globl C(SV_HullPointContents)\n\n./client/snd_mixa.s:.globl C(SND_PaintChannelFrom8)\n./client/snd_mixa.s:.globl C(Snd_WriteLinearBlastStereo16)\n\n./client/r_drawa.s:.globl C(R_ClipEdge)\n./client/r_aclipa.s:.globl C(R_Alias_clip_bottom)\n./client/r_aclipa.s:.globl C(R_Alias_clip_top)\n./client/r_aclipa.s:.globl C(R_Alias_clip_right)\n./client/r_aclipa.s:.globl C(R_Alias_clip_left)\n./client/r_aliasa.s:.globl C(R_AliasTransformAndProjectFinalVerts)\n./client/r_edgea.s:.globl C(R_InsertNewEdges)\n./client/r_edgea.s:.globl C(R_RemoveEdges)\n./client/r_edgea.s:.globl C(R_StepActiveU)\n./client/r_edgea.s:.globl C(R_GenerateSpans)\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip0)       // Surface caching generation\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip1)       // Surface caching generation\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip2)       // Surface caching generation\n./client/surf8.s:.globl C(R_DrawSurfaceBlock8_mip3)       // Surface caching generation\n</pre><p>The next thing to do, before going deeper was to quantify how much each function contributes to improving the framerate from 22.7fps to 42.2fps. To find out, I modified the engine to enable one ASM function at a time and ran the same timedemo over and over again.</p><table><tbody><tr><th>Frames per Second (fps) gain</th></tr><tr></tr></tbody></table><p>Without surprise, the most important optimizations are in the low-level drawing routines with  to render the walls,  to combine texture and lightmap into a surface, and  to draw the models. The rest barely registered on my (rather crude) benchmark.</p><a href=\"https://fabiensanglard.net/quake_asm_optimizations/chart.svg\"><img loading=\"lazy\" src=\"https://fabiensanglard.net/quake_asm_optimizations/chart.svg\" width=\"759\" height=\"309\"></a><p>The Polyset* functions are intertwined in such a way they cannot be individually switched to C/ASM. They have to be all C or all ASM.</p><p>The ASM optimizations I found often involve loop unrolling, self-modifying code, avoiding mis-predictions, leveraging the Pentium FPU pipeline to hide latency, and creating \"overlap\" where both Pentium U/V pipelines and the FPU pipeline are executing instructions in parallel.</p><p>Here are a few detailed functions. For those willing to go ever deeper in that rabbit hole, I suggest reading <i>Optimizations for Intel's\n32-Bit Processors (Feb 94)</i><a name=\"back_2\" href=\"https://fabiensanglard.net/quake_asm_optimizations/index.html#footnote_2\"></a> which covers Pentium extensively. Be warned it is more powerful than 20g of melatonin.</p><p>The function  is a good introduction to the P5 FPU. It is a simple matrix-vector multiplication., used extensively to project everything in screen space, from world polygons, model/alias polygons, and sprites.</p><pre>typedef float vec_t;\ntypedef vec_t vec3_t[3];\n\nvec3_t  vpn, vright, vup;  \n\n#define DotProduct(x,y) (x[0]*y[0]+x[1]*y[1]+x[2]*y[2])\n\nvoid TransformVector (vec3_t in, vec3_t out) {\n  out[0] = DotProduct(in,vright);\n  out[1] = DotProduct(in,vup);\n  out[2] = DotProduct(in,vpn);    \n}\n</pre><p>Let's look at the assembly. I kept mabrash's asm in AT&amp;T notation<a name=\"back_3\" href=\"https://fabiensanglard.net/quake_asm_optimizations/index.html#footnote_3\"></a> on the left. On the right is what VC6 generated, in Intel notation, decompiled by Ninja.</p><table><tbody><tr><td><pre>\n\n.globl C(TransformVector)\n\nmovl  in(%esp),%eax\nmovl  out(%esp),%edx\n\nflds  (%eax)    \nfmuls C(vright) \nflds  (%eax)    \nfmuls C(vup)    \nflds  (%eax)    \nfmuls C(vpn)    \n\nflds  4(%eax)   \nfmuls C(vright)+4 \nflds  4(%eax)   \nfmuls C(vup)+4  \nflds  4(%eax)   \nfmuls C(vpn)+4  \nfxch  %st(2)    \n\nfaddp %st(0),%st(5) \nfaddp %st(0),%st(3) \nfaddp %st(0),%st(1) \n\nflds  8(%eax)   \nfmuls C(vright)+8 \nflds  8(%eax)   \nfmuls C(vup)+8    \nflds  8(%eax)   \nfmuls C(vpn)+8    \nfxch  %st(2)    \n\nfaddp %st(0),%st(5) \nfaddp %st(0),%st(3) \nfaddp %st(0),%st(1) \n\nfstps 8(%edx)   \nfstps 4(%edx)   \nfstps (%edx)     \n\nret\n</pre></td><td><pre>\n\nfloat* TransformVector(float* a1, float* a2)\n\nmov     eax, dword [esp+0x4 {a1}]\nmov     ecx, dword [esp+0x8 {a2}]\n\nfld     st0, dword [0x2970]  \nfmul    st0, dword [eax]\nfld     st0, dword [0x2978]  \nfmul    st0, dword [eax+0x8] \nfaddp   st1, st0\nfld     st0, dword [0x2974]  \nfmul    st0, dword [eax+0x4]\nfaddp   st1, st0\nfstp    dword [ecx], st0\n\nfld     st0, dword [0x2974]  \nfmul    st0, dword [eax]\nfld     st0, dword [0x297c]  \nfmul    st0, dword [eax+0x8]\nfaddp   st1, st0\nfld     st0, dword [0x2978]  \nfmul    st0, dword [eax+0x4]\nfaddp   st1, st0\nfstp    dword [ecx+0x4], st0\n\nfld     st0, dword [0x296c]  \nfmul    st0, dword [eax]\nfld     st0, dword [0x2974]  \nfmul    st0, dword [eax+0x8]\nfaddp   st1, st0\nfld     st0, dword [0x2970]  \nfmul    st0, dword [eax+0x4]\nfaddp   st1, st0\nfstp    dword [ecx+0x8], st0\n\n\n\n\n\n\nretn     {__return_addr}</pre></td></tr></tbody></table><p> The FPU is used like a 487 FPU. Namely an un-pipelined stack where operands are picked up from the top of the stack and results are pushed back on the top of the stack (if you know how a JVM works, that is the same principle). Instructions are found in the same order as on the code, one dot-product after another. And each dot product is *, *, +, *, +. The whole sequence looks as follows.</p><pre>*, *, +, *, +, store\n*, *, +, *, +, store\n*, *, +, *, +, store</pre><p>This approach incurs stalls. A  takes three cycles<a name=\"back_4\" href=\"https://fabiensanglard.net/quake_asm_optimizations/index.html#footnote_4\"></a> to return a result. This means that each  stalls for two cycles while waiting for  result to be available.</p><p> That is a radically different approach. It enqueue as many independent (result not depending on previous operation) instructions as possible in the pipeline. On a 487 that would be a problem because the operands would have to be re-organized with costly  (4 cycles!) to swap their location on the stack.</p><p> But  is free (0 cycle) on Pentium. This instruction allows developers to use nearly all the registers () in the FPU stack. It turns the cumbersome legacy FPU stack into a convenient register array.</p><p>This allows to calculate three dot products in parallel, with three partial sums on the x87 stack at all times. And the computation looks as follows.</p><pre>* * * * * *\n+ + +\n* * *\n+ + +\nstore, store, store\n</pre><p>By the time it does the additions, the results of the multiplication are already available. This hides  latency and lets the P5 avoid stales completely. </p><p> Another optimization in Abrash's version, are the stores () located at the end instead of being mixed with other operations like in the VC6 output. Storing a value (fstp) immediately after calculating results in a 1-cycle stall because the write-back stage of the pipeline cannot be bypassed<a name=\"back_5\" href=\"https://fabiensanglard.net/quake_asm_optimizations/index.html#footnote_5\"></a>. Having the stores at the end ensures that the last faddp has enough cycles to complete before the fstp tries to move that data into memory.</p><p>This function is not actually used in Quake. It is likely one of these optimizations that Michael Abrash wrote and had to be abandoned because John Carmack rewrote the engine completely.</p><blockquote>\nMichael Abrash focused on the x86 assembly optimizations. There were some times where he had spent a lot of effort on a low level routine, then I changed the architecture and he had to start over, which I felt a little bad about, even though it was net-positive.<p>He did use a NeXT for some things (he managed the code merges between us), but he had to do his assembly timings on DOS.\n</p><div>- Conversation with John Carmack</div></blockquote><pre>fixed16_t Invert24To16(fixed16_t val) {\n  if (val &lt; 256)\n    return (0xFFFFFFFF);\n\n  return (fixed16_t)\n      (((double)0x10000 * (double)0x1000000 / (double)val) + 0.5);\n}\n</pre><p>What is cool to see is that no stone were left unturned. Here the main goal of the rewrite is to avoid a call to Microsoft costly CRT  function.</p><table><tbody><tr><td><pre>.globl C(Invert24To16)\n\n  movl  val(%esp),%ecx\n  movl  $0x100,%edx // 0x10000000000 dividend\n  cmpl  %edx,%ecx\n  jle   LOutOfRange\n\n  subl  %eax,%eax\n  divl  %ecx\n\n  ret\n\nLOutOfRange:\n  movl  $0xFFFFFFFF,%eax\n  ret</pre></td><td><pre>int32_t _Invert24To16(int32_t arg1)\n\ncmp     dword [esp+0x4 {arg1}], 0x100\njge     0xf04\n\nor      eax, 0xffffffff  {0xffffffff}\nretn     {__return_addr}\n\nfild    st0, dword [esp+0x4 {arg1}]\nfdivr   st0, qword [__real@4270000]\nfadd    st0, qword [__real@3fe0000]\njmp     __ftol\n\n\n\n</pre></td></tr></tbody></table><p>By the time the engine reaches R_DrawSurfaceBlock8, it has determined which part of a wall is visible. Now the enderer needs to \"bake\" the lightmap into the texture. The result is called a \"Surface\" (that is later handed to the rawer which rasterizes to the framebuffer). Michael Abrash describes this part extensively in <a href=\"https://www.phatcode.net/res/224/files/html/ch68/68-01.html\">Chapter 68: Quake’s Lighting Model</a> so I won't elaborate more on it.</p><p>There are four R_DrawSurfaceBlock8_mip functions. One for each level of mipmap. Here is a clickable image modified engine to show where each level triggers.</p><img src=\"https://fabiensanglard.net/quake_asm_optimizations/mipmap2.png\" onclick=\"flip(this); \"><p>The C version of all four functions is <a href=\"https://github.com/id-Software/Quake/blob/bf4ac424ce754894ac8f1dae6a3981954bc9852d/WinQuake/r_surf.c#L343\">here</a>. The ASM versions are <a href=\"https://github.com/id-Software/Quake/blob/bf4ac424ce754894ac8f1dae6a3981954bc9852d/WinQuake/surf8.s#L47\">here</a>. And the VC6 output for  is <a href=\"https://fabiensanglard.net/quake_asm_optimizations/R_DrawSurfaceBlock8_mip0.txt\">here</a>.</p><p>The most obvious optimization is the self-modifying code. Several memory locations are <a href=\"https://github.com/id-Software/Quake/blob/bf4ac424ce754894ac8f1dae6a3981954bc9852d/WinQuake/surf8.s#L121\">hard-coded to 0x12345678</a> and patched in <a href=\"https://github.com/id-Software/Quake/blob/bf4ac424ce754894ac8f1dae6a3981954bc9852d/WinQuake/surf8.s#L766\">R_Surf8Patch</a> just before R_DrawSurfaceBlock8 is called. The patching bakes the colormap base into the instruction stream which avoids using a register to keep the base. Moreover, this avoids an extra ADD to lookup the colormap.</p><p>The inner \"b\" loop is fully unrolled. This further saves a register by avoiding a loop counter. And one misprediction is avoided on the last iteration (the P5 always picks the backward jmp destination in order to excel at loops).</p><p>Given the importance of this function, I understand better now why Michael Abrash mentioned it in his book.</p><blockquote>\nAs it turns out, the raw speed of surface-based lighting is pretty good. Although an extra step is required to build the surface, moving lighting and tiling into a separate loop from texture mapping allows each of the two loops to be optimized very effectively, with almost all variables kept in registers.<p>The surface-building inner loop is particularly efficient, because it consists of nothing more than interpolating intensity, combining it with a texel and using the result to look up a lit texel color, and storing the results with a dword write every four texels.</p><p>In assembly language, we got this code down to 2.25 cycles per lit texel in Quake. </p><div>- Michael Abrash, Chapter 68: Quake’s Lighting Model</div></blockquote><p>Quake uses an Active Edge Table to render polygons as horizontal spans (I wrote about that <a href=\"https://fabiensanglard.net/quake2/quake2_software_renderer.php\">15 years ago</a> if you want to see it in action). The <a href=\"https://github.com/id-Software/Quake/blob/bf4ac424ce754894ac8f1dae6a3981954bc9852d/WinQuake/d_scan.c#L257\">C version</a> is a pretty big function which spans over 218 lines of code. VC6 <a href=\"https://fabiensanglard.net/quake_asm_optimizations/D_DrawSpans8.txt\">generated</a> 256 lines of ASM. And the <a href=\"https://github.com/id-Software/Quake/blob/bf4ac424ce754894ac8f1dae6a3981954bc9852d/WinQuake/d_draw.s#L91\">hand-optimized version</a> is a 650 lines juggernaut.</p><p>D_DrawSpans8 receives a list of spans (a portion of a surface) to be rasterized to the framebuffer. The goal is to be perspective correct every 8 pixels (vs D_DrawSpans16 which does it every 16 pixels) and interpolate the rest.</p><p>The biggest challenge of this function is that interpolating Z in screenspace does not work. In order to be perspective-correct, the interpolation must be done on 1/z. A division is the worst thing you can ask from the P5 FPU since it can take up to 39 cycles on a P5.</p><p>The main optimization here is a huge \"overlap\" where an  is issued for the next 8-pixel span at the very beginning of the current span. While the FPU is doing that division for 30+ cycles, the CPU's integer U and V pipelines draw the current 8 pixels. Many comments mention how the divide is \"in-flight\".  A funny comment from Michael Abrash assesses of the extensive care he put to do other things in the integer pipelines while fdiv is running in the floating-point pipeline.</p><pre> fdiv  %st(1),%st(0) </pre><p>To avoid a mis-prediction on the last part of a span (which may feature less than 8 pixels, a Jump table is used. The code calculates the number of pixels to draw in the span, looks up a memory address in a table, and jumps directly to a label like Entry3_8. Zero mis-prediction possible here.</p><p>There are other tiny optimizations but given how white hot this function is, everything counts. This is the case of clamp. In the C version, it performs two tests, one for \"too high\" and another one for \"below zero\" which is two branches that can result in mis-predictions.  By using  (Jump if Above), an unsigned comparison on signed integers, both high and low conditions are tested at once (if the value is negative, it turns into a very big integer that is above \"too high\"). This is super neat.</p><p> Throughout the ASM code of Quake, there are several mentions where Michael was looking for \"overlap\". This seems to indicate an obsession to find places where the FPU and the integer pipeline could process instructions in parallel.</p><pre> \n  // TODO: any overlap from rearranging?\n\n</pre><p>Like it was the case for R_DrawSurfaceBlock8_mip, Michael Abrash brought up D_DrawSpans in his <i>Graphic Programming Black Book</i> which underlines further how paramount this optimization was at the time.</p><blockquote>\nThe texture-mapping inner loop, which overlaps an FDIV for floating-point perspective correction with integer pixel drawing in 16-pixel bursts, has been squeezed down to 7.5 cycles per pixel on a Pentium, so the combined inner loop times for building and drawing a surface is roughly in the neighborhood of 10 cycles per pixel which is fast enough to do 40 frames/second at 640×400 on a Pentium/100.<div>- Michael Abrash, Chapter 68: Quake’s Lighting Model</div></blockquote><p>If you want to dig deeper, <a href=\"https://fabiensanglard.net/quake_asm_optimizations/objs.zip\">here</a> are the objs resulting from a compilation of Quake with assembly optimizations disabled. The disassembly can easily be extracted with Binary Ninja.</p>","contentLength":21350,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1r5ni65/how_michael_abrash_doubled_quake_framerate/"},{"title":"Show HN: Microgpt is a GPT you can visualize in the browser","url":"https://microgpt.boratto.ca/","date":1771180835,"author":"b44","guid":219,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47026186"},{"title":"Editor's Note: Retraction of article containing fabricated quotations","url":"https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/","date":1771180194,"author":"bikenaga","guid":262,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47026071"},{"title":"What's the best way to control Chrome from Go?","url":"http://github.com/pinchtab/pinchtab","date":1771180072,"author":"/u/Fit_Audience_7470","guid":286,"unread":true,"content":"<p>I built a small HTTP server (~1100 LOC) that wraps chromedp to give AI agents browser control. It works, but I'm wondering if I'm using the right tool for the job.</p><p>•  for CDP communication</p><p>• Raw DOM.resolveNode / Runtime.callFunctionOn for element interaction</p><p>• Accessibility.getFullAXTree for the a11y tree (main interface — cheaper than screenshots for AI)</p><p>• Single sync.Mutex per tab context</p><p>• chromedp's context-per-tab model — managing lifecycles gets messy</p><p>• No built-in way to get the accessibility tree (had to use raw CDP calls)</p><p>• Stealth flags keep getting deprecated by Chrome</p><p><strong>Is chromedp still the best option?</strong> I've looked at:</p><p>• Rod (go-rod/rod) — supposedly simpler API?</p><p>• Calling Playwright via subprocess — feels wrong from Go</p><p>• Direct WebSocket to Chrome DevTools — maximum control but maintaining it yourself</p><p>Anyone using something different? Or is chromedp + raw CDP the way to go?</p>","contentLength":917,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1r5lzmy/whats_the_best_way_to_control_chrome_from_go/"},{"title":"Why does clippy encourage `String::push('a')` over `String::push_str(''a\")`?","url":"https://www.reddit.com/r/rust/comments/1r5lqer/why_does_clippy_encourage_stringpusha_over/","date":1771179485,"author":"/u/MediumInsect7058","guid":350,"unread":true,"content":"<p>One thing that has always been annoying me is clippy telling me to use  instead of <code>String::push_str(s: &amp;str)</code> to append a single character . To me this makes no sense. Why should my program decode a utf-8 codepoint from a 32 bit char instead of just copying over 1-4 bytes from a slice? </p><p>I did some benchmarks and found  to be 5-10% faster for appending a single byte string. </p><p>Not that this matters much but I find clippy here unnecessarily opinionated with no benefit to the program.</p>","contentLength":481,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Choose Between Hindley-Milner and Bidirectional Typing","url":"https://thunderseethe.dev/posts/how-to-choose-between-hm-and-bidir/","date":1771178837,"author":"/u/thunderseethe","guid":343,"unread":true,"content":"<p>This question is common enough you’ve probably heard it posed countless times:\n“Should my new programming language use a Hindley-Milner (HM) type system or a Bidirectional (Bidir) one?”\nWhat’s that?\nI need to understand friends don’t just bring up type inference in casual conversation?</p><p>OK, ouch, fair enough.\nBut…whatever.\nThis is my blog.\nWe’re doing it anyway!\nI don’t know what you expected when you clicked on a programming languages blog.</p><p>Picking a type system is a real barrier for would be language developers.\nEyes full of trepidation as they navigate the labyrinth of nuanced choice that goes into everything a programming language asks of them.\nWhich type system to choose is just another quandary in the quagmire as they trudge towards a working prototype.</p><p>Its understandable they’d want to make a quick decision and return to marching.\nBut this is the wrong question to ask.\nThe question presumes that HM and Bidir are two ends of a spectrum.\nOn one end you have HM with type variables and unification and all that jazz.\nOn the other end you have bidirectional typing where annotations decide your types and little inference is involved.\nThis spectrum, however, is a false dichotomy.</p><p>What folks should actually be asking is “Does my language need generics?”.\nThis question frames the problem around what your language needs, rather than an arbitrary choice between two algorithms of abstract tradeoffs.\nPerhaps more importantly, it determines if you’ll need unification or not.</p><p>Generics, generally, require a type system that supports unification.\nUnification is the process of assigning and solving type variables.\nIf you’ve ever seen Rust infer a type like , that’s unification chugging along.</p><div><div>We don’t have time today. But if you’re interested in how unification works, I have a <a href=\"https://thunderseethe.dev/posts/unification\">tutorial about it\n</a>.</div></div><p>When facing down designing a type system, knowing if you need unification or not decides a lot for you.\nUnification sits center stage in Hindley-Milner.\nWhen you pick HM you pick unification.</p><p>The story is more interesting for bidirectional typing.\nIf you look to the literature, you’ll find plenty of example of bidirectional typing without a unification in sight.\nBy introducing annotations at key locations, you can type check sophisticated programs with no type variables.\nA key insight of bidirectional type is how much you can do without unification.\nAnd don’t get me wrong; it is cool how much it can do.</p><p>But this leads to the incorrect perception that bidir  or  use unification.\nThe opposite couldn’t be more true.\nBidirectional typing supports all the same features as HM typing, and more, forming more of a superset relationship.\nUnification slots into bidirectional typing like a vim user slots into home row.</p><p>This is because bidirectional typechecking is a superset of HM.\nImagine we have some AST (in Rust):</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>And we have a Type we’d like to assign to our AST:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>With an HM system, we provide an  function:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>Wow, just like that we have a real actual HM type system.</p><div><div>Please ignore all the details we’re brushing over.</div></div><p>We can imagine we’re doing all sorts of unification in .\nIf we want to make that system bidirectional, it’s just a matter of adding a  function:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>Technically,  doesn’t even have to do anything.\nA perfectly valid implementation of check would be:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>We infer a type for our AST and check that it’s equal to the expected type.\nThat’s all it takes to be bidirectional.\nHowever, equality is pretty stringent here.\nThe first time we check a type like  against a type like  our entire type inference grinds to a halt.</p><p>Instead, let’s slot unification into the same position.\nRather than requiring strict equality, we can loosen  to require that our types unify:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>With that modest adjustment, we’re bidirectional and we’re unifying.\nNow, of course, once we’ve done that we’re free to make better use of our  whenever we like.\nLet’s say we happen to know our AST has functions:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>And we’re good language developers, so of course that means Type gets a function case as well:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>We return to our check case and notice that, rather than inferring functions, we can take a little shortcut:</p><div><pre tabindex=\"0\"><code data-lang=\"rs\"></code></pre></div><p>But the point is we don’t have to.\nIf you are going to choose a Hindley-Milner type system, you might as well add four lines of code and make it a bidirectional system.\nIts free real estate.</p><p>Okay so you’re sold on bidirectional typing.\nI can see it in your eyes.\nLet’s return to our underlying question “should I support generics or not?”.\nUnification is a daunting task.\nWhen does it make sense and when does it not?</p><p>Unification is great when you don’t want to have to spell out the type of every variable in your program.\nIt’s even wormed it’s way into older language likes Java and C++ because it’s so handy to not have to spell out types.\nEven Go, a diehard in the anti-generics camp, finally capitulated and added generics.\nAnyone aiming to make a general purpose programming language should consider generics a must.\nBut, that’s not every language’s goal.</p><p>A lot of people embark on making a programming language as a learning exercise.\nIn those cases unification can present a bundle of extra complexity that doesn’t really teach you anything about what you want to learn.\nIf you’re interested in learning about type systems, unification is a must.\nBut if you just need some types so you can emit code later, that is a great time to look at bidirectional type systems that don’t use unification and require type annotations.</p><p>Or perhaps your language isn’t general purpose and you’re after a Domain Specific Language perfectly suited to your niche.\nDSLs don’t have to cover all of computation and can eschew generics to reduce surface area and concepts in the language, depending on use case.\nWith the warning that successful DSLs grow up to become general purpose programming languages, looking at you awk, and then you really hurt for the lack of features.</p><p>Regardless of where your aims, the real question you should be asking yourself is “Do I want generics or not?”.\nWhatever your answer, bidirectional typing has got you covered.</p>","contentLength":6124,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1r5lg6n/how_to_choose_between_hindleymilner_and/"},{"title":"Modern CSS Code Snippets: Stop writing CSS like it's 2015","url":"https://modern-css.com/","date":1771178650,"author":"eustoria","guid":261,"unread":true,"content":"<div>, , ; {  { : ; } }          </div>","contentLength":28,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47025851"},{"title":"The next Chrome/Edge releases will credit the ~150 Rust crates they use","url":"https://chromium-review.googlesource.com/c/chromium/src/+/7514149","date":1771177427,"author":"/u/fintelia","guid":351,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1r5ku44/the_next_chromeedge_releases_will_credit_the_150/"},{"title":"Palantir Gets Millions of Dollars from New York City's Public Hospitals","url":"https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/","date":1771177030,"author":"cdrnsf","guid":285,"unread":true,"content":"<p> public hospital system is paying millions to Palantir, the controversial ICE and military contractor, according to documents obtained by The Intercept.</p><p>Since 2023, the New York City Health and Hospitals Corporation has paid Palantir nearly $4 million to improve its ability to track down payment for the services provided at its hospitals and medical clinics. Palantir, a data analysis firm that’s now a Wall Street giant thanks to its lucrative work with the Pentagon and U.S. intelligence community, deploys its software to make more efficient the billing of Medicaid and other public benefits. That includes automated scanning of patient health notes to “Increase charges captured from missed opportunities,” contract materials reviewed by The Intercept show.</p><p>Palantir’s administrative involvement in the business of healing people stands in contrast to its longtime role helping facilitate warfare, <a href=\"https://theintercept.com/2017/03/02/palantir-provides-the-engine-for-donald-trumps-deportation-machine/\">mass deportations</a>, and dragnet surveillance.</p><p>In 2016, <a href=\"https://theintercept.com/2017/02/22/how-peter-thiels-palantir-helped-the-nsa-spy-on-the-whole-world/\">The Intercept revealed</a> Palantir’s role behind XKEYSCORE, a secret NSA bulk surveillance program revealed by the whistleblower Edward Snowden that allowed the U.S. and its allies to search the unfathomably large volumes of data they collect. The company has also attracted global scrutiny and criticism for its “<a href=\"https://www.palantir.com/assets/xrfr7uokpv1b/3MuEeA8MLbLDAyxixTsiIe/9e4a11a7fb058554a8a1e3cd83e31c09/C134184_finaleprint.pdf\">strategic partnership</a>” with the Israeli military while it was leveling Gaza.</p><p>But it’s Palantir’s work with U.S. Immigration and Customs Enforcement that is drawing the most protest today. The company provides a variety of services to help the federal government find and deport immigrants. ICE’s Palantir-furnished case management software, for example, “plays a critical role in supporting the daily operations of ICE, ensuring critical mission success,” according to federal contracting documents.</p><p>“It’s unacceptable that the same company that is targeting our neighbors for deportation and providing tools to the Israeli military is also providing software for our hospitals,” said Kenny Morris, an organizer with the American Friends Service Committee, which shared the contract documents with The Intercept.</p><p>Established by the state legislature, New York City Health and Hospitals is the nation’s biggest municipal health care system, administering over 70 facilities throughout New York City, including Bellevue Hospital, and providing care for over 1 million New Yorkers annually.</p><p>New York City Health and Hospitals spokesperson Adam Shrier did not respond to multiple requests to discuss the contract’s details. Palantir spokesperson Drew Messing said the company does not use or share hospital data outside the bounds of its contract.</p><p>Palantir’s contract with New York’s public health care system allows the company to work with patients’ protected health information, or PHI. With permission from New York City Health and Hospitals, Palantir can “de-identify PHI and utilize de-identified PHI for purposes other than research,” the contract states. De-identification generally involves the stripping of certain revealing information, such as names, Social Security numbers, and birthdays. Such provisions are common in contracts involving health data.</p><p>Activists who oppose Palantir’s involvement in New York point to a large body of research that indicates re-identifying personal data, including in medial contexts, is <a href=\"https://georgetownlawtechreview.org/re-identification-of-anonymized-data/GLTR-04-2017/\">often</a><a href=\"https://techscience.org/a/2017082801/\">trivial</a>.</p><p>“Any contract that shares any of New Yorkers’ highly personal data from NYC Health &amp; Hospital’s with Palantir, a key player in the Trump administration’s mass deportation effort, is reckless and puts countless lives at risk,” said Beth Haroules of the New York Civil Liberties Union. “Every New Yorker, without exception, has a right to quality healthcare and city services. New Yorkers must be able to seek healthcare without fear that their intimate medical information, or immigration status, will be delivered to the federal government on a silver platter.”</p><p>Palantir has long provided similar services to the U.K. National Health Service, a business relationship that today has an increasing number of detractors. Palantir “has absolutely no place in the NHS, looking after patients’ personal data,” Green Party leader Zack Polanski recently stated in a <a href=\"https://www.theguardian.com/politics/2026/feb/05/calls-to-halt-uk-palantir-contracts-grow-amid-lack-of-transparency-over-deals\">letter to the U.K. health secretary</a>.</p><figure><blockquote><p>“Palantir is targeting the exact patients that NYCHH is looking to serve.” </p></blockquote></figure><p>Some New York-based groups feel similarly out of distrust for what the firm could do with troves of sensitive personal data.</p><p>“Palantir is targeting the exact patients that NYCHH is looking to serve,” said Jonathan Westin of the Brooklyn-based organization Climate Organizing Hub. “They should immediately sever their contract with Palantir and stand with the millions of immigrant New Yorkers that are being targeted by ICE in this moment.”</p><p>“The chaos Palantir is inflicting through its technology is not just limited to the kidnapping of our immigrant neighbors and the murder of heroes like our fellow nurse, Alex Pretti,” said Hannah Drummond, an Asheville, North Carolina-based nurse and organizer with National Nurses United, a nursing union. “As a nurse and patient advocate, I don’t want anything having to do with Palantir in my hospital — and neither should any elected leader who claims to represent nurses.”</p><p>Palantir’s vocally right-wing CEO Alex Karp&nbsp;has been a <a href=\"https://www.axios.com/2025/11/08/alex-karp-palantir-democrats-mamdani\">frequent</a> critic <a href=\"https://www.foxbusiness.com/video/6384521232112\">of New York City’s</a> newly inaugurated democratic socialist Mayor Zohran Mamdani. Health and Hospitals operates as a public benefit corporation, but the mayor can exert considerable influence over the network, for instance through the appointment of its board of directors. Its president, Dr. Mitchell Katz, was <a href=\"https://www.nyc.gov/site/ocme/news/cm1025/mayor-elect-mamdani-renominates-nyc-health-hospitals-president-ceo-dr-mitchell-katz-and\">renominated</a> by Mamdani, then the mayor-elect, late last year.</p><p>The mayor’s office did not respond in time for publication when asked about its stance on the contract.</p>","contentLength":5829,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47025624"},{"title":"Oldest Active Linux Distro Slackware Finally Releases Version 15.0","url":"https://linux.slashdot.org/story/26/02/15/0249259/oldest-active-linux-distro-slackware-finally-releases-version-150?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1771176840,"author":"EditorDavid","guid":301,"unread":true,"content":"Created in 1993, Slackware is considered the oldest Linux distro that's still actively maintained. And more than three decades later... there's a new release! (And there's also a Slackware Live Edition that can run from a DVD or USB stick...)\n.\n \n\nSlackware's latest version was released way back in 2016, notes the blog It's FOSS:\n\n\nThe major highlight of Slackware 15 is the addition of the latest Linux Kernel 5.15 LTS. This is a big jump from Linux Kernel 5.10 LTS that we noticed in the beta release. Interestingly, the Slackware team tested hundreds of Linux Kernel versions before settling on Linux Kernel 5.15.19. The release note mentions... \"We finally ended up on kernel version 5.15.19 after Greg Kroah-Hartman confirmed that it would get long-term support until at least October 2023 (and quite probably for longer than that).\" \n\nIn case you are curious, Linux Kernel 5.15 brings in updates like enhanced NTFS driver support and improvements for Intel/AMD processors and Apple's M1 chip. It also adds initial support for Intel 12th gen processors. Overall, with Linux Kernel 5.15 LTS, you should get a good hardware compatibility result for the oldest active Linux distro. \n\n\nSlackware's announcement says \"The challenge this time around was to adopt as much of the good stuff out there as we could without changing the character of the operating system. Keep it familiar, but make it modern.\"\n\n\nAnd boy did we have our work cut out for us. We adopted privileged access management (PAM) finally, as projects we needed dropped support for pure shadow passwords. We switched from ConsoleKit2 to elogind, making it much easier to support software that targets that Other Init System and bringing us up-to-date with the XDG standards. We added support for PipeWire as an alternate to PulseAudio, and for Wayland sessions in addition to X11. Dropped Qt4 and moved entirely to Qt5. Brought in Rust and Python 3. Added many, many new libraries to the system to help support all the various additions. \n\nWe've upgraded to two of the finest desktop environments available today: Xfce 4.16, a fast and lightweight but visually appealing and easy to use desktop environment, and the KDE Plasma 5 graphical workspaces environment, version 5.23.5 (the Plasma 25th Anniversary Edition). This also supports running under Wayland or X11. We still love Sendmail, but have moved it into the /extra directory and made Postfix the default mail handler. The old imapd and ipop3d have been retired and replaced by the much more featureful Dovecot IMAP and POP3 server.\n \n\n\"As usual, the kernel is provided in two flavors, generic and huge,\" according to the release notes. \"The huge kernel contains enough built-in drivers that in most cases an initrd is not needed to boot the system.\" \n\nIf you'd like to support Slackware, there's an official Patreon account.\nAnd the release announcement ends with this personal note:\n\n\nSadly, we lost a couple of good friends during this development cycle and this release is dedicated to them. Erik \"alphageek\" Jan Tromp passed away in 2020 after a long illness... My old friend Brett Person also passed away in 2020. Without Brett, it's possible that there wouldn't be any Slackware as we know it — he's the one who encouraged me to upload it to FTP back in 1993 and served as Slackware's original beta-tester. He was long considered a co-founder of this project. I knew Brett since the days of the Beggar's Banquet BBS in Fargo back in the 1980's... Gonna miss you too, pal. \n\nThanks to long-time Slashdot reader rastos1 for sharing thre news.","contentLength":3576,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LT6502: A 6502-based homebrew laptop","url":"https://github.com/TechPaula/LT6502","date":1771175555,"author":"classichasclass","guid":260,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47025399"},{"title":"EU bans the destruction of unsold apparel, clothing, accessories and footwear","url":"https://environment.ec.europa.eu/news/new-eu-rules-stop-destruction-unsold-clothes-and-shoes-2026-02-09_en","date":1771175418,"author":"giuliomagnifico","guid":259,"unread":true,"content":"<p>The European Commission today (Feb 9) adopted new measures under the Ecodesign for Sustainable Products Regulation (ESPR) to prevent the destruction of unsold apparel, clothing, accessories and footwear.</p><p>The rules will help cut waste, reduce environmental damage and create a level playing field for companies embracing sustainable business models, allowing them to reap the benefits of a more circular economy.</p><p>Every year in Europe, an estimated are destroyed before ever being worn. This waste generates around  of CO2 emissions – almost equal to Sweden’s total net emissions in 2021.</p><p>To help reduce this wasteful practice, the ESPR requires companies to disclose information on the unsold consumer products they discard as waste. It also introduces a ban on the destruction of unsold apparel, clothing accessories and footwear.</p><p>The Delegated and Implementing Acts adopted today will support businesses in complying with these requirements by:</p><ul><li>: The Delegated Act outlines specific and justified circumstances under which the destruction will be permitted, for instance, due to safety reasons or product damage. National authorities will oversee compliance.</li><li> The Implementing Act introduces a standardised format for businesses to disclose the volumes of unsold consumer goods they discard. This applies from February 2027, giving businesses sufficient time to adapt.</li></ul><p>Instead of discarding stock, companies are encouraged to manage their stock more effectively, handle returns, and explore alternatives such as resale, remanufacturing, donations, or reuse.</p><p>The ban on destruction of unsold apparel, clothing accessories and footwear and the derogations will apply to large companies from  Medium-sized companies are expected to follow in 2030. The rules on disclosure under the ESPR  and will also apply to medium-sized companies in 2030.</p><blockquote><p>\"The textile sector is leading the way in the transition to sustainability, but there are still challenges. The numbers on waste show the need to act. With these new measures, the textile sector will be empowered to move towards sustainable and circular practices, and we can boost our competitiveness and reduce our dependencies.\"</p><p><strong>Jessika Roswall, Commissioner for Environment, Water Resilience and a Competitive Circular Economy</strong></p></blockquote><p>The destruction of unsold goods is a wasteful practice. In France alone, around €630 million worth of unsold products are destroyed each year. Online shopping also fuels the issue: in Germany, nearly 20 million returned items are discarded annually.&nbsp;&nbsp;</p><p>Textiles are a major part of the problem, and a key focus for action. To cut waste and reduce the sector’s environmental footprint, the European Commission is promoting more sustainable production while helping European companies stay competitive.&nbsp;</p><p>The ESPR is central to this effort. It will make products on the EU market more durable, reusable and recyclable, while boosting efficiency and circularity.</p>","contentLength":2927,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47025378"},{"title":"Show HN: Knock-Knock.net – Visualizing the bots knocking on my server's door","url":"https://knock-knock.net/","date":1771175185,"author":"djkurlander","guid":218,"unread":true,"content":"<p>Set up an unprotected server on the net, and the bots start swarming!</p><p> This site shows bots attempting (unsuccessfully) to break into an ordinary internet server.</p><p>This constant chatter of bots knocking on the doors of machines on the net has been referred to as <em>\"the background radiation of the Internet\".</em></p><p>Knock-knock.net is a visualization of this bot traffic.\n\t    It shows the bot activity in real-time, and provides historic stats of the bot attacks over time: where they are coming from, the most common usernames and passwords attempted, the worst offending ISPs, and in some cases, why the password or username was chosen.</p><p>Have fun! Send questions or comments to:<a href=\"https://knock-knock.net/#\"></a></p>","contentLength":666,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47025338"},{"title":"Fake Job Recruiters Hid Malware In Developer Coding Challenges","url":"https://it.slashdot.org/story/26/02/15/062259/fake-job-recruiters-hid-malware-in-developer-coding-challenges?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1771173240,"author":"EditorDavid","guid":300,"unread":true,"content":"\"A new variation of the fake recruiter campaign from North Korean threat actors is targeting JavaScript and Python developers with cryptocurrency-related tasks,\" reports the Register.\n\n\nResearchers at software supply-chain security company ReversingLabs say that the threat actor creates fake companies in the blockchain and crypto-trading sectors and publishes job offerings on various platforms, like LinkedIn, Facebook, and Reddit. Developers applying for the job are required to show their skills by running, debugging, and improving a given project. However, the attacker's purpose is to make the applicant run the code... [The campaign involves 192 malicious packages published in the npm and PyPi registries. The packages download a remote access trojan that\ncan exfiltrate files, drop additional payloads, or execute arbitrary commands sent from a command-and-control server.] \n\n\nIn one case highlighted in the ReversingLabs report, a package named 'bigmathutils,' with 10,000 downloads, was benign until it reached version 1.1.0, which introduced malicious payloads. Shortly after, the threat actor removed the package, marking it as deprecated, likely to conceal the activity... The RAT checks whether the MetaMask cryptocurrency extension is installed on the victim's browser, a clear indication of its money-stealing goals... \n\nReversingLabs has found multiple variants written in JavaScript, Python, and VBS, showing an intention to cover all possible targets. \n\nThe campaign has been ongoing since at least May 2025...","contentLength":1532,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hideki Sato, designer of all Sega's consoles, has died","url":"https://www.videogameschronicle.com/news/hideki-sato-designer-of-segas-consoles-dies-age-75/","date":1771172391,"author":"magoghm","guid":258,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47024907"},{"title":"Gwtar: A static efficient single-file HTML format","url":"https://gwern.net/gwtar","date":1771169826,"author":"theblazehen","guid":257,"unread":true,"content":"<div><blockquote><p>Archiving HTML files faces a trilemma: it is easy to create an archival format which is any two of static (self-contained ie. all assets included, no special software or server support), a single file (when stored on disk), and efficient (lazy-loads assets only as necessary to display to a user), but no known format allows all 3 simultaneously.</p><p>We introduce a new format,  (<a href=\"https://gwern.net/doc/cs/algorithm/information/compression/2026-01-23-dbohdan-gpt5imagemini-gwtarlogo-guitar.svg\" data-link-icon=\"image\" data-link-icon-type=\"svg\" data-link-icon-color=\"#ffb338\" data-filesize-bytes=\"4219\" data-filesize-percentage=\"1\" data-image-height=\"1024\" data-image-width=\"1024\" data-aspect-ratio=\"1 / 1\" title=\"Bohdan 2026\">logo</a>; pronounced “guitar”,  extension), which achieves all 3 properties simultaneously. A Gwtar is a classic fully-inlined HTML file, which is then processed into a self-extracting concatenated file of an HTML + JavaScript header followed by a tarball of the original HTML and assets. The HTML header’s JS stops web browsers from loading the rest of the file, loads just the original HTML, and then hooks requests and turns them into range requests into the tarball part of the file.</p><p>Thus, a regular web browser loads what seems to be a normal HTML file, and all assets download only when they need to. In this way, a static HTML page can inline anything—such as gigabyte-size media files—but those will not be downloaded until necessary, even while the server sees just a single large HTML file it serves as normal. And because it is self-contained in this way, it is forwards-compatible: no future user or host of a Gwtar file needs to treat it specially, as all functionality required is old standardized web browser/server functionality.</p><p>Gwtar allows us to easily and reliably archive even the largest HTML pages, while still being user-friendly to read.</p><p>Example pages:  (vs —: 286MB download).</p></blockquote></div><section><p>There are 3 major properties we would like of an HTML archive format, beyond the basics of actually capturing a page in the first place: it should not depend in any way on the original web page, because then it is not an archive and will inevitably break; it should be easy to manage and store, so you can scalably create them and store them for the long run; and it should be efficient, which for HTML largely means that readers should be able to download only the parts they need in order to view the current page.</p></section><section><p>No current format achieves all 3. The built-in web browser save-as-HTML format achieves single and efficient, but not static; save-as-HTML-with-directory achieves static partially and efficient, but not single; <a href=\"https://en.wikipedia.org/wiki/MHTML\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/MHTML#bodyContent\" title=\"MHTML\">MHTML</a>, <a href=\"https://en.wikipedia.org/wiki/Mozilla_Archive_Format\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Mozilla_Archive_Format#bodyContent\" title=\"Mozilla Archive Format\">MAFF</a>, <a href=\"https://github.com/gildas-lormeau/SingleFile/\" data-link-icon=\"github\" data-link-icon-type=\"svg\" title=\"'SingleFile', Lormeau 2026\">SingleFile</a>, &amp; <a href=\"https://gildas-lormeau.github.io/Polyglot-HTML-ZIP-PNG/SUMMARY.html\" title=\"How to Create HTML/ZIP/PNG Polyglot Files\">SingleFileZ</a> (a <a href=\"https://en.wikipedia.org/wiki/ZIP\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/ZIP#bodyContent\" title=\"ZIP\">ZIP</a>-compressed variant) achieve static, single, but not efficiency; <a href=\"https://en.wikipedia.org/wiki/WARC_(file_format)\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/WARC_(file_format)#bodyContent\" title=\"WARC (file format)\">WARCs</a>/<a href=\"https://specs.webrecorder.net/wacz/1.1.1/\" title=\"Web Archive Collection Zipped (WACZ)\">WACZs</a> achieve static and efficient, but not single (because while the WARC is a single file, it relies on a complex software installation like <a href=\"https://webrecorder.net/\" title=\"Webrecorder: Web Archiving for All\">WebRecorder</a>/<a href=\"https://replayweb.page/\" title=\"ReplayWeb.page\">Replay Webpage</a> to display).</p><p>An ordinary ‘save as page HTML’ browser command doesn’t work because “Web Page, HTML Only” leaves out most of a web page; even “Web Page, Complete” is inadequate because a lot of assets are dynamic and only appear when you interact with the page—especially images. If you want a  HTML archive, one which has no dependency on the original web page or domain, you have to use a tool specifically designed for this. I usually use SingleFile. SingleFile produces a static snapshot of the live web page, while making sure that <a href=\"https://en.wikipedia.org/wiki/Lazy_loading\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Lazy_loading#bodyContent\" title=\"Lazy loading\">lazy-loaded</a> images are first loaded, so they are included in the snapshot.</p><p>SingleFile often produces a useful static snapshot. It also achieves another nice property: the snapshot is a , just a simple single  file, which makes life so much easier in terms of organizing and hosting. Want to mirror a web page? SingleFile it, and upload the resulting single file to a convenient directory somewhere, boom—done forever. Being a single file is important on Gwern.net, where I must host so many files, and I run so many lints and checks and automated tools and track metadata etc. and where other people may rehost my archives.</p><p>However, a user of SingleFile quickly runs into a nasty drawback: snapshots can be surprisingly large. In fact, some snapshots on Gwern.net are over half a gigabyte! For example, the homepage for the research project <a href=\"https://gwern.net/doc/www/lllyasviel.github.io/96def0bcd8813bb1389665c487366a2ac61eaf4e.html\" data-url-archive=\"/doc/www/lllyasviel.github.io/96def0bcd8813bb1389665c487366a2ac61eaf4e.html\" data-url-original=\"https://lllyasviel.github.io/pages/paints_undo/\" data-filesize-bytes=\"507833876\" data-filesize-percentage=\"100\" title=\"PaintsUndo: A Base Model of Drawing Behaviors in Digital Paintings\">“PaintsUndo: A Base Model of Drawing Behaviors in Digital Paintings”</a> is 485MB  size optimization, while the raw HTML is 0.6MB. It is common for an ordinary somewhat-fancy Web 2.0 blog post like a <a href=\"https://en.wikipedia.org/wiki/Medium.com\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Medium.com#bodyContent\" title=\"Medium.com\">Medium.com</a> post to be &gt;20MB once fully archived. This is because such web pages wind up importing a lot of <a href=\"https://en.wikipedia.org/wiki/Web_Fonts\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Web_Fonts#bodyContent\" title=\"Web Fonts\">fonts</a>, JS, widgets and icons etc., all of which assets must be saved to ensure it is fully static; and then there is additional wasted space overhead due to <a href=\"https://en.wikipedia.org/wiki/Binary-to-text_encoding\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Binary-to-text_encoding#bodyContent\" title=\"Binary-to-text encoding\">converting</a> assets from their original binary encoding into <a href=\"https://en.wikipedia.org/wiki/Base64\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Base64#bodyContent\" title=\"Base64\">Base64</a> text which can be <a href=\"https://en.wikipedia.org/wiki/Data_URI_scheme\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Data_URI_scheme#bodyContent\" title=\"Data URI scheme\">interleaved with the original HTML</a>.</p><p>This is especially bad because, unlike the original web page, anyone viewing a snapshot  download the . That 500MB web page is possibly OK because a reader only downloads the images that they are looking at; but the archived version must download everything. A web browser has to download the entire page, after all, to display it properly; and there is no lazy-loading or ability to optionally load ‘other’ files—there are no other files ‘elsewhere’, that was the whole point of using SingleFile!</p><p>Hence, a SingleFile archive is static, and a single file, but it is not : viewing it requires downloading unnecessary assets.</p><p>So, for some archives, we ‘split’ or ‘deconstruct’ the static snapshot back into a normal HTML file and a directory of asset files, using <a href=\"https://gwern.net/static/build/deconstruct_singlefile.php\" data-link-icon=\"code\" data-link-icon-type=\"svg\" data-link-icon-color=\"#787cb4\" data-filesize-bytes=\"19434\" data-filesize-percentage=\"4\"><code>deconstruct_singlefile.php</code></a> (which incidentally makes it easy to re-compress all the images, which produces large savings as many websites are surprisingly bad at basic stuff like PNG/JPG/GIF compression); then we are back to a static, efficient, but not single file, archive.</p><p>This is fine for our <a href=\"https://gwern.net/archiving#preemptive-local-archiving\" data-filesize-bytes=\"88086\" data-filesize-percentage=\"56\" title=\"‘Archiving URLs § Preemptive Local Archiving’, Gwern 2011\">auto-generated local archives</a> because they are stored in their own directory tree which is off-limits to most Gwern.net infrastructure (and off-limits to search engines &amp; agents or off-site hotlinking), and it doesn’t matter too much if they litter tens of thousands of directories and files. It is not fine for HTML archives I would like to host as first-class citizens, and expose to Google, and hope people will rehost someday when Gwern.net inevitably dies.</p><p>So, we could either host a regular SingleFile archive, which is static, single, and inefficient; or a deconstructed archive, which is static, multiple, and efficient, but not all 3 properties.</p><p>This issue came to a head in January 2026 when I was archiving the Internet Archive snapshots of Brian Moriarty’s famous lectures <a href=\"https://gwern.net/doc/philosophy/religion/1999-03-17-brianmoriarty-whoburiedpaul.html\" data-link-icon=\"internet-archive\" data-link-icon-type=\"svg\" data-filesize-bytes=\"6394956\" data-filesize-percentage=\"93\" title=\"'Who Buried Paul?', Moriarty 1999\">“Who Buried Paul?”</a> and <a href=\"https://gwern.net/doc/philosophy/religion/2010-02-brianmoriarty-thesecretofpsalm46.html\" data-link-icon=\"internet-archive\" data-link-icon-type=\"svg\" data-filesize-bytes=\"299579672\" data-filesize-percentage=\"100\" title=\"‘The Secret of Psalm 46’, Moriarty 2010\">“The Secret of Psalm 46”</a>, since I noticed while writing <a href=\"https://gwern.net/video-game-art\" data-filesize-bytes=\"19787\" data-filesize-percentage=\"27\" title=\"‘Video Games as Art’, Gwern 2025\">an essay drawing on them</a> that his whole website had sadly gone down. I admire them and wanted to host them properly so people could easily find my fast reliable mirrors (unlike the slow, hard-to-find, unreliable IA versions), but realized I was running into our long-standing dilemma: they would be efficient in the local archive system after being split, but unfindable; or if findable, inefficiently large and reader-unfriendly. Specifically, the video of “Who Buried Paul?” was not a problem because it had been linked as a separate file, so I simply <a href=\"https://gwern.net/doc/philosophy/religion/1999-03-17-brianmoriarty-whoburiedpaul-videolecture.mp4\" data-link-icon=\"file-video\" data-link-icon-type=\"svg\" data-filesize-bytes=\"133173584\" data-filesize-percentage=\"99\" data-image-height=\"244\" data-image-width=\"322\" data-aspect-ratio=\"161 / 122\">converted it to MP4</a> and edited the link; but “The Secret of Psalm 46” turned out to inline the OGG/MP3 recordings of the lecture and abruptly increased from &lt;1MB to .</p><p>I discussed it with <a href=\"https://wiki.obormot.net/\" title=\"Welcome to OborWiki\">Said Achmiz</a>, and he began developing a fix.</p></section><section><p>To achieve all 3, we need some way to download only part of a file, and selectively download the rest. This lets us have a single static archive of potentially arbitrarily large size, which can safely store every asset which might be required.</p><p>HTTP already easily supports selective downloading via the ancient <a href=\"https://en.wikipedia.org/wiki/Byte_serving\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Byte_serving#bodyContent\" title=\"Byte serving\">HTTP Range query feature</a>, which allows one to query for a precise range of bytes inside a URL. This is mostly used to do things like resume downloads, but you can also <a href=\"https://gwern.net/design-graveyard#range-queries\" data-filesize-bytes=\"200493\" data-filesize-percentage=\"73\">do interesting things</a> like run databases in reverse: a web browser client can run a database application locally which reads a database file stored on a server, because Range queries let the client download only the exact parts of the database file it needs at any given moment, as opposed to the entire thing (which might be terabytes in size).</p><p>This is how formats like WARC can render efficiently: host a WARC as a normal file, and then simply range-query the parts displayed at any moment.</p><p>The challenge is the first part: how do we download  the original HTML and subsequently only the displayed assets? If we have a single HTML file and then a separate giant archive file, we could easily just rewrite the HTML using JS to point to the equivalent ranges in the archive file (or do something server-side), but that would achieve only static and efficiency, not single file. If we combine them, like SingleFile, we are back to static and single file, but not efficiency.</p><p>The simplest solution here would be to decide to complicate the server itself and do the equivalent of <code>deconstruct_singlefile.php</code> on the fly. HTML requests, perhaps detecting some magic string in the URL like , is handed to a <a href=\"https://en.wikipedia.org/wiki/Common_Gateway_Interface\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Common_Gateway_Interface#bodyContent\" title=\"Common Gateway Interface\">CGI</a> proxy process, which splits the original single HTML file into a normal HTML file with lazy-loaded references. The client browser sees a normal multiple efficient HTML, while everything on server sees a static single inefficient HTML. (A possible example is <a href=\"https://gwern.net/doc/www/github.com/ff0072519026bd8a7f72adcf3f86a25a1932e14d.html\" data-link-icon=\"github\" data-link-icon-type=\"svg\" data-url-archive=\"/doc/www/github.com/ff0072519026bd8a7f72adcf3f86a25a1932e14d.html\" data-url-original=\"https://github.com/oils-for-unix/wwz\" data-filesize-bytes=\"4157805\" data-filesize-percentage=\"79\" title=\"oils-for-unix/wwz: A WSGI program that serves content out of a zip file (.wwz file). Deploy as CGI or FastCGI\">WWZ</a>.)</p><p>While this solves the immediate Gwern.net problem, it does so at the permanent cost of server complexity, and does not do much to help anyone else. (It is unrealistic to expect more than a handful of people to modify their servers this invasively.) I also considered taking the WARC red pill and going full WebRecorder, but quailed.</p><section><p>How can we trick an HTML file into acting like a <a href=\"https://en.wikipedia.org/wiki/Tar_(computing)\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Tar_(computing)#bodyContent\" title=\"Tar (computing)\">tarball</a> or ZIP file, with partial random access?</p><p>Our initial approach was to ship an HTML + JS header with an appended archive, where the JS would do HTTP Range queries into the appended binary archive; the challenge, however, was to  the file from downloading past the header. To do this, we considered some approaches ‘outside’ the page, like encoding the archive index into the filename/URL itself (ie. ) and requiring the server to parse  out and slice the archive down to just the header, which then handled the range requests; this minimized how much special handling the server did, while being backwards/forwards-compatible with non-compliant servers (who would ignore the index and simply return the entire file, and be no worse than before). This worked in our prototypes, but required at least some server-side support and also required that the header be fixed-length (because any changes would in length would invalidate the index).</p><p>Eventually, Achmiz realized that you  stop downloading from  an HTML page, using the JS command ! <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Window/stop\" data-link-icon=\"FF\" data-link-icon-type=\"text,sans\" data-link-icon-color=\"#e66000\" title=\"'Window: <code>stop()</code> method—Web APIs', MDN 2026\">MDN</a> (<a href=\"https://caniuse.com/mdn-api_window_stop\" data-link-icon=\"CanI\" data-link-icon-type=\"text,sans,quad\" data-link-icon-color=\"#c75000\" title=\"Window API: <code>stop</code>\">&gt;96% support</a>, <a href=\"https://html.spec.whatwg.org/multipage/nav-history-apis.html#dom-window-stop\" title=\"HTML Standard\">spec</a>):</p><blockquote><p>The  stops further resource loading in the current browsing context, equivalent to the stop button in the browser.</p><p>Because of how scripts are executed, this method cannot interrupt its parent document’s loading, but it will stop its images, new windows, and other still-loading objects.</p></blockquote><p>This is precisely what we need, and the design falls into place.</p></section></section><section><p>A Gwtar is an HTML file with a HTML + JS + JSON header followed by a tarball and <a href=\"https://gwern.net/gwtar#optional-trailing-data\">possibly further assets</a>. (A Gwtar could be seen as  a <a href=\"https://en.wikipedia.org/wiki/Polyglot_(computing)\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Polyglot_(computing)#bodyContent\" title=\"Polyglot (computing)\">polyglot file</a> is a file valid as more than one format—in this case, a  file that is also a  archive, and possibly . But strictly speaking, it is not.)</p><section><section><p>The simple approach is to download the binary assets, encode them into Base64 text, and inject them into the HTML DOM. This is inefficient in both compute and RAM because the web browser must immediately reverse this to get a binary to work with. So we actually use the browser optimization of <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Blob\" data-link-icon=\"FF\" data-link-icon-type=\"text,sans\" data-link-icon-color=\"#e66000\" title=\"Blob—Web APIs\">blobs</a> to just pass the binary asset straight to the browser.</p><p>A tricky bit is that inline JS can depend on “previously loaded” JS files, which may not have actually loaded  because the first attempt failed (of course) and the real Range request is still racing. We currently solve this by just downloading all JS before rendering the HTML, at some cost to responsiveness.</p><p>So, a web browser will load a normal web page; the JS will halt its loading; a new page loads, and all of its requests initially fail but get repeated immediately and work the second time; the entire archive never gets downloaded unless required. All assets are provided, there is a single Gwtar file, it is efficient; it doesn’t require JS for archival integrity, as just the entire archive downloads if the JS is not executed; and it is cross-platform and standards-compliant, requires no server-side support or future users/hosts to do anything whatsoever, and is a transparent, self-documenting file format which can be easily converted back to a ‘normal’ multiple-file HTML (<code> foo.gwtar.html  xf </code>)  a user can just re-archive it normally with tools like SingleFile.</p></section></section><section><p>In the event of JS problems, <a href=\"https://gwern.net/static/build/gwtar_noscript.html\" data-link-icon=\"code\" data-link-icon-type=\"svg\" data-filesize-bytes=\"1512\" data-filesize-percentage=\"0\">a  message</a> explains what the Gwtar format is and why it requires JS, and links to this page for more details.</p><p>It also detects whether range requests are supported or downgraded to requesting the entire file. If the latter, it will start rendering it.</p><p>This is not as slow as it seems because we can benefit from connection level compression like <a href=\"https://en.wikipedia.org/wiki/Gzip\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Gzip#bodyContent\" title=\"Gzip\">gzip</a> or <a href=\"https://en.wikipedia.org/wiki/Brotli_compression\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Brotli_compression#bodyContent\" title=\"Brotli compression\">Brotli compression</a>. And because our preprocessing linearize the assets in dependency order, we receive the bytes in order of page appearance, and so in this mode, the “above the fold” images and stuff will still load first and quickly. (This in comparison to the usual SingleFile, where you have to receive every single asset before you’re done, and which may be slower.)</p></section><section><section><p>Strangely, the biggest drawback of Gwtar turns out to be  viewing of HTML archives. SingleFileZ encounters the same issue: in the name of security (<a href=\"https://en.wikipedia.org/wiki/Same-origin_policy\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Same-origin_policy#bodyContent\" title=\"Same-origin policy\">origin</a>/<a href=\"https://en.wikipedia.org/wiki/CORS\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/CORS#bodyContent\" title=\"CORS\">CORS</a>/sandboxing), browsers will not execute certain requests in local HTML pages, so it will break, as it is no longer able to request from itself.</p><p>We regard this as unfortunate, but an acceptable tradeoff, as for local browsing, the file can be easily converted back to the non-JS dependent multiple/single-file HTML formats.</p></section><section><p>Range requests are old, standardized, and important for resuming downloads or viewing large media files like video, and every web server should, in theory, support it by default. In practice, there may be glitches, and one should check.</p><p>An example <a href=\"https://en.wikipedia.org/wiki/CURL\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/CURL#bodyContent\" title=\"CURL\">curl</a> command which should return a HTTP 206 (not 200) request if range requests are correctly working:</p><div><pre><code></code></pre></div><p>Servers  serve Gwtar files as  if possible. This may require some configuration (eg. <a href=\"https://blog.nginx.org/blog/smart-efficient-byte-range-caching-nginx\" title=\"Smart and Efficient Byte-Range Caching with NGINX\">in nginx</a>), but should be straightforward.</p><section><p>However, Cloudflare has an undocumented, hardwired behavior: its proxy (not cache) will strip Range request headers for  responses regardless of cache settings. This does not break Gwtar rendering, of course, but it does break efficiency and defeats the point of Gwtar for Gwern.net</p><p>As a workaround, we serve Gwtars with the MIME type —web browsers like Firefox &amp; Chromium will content-sniff the opening  tag and render correctly, while Cloudflare passes Range requests through for unrecognized types. (This is not ideal, but a more conventional MIME type like  results in web browsers downloading the file without trying to render it at all; and using a MIME type trick is better than alternatives like trying to serve Gwtars as MP4s, using a special-case subdomain just to bypass Cloudflare completely, using complex tools like Service Workers to try to undo the removal, etc.)</p></section></section></section><section><p>Because a Gwtar can store large binary assets without burdening the viewer and is an archive format, it may be useful for reproducible science/statistics: include datasets, such as <a href=\"https://sqlite.org/wasm/doc/trunk/index.md\" data-link-icon=\"txt\" data-link-icon-type=\"svg\" title=\"sqlite3 WebAssembly &amp;amp; JavaScript Documentation Index\">Sqlite3 databases</a>, and do computation on them like visualization or analysis. The question is, how do we ensure that assets get referenced in a way that SingleFile can “see” them and include them inline (to be stored in the final Gwtar as split-out objects), and then addressed and loaded by simple user JS, in a way which still works  Gwtar?</p><p>A potential approach in Gwtar v1 would be to reference all such assets using the <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/object\" data-link-icon=\"FF\" data-link-icon-type=\"text,sans\" data-link-icon-color=\"#e66000\" title=\"'<object>', element—HTML MDN\"> tag</a>, and then the user JS adds a simple listener hook to the  event, which will fire either when the browser loads the asset normally (multi-file) or when Gwtar completes its range-fetch rewrite, and then kicks off the actual userland work. This does not require any unusual or contorted user JS, appears to be backwards/forwards compatible, and to satisfy all our desiderata.</p><div><pre><code></code></pre></div></section><section><p>The appended tarball can itself be followed by additional arbitrary binary assets, which can be large since they will usually not be downloaded. (While the exact format of each appended file is up to the users, it’s a good idea to wrap them in tarballs if you can.)</p><p>This flexibility is intended primarily for allowing ad hoc metadata extensions like <a href=\"https://en.wikipedia.org/wiki/Cryptographic_signatures\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Cryptographic_signatures#bodyContent\" title=\"Cryptographic signatures\">cryptographic signatures</a> or forward error correction (<a href=\"https://en.wikipedia.org/wiki/Error_correction_code\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Error_correction_code#bodyContent\" title=\"Error correction code § Forward error correction\">FEC</a>).</p><section><p>The Gwern.net generation script uses this feature to add <a href=\"https://en.wikipedia.org/wiki/Par2\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Par2#bodyContent\" title=\"Par2\">par2</a> FEC in an additional tarball. This allows recovery of the original Gwtar if it has been partially corrupted or lost. (It cannot recover loss of the file as a whole, which is why FEC is ideally done over large corpuses, and not individual files, but this is better than nothing, and gives us free integrity checking as well.)</p><p>PAR2 can find its FEC data even in corrupted files by scanning for FEC data (“packets”) it recognizes, while tar ignores appended data; so adding, say, 25% par2 FEC is as simple as running <code> foo.gwtar.html  cf.  foo.gwtar.html.par2 foo.gwtar.html.vol.par2  foo.gwtar.html  foo.gwtar.html.par2</code>, and .</p><p>This yields the original  without any FEC. A repaired Gwtar file can then have fresh FEC added to be just like the old Gwtar + FEC archive, or be integrated in some broader system which achieves long-term protection some other way.</p></section><section><p>A simple form of cryptographic signing would be to use GPG to sign it as a normal, separate, signature file (creates ): <code> foo.gwtar.html</code>.</p><p>And we could also append an ASCII ‘armored’ GPG signature, as it won’t confuse tar, like <code> foo.gwtar.html  foo.gwtar.html</code>. Since GPG won’t munge a file like PAR2 will, an adhoc format would be to wrap it in tar to assist extracting:</p><div><pre><code></code></pre></div><p>or in magic text, like a HTML comment:</p><div><pre><code></code></pre></div></section></section></section><section><p>This documentation and the Gwtar code is licensed under the <a href=\"https://creativecommons.org/public-domain/cc0/\" data-link-icon=\"creative-commons\" data-link-icon-type=\"svg\" title=\"‘CC-0: Creative Commons public domain license’, Commons 2002\">CC-0</a><a href=\"https://en.wikipedia.org/wiki/Public_domain\" data-link-icon=\"wikipedia\" data-link-icon-type=\"svg\" data-url-iframe=\"https://en.m.wikipedia.org/wiki/Public_domain#bodyContent\" title=\"Public domain\">public domain</a> copyright license. We are unaware of any software patents.</p></section><section><p>Gwtar v1 could be improved with:</p><ol><li><p>Checking of hashsums when rendering (possibly async or deferred)</p></li><li><p>More aggressive prefetching of assets</p></li><li><p>Integration into SingleFile (possibly as a “SingleFileZ2” forma?)</p></li><li><p>Testing: corpus of edge-case test files (inline SVG, , CSS  chains, web fonts, data URIs in CSS…)</p></li></ol><p>A Gwtar v2 could add breaking changes like:</p><ol><li><p>format provides more rigorous validation/checking of HTML &amp; assets; require HTML &amp; asset validity, assets all decode successfully, etc.</p></li><li><p>standardize appending formats</p></li><li><p>built-in compression with Brotli/gzip for formats not already compressed</p></li><li><p>One would try to replace MAFF’s capability of creating sets of documents which are convenient to link/archive and can automatically share assets for de-duplication (eg. page selected by a built-in widget, or perhaps by a hash-anchor like <code>archive.gwtar.html#page=foo.html</code>? Can an initial web page open new tabs of all the other web pages in the archive?)</p></li><li><p>Better de-duplication, eg. content-addressed asset names (hash-based) enabling deduplication across multiple gwtars</p></li></ol></section>","contentLength":19307,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47024506"},{"title":"What does “config hell” actually look like in the real world?","url":"https://www.reddit.com/r/kubernetes/comments/1r5euc1/what_does_config_hell_actually_look_like_in_the/","date":1771162680,"author":"/u/Real_Alternative_898","guid":322,"unread":true,"content":"<p>I've heard about \"Config Hell\" and have looked into different things like IAM sprawl and YAML drift, but it still feels a little abstract. I'm trying to understand what it looks like in practice.</p><p>I'm looking for war stories on when things blew up, why, what systems broke down, who was at fault.</p><p>Just looking for some examples to ground me. I'd take anything worth reading on it too.</p>","contentLength":381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ring programming language version 1.26 is released!","url":"https://ring-lang.github.io/doc1.26/whatisnew26.html","date":1771160142,"author":"/u/mrpro1a1","guid":342,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1r5dyof/ring_programming_language_version_126_is_released/"},{"title":"Amazon's Ring and Google's Nest reveal the severity of U.S. surveillance state","url":"https://greenwald.substack.com/p/amazons-ring-and-googles-nest-unwittingly","date":1771159337,"author":"mikece","guid":256,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47023238"},{"title":"Vim 9.2 Released","url":"https://developers.slashdot.org/story/26/02/15/0741249/vim-92-released?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1771158840,"author":"EditorDavid","guid":298,"unread":true,"content":"\"More than two years after the last major 9.1 release, the Vim project has announced Vim 9.2,\" reports the blog Linuxiac:\n\n\n\nA big part of this update focuses on improving Vim9 Script as Vim 9.2 adds support for enums, generic functions, and tuple types. \n\nOn top of that, you can now use built-in functions as methods, and class handling includes features like protected constructors with _new(). The :defcompile command has also been improved to fully compile methods, which boosts performance and consistency in Vim9 scripts. \n\nInsert mode completion now includes fuzzy matching, so you get more flexible suggestions without extra plugins. You can also complete words from registers using CTRL-X CTRL-R. New completeopt flags like nosort and nearest give you more control over how matches are shown. Vim 9.2 also makes diff mode better by improving how differences are lined up and shown, especially in complex cases. \n\nPlus on Linux and Unix-like systems, Vim \"now adheres to the XDG Base Directory Specification, using $HOME/.config/vim for user configuration,\" according to the release notes. \n\n\n\nAnd Phoronix Mcites more new features:\n\n\n\nVim 9.2 features \"full support\" for Wayland with its UI and clipboard handling. The Wayland support is considered experimental in this release but it should be in good shape overall... \n\n\n\nVim 9.2 also brings a new vertical tab panel alternative to the horizontal tab line. \n\nThe Microsoft Windows GUI for Vim now also has native dark mode support.\n \n\n\nYou can find the new release on Vim's \"Download\" page.","contentLength":1552,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I built tokio-fsm: proc macro for compile-time validated async state machines","url":"https://www.reddit.com/r/rust/comments/1r5cpml/i_built_tokiofsm_proc_macro_for_compiletime/","date":1771156103,"author":"/u/shree_ee","guid":346,"unread":true,"content":"<p>Tired of writing the same event loop + channel + timeout boilerplate for every stateful async workflow. tokio-fsm discovers states/events from your code and validates transitions at compile time. I am inspired by the work I found myself doing recently and thought there is a gap, plus I love compile-time macros.</p><p>impl Connection { type Context = ConnectionCtx; type Error = std::io::Error;</p><pre><code>#[on(state = Idle, event = Connect)] async fn start(&amp;mut self) -&gt; Transition&lt;Connecting&gt; { Transition::to(Connecting) } #[on(state = Connecting, event = Success)] #[state_timeout(duration = \"30s\")] async fn connected(&amp;mut self) -&gt; Transition&lt;Active&gt; { Transition::to(Active) } </code></pre><p>Invalid transitions = compile errors. Unreachable states = compile errors. Built-in timeouts, channels, background tasks.</p><ul><li>API ergonomics (does <code>#[on(state = X, event = Y)]</code> feel natural?)</li><li>Missing features for real-world usage</li></ul><p>Issues/PRs welcome. Still learning Rust ecosystem best practices.</p>","contentLength":951,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I fixed Windows native development","url":"https://marler8997.github.io/blog/fixed-windows/","date":1771154726,"author":"deevus","guid":255,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47022891"},{"title":"Lunar: a self-hosted Golang+Lua FaaS for personal use.","url":"https://github.com/dimiro1/lunar","date":1771153529,"author":"/u/claudemiro","guid":291,"unread":true,"content":"<p>Last holidays, I wanted to automate a few things and ended up creating Lunar, which is a lightweight faas platform, sqlite backed, and single binary deployment, where functions are written in Lua. </p><p>Let me know what you think, and feel free to contribute to the project; you can find a few ideas listed in the contributions file.</p>","contentLength":327,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1r5c00m/lunar_a_selfhosted_golanglua_faas_for_personal_use/"},{"title":"Salvo vs Axum — why is Axum so much more popular?","url":"https://www.reddit.com/r/rust/comments/1r5bqhy/salvo_vs_axum_why_is_axum_so_much_more_popular/","date":1771152560,"author":"/u/Sensitive-Raccoon155","guid":349,"unread":true,"content":"<p>I’ve been playing with both Salvo and Axum lately, and something I can’t wrap my head around is why Axum is so much more popular.</p><p>From a developer experience point of view, Salvo feels surprisingly complete. A lot of the things I usually need are already there, and I don’t have to think too much about adding extra crates for common backend tasks. With Axum, I often end up assembling the stack myself, which isn’t bad, just different.</p><p>I can’t really figure out why Axum gets so much more attention while Salvo barely comes up in discussions. From what I’ve seen so far, Salvo feels pretty capable and well thought out. Maybe I’m missing something, maybe not.</p><p>What do you all think about this?</p>","contentLength":705,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"new software: liper","url":"https://www.reddit.com/r/linux/comments/1r5b6yn/new_software_liper/","date":1771150583,"author":"/u/prettyoddoz","guid":324,"unread":true,"content":"<p>liper is an application that plays music while you’re at your desktop and stops when an application is open, kind of like a game console would.</p><p>it's pretty simple to use: just clone the repo over at <a href=\"https://codeberg.org/howtoedittv/liper\">https://codeberg.org/howtoedittv/liper</a>, cd into it, and run . make sure you have the  folder made and that you own it.. used to be called dremel</p>","contentLength":344,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I made a noise generator TUI","url":"https://www.reddit.com/r/rust/comments/1r5aluk/i_made_a_noise_generator_tui/","date":1771148379,"author":"/u/Aggressive-Smell-432","guid":348,"unread":true,"content":"<p>I’ve been wanting a TUI for something like this for a long time. I wasn't sure why one didn't exist yet, so I made it myself.</p><p>I tried to keep it minimal, but it can also download more sounds directly using yt-dlp. I think it is pretty much feature-complete now, though I would like to add more default sounds in the future.</p><p>here is a link to the repo</p>","contentLength":350,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Two different tricks for fast LLM inference","url":"https://www.seangoedecke.com/fast-llm-inference/","date":1771147653,"author":"swah","guid":254,"unread":true,"content":"<p><a href=\"https://platform.claude.com/docs/en/build-with-claude/fast-mode\">Anthropic</a> and <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">OpenAI</a> both recently announced “fast mode”: a way to interact with their best coding model at significantly higher speeds.</p><p>These two versions of fast mode are very different. Anthropic’s <a href=\"https://platform.claude.com/docs/en/build-with-claude/fast-mode#how-fast-mode-works\">offers</a> up to 2.5x tokens per second (so around 170, up from Opus 4.6’s 65). OpenAI’s offers more than 1000 tokens per second (up from GPT-5.3-Codex’s 65 tokens per second, so 15x). So OpenAI’s fast mode is six times faster than Anthropic’s.</p><p>However, Anthropic’s big advantage is that they’re serving their actual model. When you use their fast mode, you get real Opus 4.6, while when you use OpenAI’s fast mode you get GPT-5.3-Codex-Spark, not the real GPT-5.3-Codex. Spark is indeed much faster, but is a notably less capable model: good enough for many tasks, but it gets confused and messes up tool calls in ways that vanilla GPT-5.3-Codex would never do.</p><p>Why the differences? The AI labs aren’t advertising the details of how their fast modes work, but I’m pretty confident it’s something like this: <strong>Anthropic’s fast mode is backed by  inference, while OpenAI’s fast mode is backed by special monster Cerebras chips</strong>. Let me unpack that a bit.</p><h3>How Anthropic’s fast mode works</h3><p>The tradeoff at the heart of AI inference economics is , because the main bottleneck is . GPUs are very fast, but moving data onto a GPU is not. Every inference operation requires copying all the tokens of the user’s prompt onto the GPU before inference can start. Batching multiple users up thus increases overall throughput at the cost of making users wait for the batch to be full.</p><p>A good analogy is a bus system. If you had zero batching for passengers - if, whenever someone got on a bus, the bus departed immediately - commutes would be much faster <em>for the people who managed to get on a bus</em>. But obviously overall throughput would be much lower, because people would be waiting at the bus stop for hours until they managed to actually get on one.</p><p>Anthropic’s fast mode offering is basically a bus pass that guarantees that the bus immediately leaves as soon as you get on. It’s six times the cost, because you’re effectively paying for all the other people who could have got on the bus with you, but it’s way faster because you spend  time waiting for the bus to leave.</p><p>edit: I want to thank a reader for emailing me to point out that the “waiting for the bus” cost is really only paid for the first token, so that won’t affect  latency (just latency per turn or tool call). It’s thus better to think of the performance impact of batch size being mainly that smaller batches require fewer flops and thus execute more quickly. In my analogy, maybe it’s “lighter buses drive faster”, or something.</p><p>Obviously I can’t be fully certain this is right. Maybe they have access to some new ultra-fast compute that they’re running this on, or they’re doing some algorithmic trick nobody else has thought of. But I’m pretty sure this is it. Brand new compute or algorithmic tricks would likely require changes to the model (see below for OpenAI’s system), and “six times more expensive for 2.5x faster” is right in the ballpark for the kind of improvement you’d expect when switching to a low-batch-size regime.</p><h3>How OpenAI’s fast mode works</h3><p>OpenAI’s fast mode does not work anything like this. You can tell that simply because they’re introducing a new, worse model for it. There would be absolutely no reason to do that if they were simply tweaking batch sizes. Also, they told us in the announcement <a href=\"https://openai.com/index/introducing-gpt-5-3-codex-spark/\">blog post</a> exactly what’s backing their fast mode: Cerebras.</p><p>OpenAI <a href=\"https://openai.com/index/cerebras-partnership/\">announced</a> their Cerebras partnership a month ago in January. What’s Cerebras? They build “ultra low-latency compute”. What this means in practice is that they build . A H100 chip (fairly close to the frontier of inference chips) is just over a square inch in size. A Cerebras chip is  square inches.</p><p>You can see from pictures that the Cerebras chip has a grid-and-holes pattern all over it. That’s because silicon wafers this big are supposed to be broken into dozens of chips. Instead, Cerebras etches a giant chip over the entire thing.</p><p>The larger the chip, the more internal memory it can have. The idea is to have a chip with SRAM large enough , so inference can happen entirely in-memory. Typically GPU SRAM is measured in the tens of . That means that a lot of inference time is spent streaming portions of the model weights from outside of SRAM into the GPU compute. If you could stream all of that from the (much faster) SRAM, inference would a big speedup: fifteen times faster, as it turns out!</p><p>So how much internal memory does the latest Cerebras chip have? <a href=\"https://arxiv.org/html/2503.11698v1#:~:text=Most%20recently%2C%20the%20Wafer%20Scale,of%2021%20petabytes%20per%20second.\">44GB</a>. This puts OpenAI in kind of an awkward position. 44GB is enough to fit a small model (~20B params at fp16, ~40B params at int8 quantization), but clearly not enough to fit GPT-5.3-Codex. That’s why they’re offering a brand new model, and why the Spark model has a bit of “small model smell” to it: it’s a smaller <a href=\"https://en.wikipedia.org/wiki/Knowledge_distillation\">distil</a> of the much larger GPT-5.3-Codex model.</p><p>edit: I was wrong about this - the Codex model is almost certainly larger than this, and doesn’t need to fit entirely in one chip’s SRAM (if it did, we’d be seeing faster speeds). Thanks to the Hacker News commenters for correcting me. But I think there’s still a good chance that Spark is SRAM-resident (split across a few Cerebras chips) which is what’s driving the speedup.</p><h3>OpenAI’s version is much more technically impressive</h3><p>It’s interesting that the two major labs have two very different approaches to building fast AI inference. If I had to guess at a conspiracy theory, it would go something like this:</p><ul><li>OpenAI partner with Cerebras in mid-January, obviously to work on putting an OpenAI model on a fast Cerebras chip</li><li>Anthropic have no similar play available, but they know OpenAI will announce some kind of blazing-fast inference in February, and they want to have something in the news cycle to compete with that</li><li>Anthropic thus hustles to put together the kind of fast inference they  provide: simply lowering the batch size on their existing inference stack</li><li>Anthropic (probably) waits until a few days before OpenAI are done with their much more complex Cerebras implementation to announce it, so it looks like OpenAI copied them</li></ul><p>Obviously OpenAI’s achievement here is more technically impressive. Getting a model running on Cerebras chips is not trivial, because they’re so weird. Training a 20B or 40B param distil of GPT-5.3-Codex that is still kind-of-good-enough is not trivial. But I commend Anthropic for finding a sneaky way to get ahead of the announcement that will be largely opaque to non-technical people. It reminds me of OpenAI’s mid-2025 sneaky introduction of the Responses API to help them <a href=\"https://www.seangoedecke.com/responses-api\">conceal their reasoning tokens</a>.</p><h3>Is fast AI inference the next big thing?</h3><p>Seeing the two major labs put out this feature might make you think that fast AI inference is the new major goal they’re chasing. I don’t think it is. If my theory above is right, Anthropic don’t care  much about fast inference, they just didn’t want to appear behind OpenAI. And OpenAI are mainly just exploring the capabilities of their new Cerebras partnership. It’s still largely an open question what kind of models can fit on these giant chips, how useful those models will be, and if the economics will make any sense.</p><p>I personally don’t find “fast, less-capable inference” particularly useful. I’ve been playing around with it in Codex and I don’t like it. The usefulness of AI agents is dominated by <em>how few mistakes they make</em>, not by their raw speed. Buying 6x the speed at the cost of 20% more mistakes is a bad bargain, because most of the user’s time is spent handling mistakes instead of waiting for the model.</p><p>However, it’s certainly possible that fast, less-capable inference becomes a core lower-level primitive in AI systems. Claude Code already uses <a href=\"https://github.com/anthropics/claude-code/issues/1098#issuecomment-2884244872\">Haiku</a> for some operations. Maybe OpenAI will end up using Spark in a similar way.</p><p>edit: there are some good comments about this post on <a href=\"https://news.ycombinator.com/item?id=47022329\">Hacker News</a>. First, a good <a href=\"https://news.ycombinator.com/item?id=47022810\">correction</a>: Cerebras offers a ~355B model, GLM-4.7, at 1000 tokens per second already, so I’m wrong about Spark living in a single chip’s SRAM. Presumably they’re sharding Spark across multiple chips, like they’re doing with GLM-4.7.</p><p>Many commenters disagreed with me (and each other) about the performance characteristics of batching. Some <a href=\"https://news.ycombinator.com/item?id=47025656\">said</a> that continuous batching means nobody ever waits for a bus, or that the <a href=\"https://news.ycombinator.com/item?id=47025997\">volume</a> of requests for Anthropic models means batch wait time is negligible. Other users <a href=\"https://news.ycombinator.com/item?id=47023038\">disagreed</a> about whether chip-to-chip communication is a bottleneck at inference time, or whether chaining chips together affects throughput.</p><p>I only have a layman’s understanding of continuous batching, but it seems to me that you still have to wait for a slot to become available (even if you’re not waiting for the entire previous batch to finish), so the batch size throughput/latency tradeoff still applies. Overall, I think the takeaway is that this stuff is really complicated and hard to form a good, simple mental model around. </p>","contentLength":9173,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47022329"},{"title":"Package Management Namespaces","url":"https://nesbitt.io/2026/02/14/package-management-namespaces.html","date":1771145831,"author":"/u/max123246","guid":341,"unread":true,"content":"<p>Every package needs a name. The rules for how those names work is one of the most consequential decisions a package manager makes, and one of the hardest to change later. I <a href=\"https://nesbitt.io/2025/12/29/categorizing-package-registries.html\">categorized the approaches</a> previously and touched on the <a href=\"https://nesbitt.io/2025/12/05/package-manager-tradeoffs.html\">tradeoffs</a> briefly.</p><p>RubyGems, PyPI, crates.io, Hex, Hackage, CRAN, and LuaRocks all use flat namespaces: one global pool of names, first-come-first-served. You pick a name, and if nobody has it, it’s yours.</p><p>This gives you , , . The names are short, memorable, and greppable, with no punctuation to remember and no organization to look up.</p><p>At scale, though, good names run out. Someone registers  on day one and never publishes a real package. Or they publish something, abandon it, and the name sits there forever, pointing at a library last updated in 2013. PyPI has over 600,000 projects. Many of the short, obvious names were claimed years ago by packages with single-digit downloads.</p><p>Name scarcity creates pressure, and you end up with  because  was taken,  because  was the old version, or  because the original  package was abandoned and PyPI doesn’t recycle names. New developers have to learn not just what to install but which of several similar-sounding packages is the right one.</p><p>Flat namespaces also make <a href=\"https://nesbitt.io/2025/12/17/typosquatting-in-package-managers.html\">typosquatting</a> straightforward. Someone registers  next to  and waits. The attack works because there’s nothing between the user’s keystrokes and the registry lookup, no organization to verify and no hierarchy to navigate, just a string match against a flat list.</p><p>Some registries add normalization rules to limit this. PyPI treats hyphens, underscores, and dots as equivalent, so  and  resolve to the same thing. crates.io does similar normalization. RubyGems doesn’t, which is why both  and  can coexist as unrelated packages.</p><p>npm added scopes in 2014. Instead of just , you could publish . Packagist has always used  format: , . JSR, Ansible Galaxy, Puppet Forge, and others follow similar patterns.</p><p>Scopes split the package name into two parts: who published it, and what they called it. Different organizations can use the same package name without collision, so  and  coexist without confusion.</p><p>npm’s implementation is interesting because scopes are optional. You can still publish unscoped packages to the flat namespace. So npm actually has two systems running in parallel: a flat namespace for legacy packages and a scoped namespace for newer ones.</p><p>Most of the ecosystem’s most-used packages (, , ) predate scopes and sit in the flat namespace. Scopes are most common for organizational packages (everything under , for example) and type definitions (). And because so much of the ecosystem depends on unscoped names, npm can never require scopes without breaking the world.</p><p>Packagist required scopes from the start. Every Composer package is , no exceptions. This avoided the split-namespace problem npm has, but it means you need to know the vendor name. Is it  or ? You have to look it up. And vendor names themselves are first-come-first-served, just pushing the squatting problem up one level. The stakes are higher, though, because squatting a vendor name locks out an entire family of package names rather than just one. Someone could register the  vendor on Packagist before Google gets there, and that blocks every  package at once.</p><p>Scopes also require governance. Who decides that  belongs to the Babel team? npm ties scopes to user accounts and organizations, which means you need account management, ownership transfer procedures, and dispute resolution. When a maintainer leaves a project, their scoped packages might need to move. This is solvable but adds operational overhead that flat registries avoid.</p><p>Maven Central uses reverse-domain naming: <code>org.apache.commons:commons-lang3</code>, . The group ID is supposed to correspond to a domain you control.</p><p>The reverse-domain approach ties naming authority to DNS. If you own , you can publish under . This defers governance to the existing DNS system rather than requiring the registry to manage name ownership. Maven Central enforces this by requiring you to prove domain ownership, or for projects without their own domain, to use  as a fallback.</p><p>That fallback is interesting because it quietly undermines the premise: the whole point of reverse-domain naming is that you prove ownership of infrastructure you control, but  just defers to GitHub’s namespace. It’s URL-based naming wearing a reverse-domain costume.</p><p>Organizations with stable domains get clean namespaces out of this. Apache, Google, and Spring all have clear homes. The trade-off is verbose identifiers. <code>org.springframework.boot:spring-boot-starter-web</code> is a lot of characters. IDE autocompletion papers over this in Java, but the verbosity is real when reading build files or discussing dependencies.</p><p>Domain ownership is also less stable than it looks. Companies get acquired and change domains. Open source projects move between hosting organizations. A package published under  in 2005 might need to live under  after the acquisition, except it can’t, because changing the group ID would break every project that depends on the old one. So old names persist as historical artifacts.</p><p>The hierarchy also doesn’t prevent all squatting. Someone could register a domain specifically to claim a Maven namespace. More concerning is domain resurrection: when a domain expires after its owner has already registered a Maven group ID, anyone can buy that domain and potentially claim the namespace. Maven Central <a href=\"https://central.sonatype.org/register/namespace/\">verifies domain ownership</a> when you first register a group ID, requiring a DNS TXT record, but that verification is a point-in-time check.</p><p>In January 2024, security firm Oversecured published <a href=\"https://blog.oversecured.com/Introducing-MavenGate-a-supply-chain-attack-method-for-Java-and-Android-applications/\">MavenGate</a>, an analysis of 33,938 domains associated with Maven group IDs. They found that 6,170 of them, roughly 18%, had expired or were available for purchase. The affected group IDs included widely-used libraries like , , and . A new owner of any of those domains could publish new versions under the existing group ID. Existing artifacts on Maven Central are immutable so old versions wouldn’t change, but build files that pull the latest version would pick up the attacker’s release.</p><p>Sonatype responded by disabling accounts tied to expired domains and tightening their verification process, but they haven’t announced ongoing domain monitoring. PyPI, facing the same problem with account email domains, <a href=\"https://blog.pypi.org/posts/2025-08-18-preventing-domain-resurrections/\">built automated daily checks</a> in 2025 and found around 1,800 accounts to unverify.</p><p>Clojars shows what happens when a registry in the Maven ecosystem takes a different approach. Clojure libraries are distributed as Maven artifacts, but Clojars originally let you use any group ID without verification. You could publish under  or  with no domain proof. This was simpler for the Clojure community, where most libraries are small and maintained by individuals, but it meant Clojars had a much more relaxed namespace than Maven Central.</p><p>Since build tools can pull from both registries, the gap created a dependency confusion risk: an attacker could register an unverified group on Clojars that shadows a legitimate Maven Central library. In 2021, after dependency confusion attacks became widely understood, Clojars <a href=\"https://github.com/clojars/clojars-web/wiki/Verified-Group-Names\">started requiring verified group names</a> for new projects, adopting the same reverse-domain convention as Maven Central. Existing projects with unverified groups were grandfathered in, so the old flat names still exist alongside the new hierarchical ones.</p><p>Go modules use import paths that are URLs: , . There’s no registration step. The URL points to a repository, and the module system fetches code from there (or from the Go module proxy, which caches it).</p><p>This model sidesteps the registry as naming authority entirely. You publish code to a repository and the URL is the identifier, with no approval step required. Name collisions don’t arise because URLs are globally unique by construction, and owning the repo means owning the name.</p><p>Names become tied to hosting infrastructure, though. When  is the package identity, a GitHub org rename breaks every downstream consumer. Go addressed this with the module proxy, which caches modules so they survive repo disappearance, but the name still reflects the original location even if the code has moved. Import paths like  that redirect to  create confusion about which is canonical. And your package identity depends on a third party either way: GitHub controls the  namespace, so if they ban your account or the organization renames, your package identity changes. You’ve traded one governance dependency for another, a hosting platform instead of a registry.</p><p>“No registration step” has its own consequences. Without a registry to mediate names, there’s no obvious place to check for existing packages, no search, no download counts, no centralized vulnerability database. Go built most of these features separately with pkg.go.dev and the module proxy. The URL-based naming stayed, but the surrounding infrastructure converged toward what registries provide anyway, just assembled differently.</p><p>Deno launched with raw URL imports and eventually built <a href=\"https://jsr.io\">JSR</a>, a scoped registry with semver resolution, because URL imports created <a href=\"https://deno.com/blog/http-imports\">problems they couldn’t solve</a> at the URL layer: duplicated dependencies when the same package was imported from slightly different URLs, version management scattered across every import statement, and reliability issues when hosts went offline. You can start without a registry, but the things registries do (search, versioning, deduplication, availability) keep needing to be solved, and solving them piecemeal tends to reconverge on something registry-shaped.</p><p>Apple hired Max Howell to build SwiftPM in 2015. He’d created Homebrew and used both CocoaPods and Carthage heavily, so he arrived with strong opinions about how a language package manager should work. As he told <a href=\"https://changelog.com/podcast/232\">The Changelog</a>: “I’d been involved with CocoaPods and Carthage and used them heavily, and obviously made Homebrew, so I had lots of opinions about how a package manager should be.” He was drawn to decentralization, something he wished Homebrew had from the start.</p><p>Carthage had already demonstrated the approach in the Apple ecosystem, launching in 2014 as a deliberate reaction against CocoaPods’ centralized registry, using bare Git URLs with no registry at all. SwiftPM followed the same path, using Git repository URLs as package identifiers with no central registry.</p><p>Go made the same choice but then spent years building infrastructure around it: a module proxy that caches source in immutable storage so deleted repos still resolve, a checksum database () that uses a transparency log to guarantee every user gets identical content for a given version, and pkg.go.dev for search and discovery.</p><p>SwiftPM doesn’t have any of this yet. Every  clones directly from the Git host. If a repo disappears, resolution fails with no fallback. SwiftPM records a fingerprint per package version the first time it downloads it, but that fingerprint lives on your machine only. There’s no global database to verify that what you downloaded matches what everyone else got, no way to detect a targeted attack serving different content to different users.</p><p>A <a href=\"https://checkmarx.com/blog/chainjacking-the-new-supply-chain-attack/\">2022 Checkmarx study</a> found thousands of packages across Go and Swift vulnerable to repo-jacking, where an attacker registers an abandoned GitHub username and recreates a repo that existing packages still point to. Go’s proxy mitigates this because cached modules don’t re-fetch from the source, but SwiftPM has no such layer.</p><p>The pieces to fix this are partly in place. Apple defined a <a href=\"https://github.com/swiftlang/swift-evolution/blob/main/proposals/0292-package-registry-service.md\">registry protocol</a> (SE-0292, shipped in Swift 5.7) and built client support for it in SwiftPM, including package signing. The client tooling is ready, the protocol is specified, and the ecosystem is still small enough that introducing a namespace layer wouldn’t require the kind of painful migration that npm or PyPI face. The <a href=\"https://swiftpackageindex.com\">Swift Package Index</a>, community-run and Apple-sponsored, already tracks around 12,000 packages. What’s missing is the public registry service itself and the integrity infrastructure around it, and the window for adding these before the ecosystem’s size makes it much harder is not open forever.</p><p>As I wrote about in <a href=\"https://nesbitt.io/2026/01/23/package-management-is-a-wicked-problem.html\">Package Management is a Wicked Problem</a>, once PyPI accepted namespace-less package names, that was permanent. If PyPI added mandatory namespaces tomorrow, every existing , every tutorial, every CI script would need updating. The new system would have to support both namespaced and un-namespaced packages indefinitely. You haven’t replaced the flat namespace, you’ve just added a layer on top of it.</p><p>npm’s experience shows what this looks like in practice. Scoped packages have been available since 2014, but most of the ecosystem still uses flat names. The existence of scopes didn’t make  become  because too much already depends on the existing name. Scopes ended up being used primarily for new packages and organizational groups rather than as a migration path for the existing namespace.</p><p>NuGet went through a partial migration. It added package ID prefix reservation in 2017, letting Microsoft reserve the  prefix. But this is a bolt-on: the underlying namespace is still flat, and the prefixes are just a verified badge on the registry UI. It helps users identify official packages but doesn’t change the naming model.</p><p>PyPI is threading this needle right now with <a href=\"https://peps.python.org/pep-0752/\">PEP 752</a>, which proposes letting organizations reserve package name prefixes. Google could reserve , Apache could reserve <code>apache-airflow-providers-</code>, and future uploads matching those prefixes would require authorization from the namespace owner. Like NuGet’s approach, it requires no installer changes and leaves existing packages unaffected. It only applies going forward, though, and the thousands of existing packages with no organizational prefix remain as they are.</p><p>Cargo and crates.io are attempting something more ambitious. The Rust community has been discussing namespaces since at least 2014, and after several earlier proposals that leaned toward npm-style user or org scopes, they settled on <a href=\"https://rust-lang.github.io/rfcs/3243-packages-as-optional-namespaces.html\">RFC 3243</a> (“Packages as Optional Namespaces”), authored by Manish Goregaokar, who had been working on the problem since at least 2018 when the first “packages as namespaces” pre-RFC appeared.</p><p>The approach treats existing crate names as potential namespace roots: if you own the  crate, you can publish , and only owners of  can create crates in that namespace. Ownership flows down automatically. The  separator was chosen after extensive debate because it aligns with Rust’s existing path syntax, so <code>serde::derive::Deserialize</code> reads naturally in Rust source. An earlier proposal used  but that conflicted with Cargo’s feature syntax.</p><p>The design is carefully scoped. Namespaces are optional, so the flat namespace stays and nothing breaks. It’s framed around projects rather than organizations, with the primary use cases being things like  or  rather than org-level grouping. Only single-level nesting is supported for now. And they explicitly chose not to do NuGet-style prefix reservation because in a flat namespace where  already exists, reserving the  prefix would create confusion about whether existing  crates are actually owned by .</p><p>The migration challenges are real even with this careful design. A crate like  already exists in the flat namespace, and transitioning it to  means a new name that every downstream consumer would need to update. The RFC suggests maintaining re-export crates during transition, but there’s no alias mechanism yet. Some projects face an even harder version of this problem: the  project manages a family of  crates, but someone else owns the  crate, so they can’t use it as their namespace root.</p><p>The RFC was accepted and became an official Rust project goal for 2025, led by Ed Page on the Cargo team. As of late 2025, Cargo support is partially implemented but compiler support is still in progress, requiring coordination across the lang, compiler, and crates.io teams. It’s the most carefully designed attempt at retrofitting namespaces onto a flat registry that I’m aware of, and the fact that it’s taking years of design and implementation work for a well-resourced community with strong governance shows how hard this problem is once a flat namespace is established.</p><p>If you’re starting a registry today, you don’t have to require namespaces from day one, but you could reserve the separator character and the ownership semantics so that namespaces can be added later without conflicting with existing names. The reason crates.io can use  is that no existing crate name contains it. If they’d allowed colons in crate names from the start, this whole approach would have been foreclosed. Keeping your options open costs almost nothing at launch and can save years of design work later.</p>","contentLength":16879,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1r59xjq/package_management_namespaces/"},{"title":"You like typing and you are a fan terminal ? You will love this ? The new version of COUIK is out with new UI and new features","url":"https://www.reddit.com/r/golang/comments/1r59r3c/you_like_typing_and_you_are_a_fan_terminal_you/","date":1771145138,"author":"/u/TemporaryStrong6968","guid":290,"unread":true,"content":"<div><p>- You get a little chart at the end to see how you did over time - Logo configuration - Command palette guide (CTRL + P)</p></div>   submitted by   <a href=\"https://www.reddit.com/user/TemporaryStrong6968\"> /u/TemporaryStrong6968 </a>","contentLength":162,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Oat – Ultra-lightweight, zero dependency, semantic HTML, CSS, JS UI library","url":"https://oat.ink/","date":1771143425,"author":"twapi","guid":253,"unread":true,"content":"<section><h3>Semantic, minimal, zero dependencies. ~8KB CSS and JS.</h3><p>\n    Oat is an ultra-lightweight HTML + CSS, semantic UI component library with zero dependencies.\n    No framework, build, or dev complexity. Just include the tiny CSS and JS files and you are good to go building\n    decent looking web applications with most commonly needed components and elements.\n  </p><p>\n    Semantic tags and attributes are styled contextually out of the box without classes, forcing best practices, and reducing\n    markup class pollution. A few dynamic components are WebComponents and use minimal JavaScript.\n  </p></section><section><article><p> CSS,  JS, minified + gzipped.</p></article><article><p>Fully-standalone with no dependencies on any JS or CSS frameworks or libraries.\n      No Node.js ecosystem garbage or bloat.\n    </p></article><article><p>Native elements like , ,  and\n      semantic attributes like  are styled directly. No classes.</p></article><article><p>Semantic HTML and ARIA roles are used (and forced in many places) throughout.\n      Proper keyboard navigation support for all components and elements.</p></article><article><p>Easily customize the overall theme by overriding a handful of CSS variables.  on body\n      automatically uses the bundled dark theme.</p></article></section><section><p>\n    This was made after the unending frustration with the over-engineered bloat, complexity, and dependency-hell of pretty much every Javascript UI library and framework out there. Done with the continuous PTSD of rug-pulls and lockins of the Node.js ecosystem trash.\n    \n    I've published this, in case other Node.js ecosystem trauma victims find it useful.\n  </p><p>\n    My goal is a simple, minimal, vanilla, standards-based UI library that I can use in my own projects for the long term without having to worry about Javascript ecosystem trash. Long term because it's just simple vanilla CSS and JS.\n    The look and feel are influenced by the shadcn aesthetic.\n  </p></section>","contentLength":1787,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47021980"},{"title":"Migrating From Discord to Stoat on Linux","url":"https://www.reddit.com/r/linux/comments/1r596bh/migrating_from_discord_to_stoat_on_linux/","date":1771143007,"author":"/u/BeyondOk1548","guid":326,"unread":true,"content":"<p>Hello everyone. I wanted to make this post here, since Discord has decided to force age assumptions via facial scan and ID verification upon normal people. I also want to say that I'm not associated with Stoat in any capacity. I'm just a new user and want to make others aware of this.</p><p>First off. Yes, there are other valid alternatives that I'll list as well that I'll list here with an explanation of why it didn't work for me.</p><ol><li><a href=\"https://www.teamspeak.com/en/\">Teamspeak</a>: Thanks but no thanks. Screen sharing and audio for voice is amazing, but it's not the one for me. UI feels scattered and confusing.</li><li><a href=\"https://matrix.org/\">Matrix</a>: Amazing choice. Very clean look, and audio is great. The biggest issue though, is getting normies to use it. It can be a bit confusing if you're looking for something to replace discord. It also feels very corporate. But do not sleep on this.</li><li><a href=\"https://www.whatsapp.com/\">WhatsApp</a>, <a href=\"https://signal.org/\">Signal</a>, <a href=\"https://telegram.org/\">Telegram</a>: Not applicable in my opinion. Extremely different use case. Signal is great. Telegram is alright. Don't use WhatsApp. :)</li></ol><p>I'm not here to judge the software that you use. Use whatever software fits you or your group/use case. I'm only making a post to help \"normies\" get away from discord. Admittedly, not a lot of them are going to be looking here. So please crosspost (if allowed) to help spread the word as much as possible. I also use void btw, so there might be some differences in steps such as file paths, but it should all be the same. If there is an issue, just leave a comment and we'll address it together.</p><p>With all the boilerplate out of the way: here is how you can use stoat on Linux.</p><p>Use the AUR. If you are not sure how to use the AUR, then you'll have to find out how. I will not be telling you here.</p><ol><li>Download the .zip necessary for your instance (if you're not sure whether x86 or arm, just choose x86).</li><li>Once you've downloaded that .zip file, just extract it as you would any .zip, and rename its folder to \"Stoat\" for simplicity.</li><li>Move that new folder you renamed to \"Stoat\" into <code>~/.local/share/applications/</code>.</li><li>In your terminal, run: <code>ls ~/.local/share/applications/Stoat/</code>. <ul><li>If you see output including a file named \"stoat-desktop\", great. You're doing awesome. Keep going.</li></ul></li><li>You'll need to create a desktop entry. So, create a file named \"stoat.desktop\" and open it in your favorite text editor. Follow this template:</li></ol><pre><code>[Desktop Entry] Name=Stoat GenericName=Stoat Exec=\"~/.local/share/applications/share/Stoat/stoat-desktop/\" Type=Application Categories=AudioVideo;Network; Icon=/path/to/icon </code></pre><ul><li>Lastly, we just need to move the  file we created to  so that it can be found by your launcher/menu. I would just recommend by opening the folder in a terminal and using the  command: <code>sudo mv ./stoat.desktop /usr/share/applications</code>.</li></ul><p>Once that is done, you should be done. Enjoy stoat at your leisure. It's going to have a generic icon if you haven't appointed an icon to it. Luckily for you, I've made some simple icons to fix that for you. They're on my GitHub. You're more than welcome to use them. <a href=\"https://github.com/dclmao/stoat-icon/\">https://github.com/dclmao/stoat-icon</a>.</p>","contentLength":2981,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Next Two Years of Software Engineering","url":"https://addyosmani.com/blog/next-two-years/","date":1771142337,"author":"/u/fagnerbrack","guid":345,"unread":true,"content":"<p>The software industry sits at a strange inflection point. AI coding has evolved from autocomplete on steroids to agents that can autonomously execute development tasks. The economic boom that fueled tech’s hiring spree has given way to an efficiency mandate: companies now often favor profitability over growth, experienced hires over fresh graduates, and smaller teams armed with better tools.</p><p>Meanwhile, a new generation of developers is entering the workforce with a different calculus: pragmatic about career stability, skeptical of hustle culture, and raised on AI assistance from day one.</p><p>What happens next is genuinely uncertain. Below are five critical questions that may shape software engineering through 2026, with two contrasting scenarios for each. These aren’t really predictions, but lenses for preparation. The goal is a clear roadmap for handling what comes next, grounded in current data and tempered by the healthy skepticism this community is known for.</p><h2>1. The Junior developer question</h2><p><strong>The bottom line: Junior developer hiring could collapse as AI automates entry-level tasks, or rebound as software spreads into every industry. Both futures require different survival strategies.</strong></p><p>The flip scenario: AI unlocks massive demand for developers across every industry, not just tech. Healthcare, agriculture, manufacturing, and finance all start embedding software and automation. Rather than replacing developers, AI becomes a force multiplier that spreads development work into domains that never employed coders. We’d see more entry-level roles, just different ones: “AI-native” developers who quickly build automations and integrations for specific niches.</p><p>The long-term risk of the pessimistic scenario is often overlooked: today’s juniors are tomorrow’s senior engineers and tech leaders. Cut off the talent pipeline entirely and you create a leadership vacuum in 5-10 years. <a href=\"https://www.finalroundai.com/blog/ai-is-making-it-harder-for-junior-developers-to-get-hired\">Industry veterans call this the “slow decay”</a>: an ecosystem that stops training its replacements.</p><p> Make yourself AI-proficient and versatile. Demonstrate that one junior plus AI can match a small team’s output. Use AI coding agents (Cursor/Antigravity/Claude Code/Gemini CLI) to build bigger features, but understand and explain every line if not most. Focus on skills AI can’t easily replace: communication, problem decomposition, domain knowledge. Look at adjacent roles (QA, DevRel, data analytics) as entry points. Build a portfolio, especially projects integrating AI APIs. Consider apprenticeships, internships, contracting, or open source. Don’t be “just another new grad who needs training”; be an immediately useful engineer who learns quickly.</p><p> Fewer juniors means more grunt work landing on your plate. Lean on automation for routine tasks, but don’t do everything yourself. Set up CI/CD, linters, and AI-assisted testing to catch basic issues. Mentor unofficially through open source or coaching colleagues in other departments. <a href=\"https://www.finalroundai.com/blog/ai-is-making-it-harder-for-junior-developers-to-get-hired\">Be frank with management about the risks of all-senior teams</a>. If junior demand rebounds, be ready to onboard effectively and delegate in ways that use AI. Your value is in multiplying the whole team’s output, not just your own code.</p><p><strong>The bottom line: Core programming skills could atrophy as AI writes most code, or become more critical than ever as human developers focus on oversight. The coming years determine whether we trade understanding for speed.</strong></p><p><a href=\"https://stackoverflow.blog/2025/09/10/ai-vs-gen-z/\">84% of developers now use AI assistance regularly</a>. For many, the first instinct when facing a bug or new feature isn’t to write code from scratch, but to compose a prompt and stitch together AI-generated pieces. Entry-level coders are skipping the “hard way”: they might never build a binary search tree from scratch or debug a memory leak on their own.</p><p>The skillset is shifting from implementing algorithms to knowing how to ask the AI the right questions and verify its output. <a href=\"https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html\">The first rung of the ladder now demands prompting and validating AI</a> rather than demonstrating raw coding ability. Some senior engineers worry this produces a generation who can’t code well independently, a kind of deskilling. AI-generated code introduces subtle bugs and security vulnerabilities that less-experienced developers might miss.</p><p>The counter-scenario: as AI handles the routine 80%, humans focus on the hardest 20%. Architecture, tricky integrations, creative design, edge cases: the problems machines alone can’t solve. Rather than making deep knowledge obsolete, AI’s ubiquity makes human expertise more important than ever. This is the “high-leverage engineer” who uses AI as a force multiplier but must deeply understand the system to wield it effectively.</p><p>If everyone has AI coding agent access, what distinguishes great developers is knowing when the AI is wrong or suboptimal. <a href=\"https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html\">As one senior engineer put it</a>: “The best software engineers won’t be the fastest coders, but those who know when to distrust AI.”</p><p>Developer discourse in 2025 was split. Some admitted they hardly ever write code “by hand” and think coding interviews should evolve. Others argued that skipping fundamentals leads to more firefighting when AI’s output breaks. <a href=\"https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html\">The industry is starting to expect engineers to bring both</a>: AI speed and foundational wisdom for quality.</p><p> Use AI as a learning tool, not a crutch. When AI coding agents (Cursor/Antigravity/Claude Code/Gemini CLI) suggest code review why it works, identify weaknesses. Occasionally disable your AI helper and write key algorithms from scratch. Prioritize CS fundamentals: data structures, algorithms, complexity, memory management. Implement projects twice, once with AI, once without, and compare. Learn prompt engineering and tool mastery. Train yourself in rigorous testing: write unit tests, read stack traces without immediately asking AI, get comfortable with debuggers. Deepen complementary skills AI can’t replicate: system design, user experience intuition, concurrency reasoning. Show you can both crank out solutions with AI and tackle thorny issues when it fails.</p><p> Position yourself as the guardian of quality and complexity. Sharpen your core expertise: architecture, security, scaling, domain knowledge. Practice modeling systems with AI components and think through failure modes. Stay current on vulnerabilities in AI-generated code. Embrace your role as mentor and reviewer: define where AI use is acceptable and where manual review is mandatory (payment or safety code). Lean into creative and strategic work; let the junior+AI combo handle routine API hookups while you decide which APIs to build. Invest in soft skills and cross-domain knowledge. Stay current on new tools and best practices. Double down on what makes a human developer indispensable: sound judgment, system-level thinking, and mentorship.</p><p><strong>The bottom line: The developer role could shrink into limited auditing (overseeing AI-generated code) or expand into a pivotal orchestrator position designing and governing AI-driven systems. Either way, adding value means more than just coding.</strong></p><p>The extremes here are stark. In one vision, developers see their creative responsibilities diminished. Rather than building software, they mostly audit and babysit AI outputs. AI systems (or “citizen developers” using no-code platforms) handle production; human developers review auto-generated code, check for errors, bias, or security issues, and approve deployments. Maker becomes checker. The joy of code creation replaced by the anxiety of risk management.</p><p>There are reports of engineers spending more time evaluating AI-generated pull requests and managing automated pipelines, less time crafting code from scratch. Programming feels less like creative problem-solving and more like compliance. As one engineer lamented: “I don’t want to end up as a code janitor, cleaning up what the AI throws over the wall.”</p><p>The alternative future is far more interesting: developers evolve into high-level orchestrators, combining technical, strategic, and ethical responsibilities. AI “workers” mean human developers take on an architect or general contractor role, designing the overall system, deciding which tasks go to which AI or software component, weaving solutions from many moving parts.</p><p><a href=\"https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html\">A CEO of a low-code platform articulated this vision</a>: in an “agentic” development environment, engineers become “composers,” orchestrating ensembles of AI agents and software services. They won’t write every note themselves, but they define the melody: architecture, interfaces, how agents interact. This role is interdisciplinary and creative: part software engineer, part system architect, part product strategist.</p><p>The optimistic take: as AI handles rote work, developer roles shift toward higher-value activities by necessity. Jobs may become more interesting. Someone has to decide what the AI should build, verify the product makes sense, and continuously improve it.</p><p>Which way it goes may depend on how organizations choose to integrate AI. Companies that see AI as labor replacement might trim dev teams and ask remaining engineers to keep automations running. Companies that see AI as a way to amplify their teams might keep headcounts similar but have each engineer deliver more ambitious projects.</p><p> Seek opportunities beyond just writing code. Volunteer for test case writing, CI pipeline setup, or application monitoring: skills aligned with an auditor/custodian role. Keep your creative coding alive through personal projects so you don’t lose the joy of building. Develop a systems mindset: learn how components communicate, what makes APIs well-designed. Read engineering blogs and case studies of system designs. Familiarize yourself with AI and automation tools beyond code generation: orchestration frameworks, AI APIs. Improve communication skills, written and verbal. Write documentation as if explaining to someone else. Ask senior colleagues not just “Does my code work?” but “Did I consider the right things?” Prepare to be verifier, designer, and communicator, not just coder.</p><p> Lean into leadership and architectural responsibilities. Shape the standards and frameworks that AI and junior team members follow. Define code quality checklists and ethical AI usage policies. Stay current on compliance and security topics for AI-produced software. Focus on system design and integration expertise; volunteer to map data flows across services and identify failure points. Get comfortable with orchestration platforms (Kubernetes, Airflow, serverless frameworks, agent orchestration tools). Double down on your role as technical mentor: more code reviews, design discussions, technical guidelines. Hone your ability to quickly assess someone else’s (or something’s) code and give high-level feedback. Develop product and business sense; understand why features get built and what customers care about. Shadow a product manager or join customer feedback sessions. Protect your creative passion through prototypes, hackathons, or emerging tech research. Evolve from coder to conductor.</p><h2>4. The Specialist vs. Generalist question</h2><p><strong>The bottom line: Narrow specialists risk finding their niche automated or obsolete. The fast-changing, AI-infused landscape rewards T-shaped engineers: broad adaptability with one or two deep skills.</strong></p><p>Given how quickly models, tools and frameworks rise and fall, betting your career on a single technology stack is risky. A guru in a legacy framework might suddenly find themselves in less demand when a new AI tool handles that tech with minimal human intervention. Developers who specialize narrowly in “a single stack, framework or product area” might wake up to find that area declining or redundant.</p><p>Think of COBOL developers, Flash developers, or mobile game engine specialists who didn’t pivot when the industry moved. What’s different now is the pace of change. AI automation can make certain programming tasks trivial, undercutting roles that revolved around those tasks. A specialist who only knows one thing (fine-tuning SQL queries, slicing Photoshop designs into HTML) could find AI handling 90% of that work.</p><p>Hiring managers chase the newest niche. A few years ago everyone wanted cloud infrastructure specialists; now there’s a surge in AI/ML engineers. Those who specialized narrowly in yesterday’s technology feel stalled as that niche loses luster.</p><p>AI tools actually augment generalists more, making it easier for one person to handle multiple components. A back-end engineer can rely on AI help to create a reasonable UI; a front-end specialist can have AI generate server boilerplate. An AI-rich environment lets people operate more broadly. Meanwhile, deep specialists might find their niche partly automated with no easy way to branch out.</p><p> Establish a broad foundation early. Even if hired for a specific role, peek outside that silo. If you’re doing mobile, learn backend basics; if you’re doing front-end, try writing a simple server. Learn the deployment process and tools like Docker or GitHub Actions. Identify one or two areas that genuinely excite you and go deeper: this becomes your vertical expertise. Brand yourself as a hybrid: “full-stack developer with cloud security focus” or “frontend developer with UX expertise.” Use AI tools to learn new domains quickly; when you’re a novice in backend, have ChatGPT generate starter API code and study it. Build the habit of continuous re-skilling. Participate in hackathons or cross-functional projects to force yourself into generalist mode. Tell your manager you want exposure to different parts of the project. Adaptability is a superpower early in your career.</p><p> Map your skill graph: what are you expert in, what related domains have you only touched superficially? Pick one or two adjacent domains and commit to becoming conversant. If you’re a back-end database specialist, get comfortable with a modern front-end framework or learn ML pipeline basics. Do a small project in your weak area with AI assistance. Integrate your deep expertise with new contexts; if you specialize in web app performance, explore how those skills apply to ML inference optimization. Advocate for or design your role to be more cross-functional. Volunteer to be the “integration champion” for projects touching multiple areas. Mentor others to spread skills around while picking up something from them in return. Update your resume to reflect versatility. Use your experience to identify patterns and transferable knowledge. Become the T-shaped role model: deep in your specialty (giving authority and confidence) but actively stretching horizontally.</p><h2>5. The Education question</h2><p><strong>The bottom line: Will a CS degree remain the gold standard, or will faster learning paths (bootcamps, online platforms, employer training) overtake it? Universities may struggle to keep up with an industry that changes every few months.</strong></p><p>A four-year computer science degree has long been the primary ticket into software roles. But that tradition is being questioned.</p><p>One future: universities remain important but struggle to stay relevant. Degrees stay the default credential, but programs lag behind rapidly evolving needs, hampered by slow curriculum update cycles and bureaucratic approval processes. Students and employers feel academia is disconnected from industry, teaching theory or outdated practice that doesn’t translate to job skills.</p><p>Recent grads report never learning about cloud computing, modern DevOps, or AI tooling during their degree. If universities demand high time and financial investment while delivering low-relevance education, they risk being seen as expensive gatekeepers. But many companies still require a bachelor’s degree out of inertia, so the burden shifts to students to fill the gap with bootcamps, online courses, and self-taught projects.</p><p>Bootcamps have matured. They produce grads who get hired at top companies alongside CS grads. These programs are shorter (12-week intensive) and focus on practical skills: current frameworks, cloud services, teamwork. The hiring currency is shifting toward live portfolios, micro-credentials, and verified skills. A strong GitHub portfolio or recognized certification can bypass degree requirements.</p><p>Employer-driven education is emerging: companies creating their own training pipelines or partnering with bootcamps. Some big tech companies have started internal “universities” for non-traditional candidates. AI itself offers new ways to learn: AI tutors, interactive coding sandboxes, personalized instruction outside university settings.</p><p>A modular ecosystem of learning is far more accessible than an expensive four-year degree. A kid in a country without strong CS universities can take the same Coursera courses and build the same portfolio as someone in Silicon Valley.</p><p><em>Aspiring/junior developers:</em> If in a traditional CS program, don’t rely on it exclusively. Augment coursework with real-world projects: build a web app, contribute to open source. Seek internships or co-ops. If your curriculum misses hot topics, learn them through online platforms. Earn industry-recognized certifications (GCP, AWS, Azure) to signal practical knowledge. If self-teaching or in a bootcamp, focus on a compelling portfolio: at least one substantial project with good documentation. Be active in the developer community: contribute to open source, write technical posts. Network through LinkedIn, meetups, dev events. Get an experienced developer to vouch for you. Keep learning continuously; the half-life of technical skills is short. Use AI as your personal tutor. Prove your skills in concrete ways: portfolio, certification, and ability to talk intelligently about your work will open doors.</p><p><em>Senior developers and leaders:</em> Your credential alone won’t carry you forever. Invest in continuous education: online courses, workshops, conferences, certifications. Validate your skills in new ways; be prepared for interviews that assess current competency through real problems. Maintain side projects with new tech. Reassess job requirements: do you really need a new hire to have a CS degree, or do you need certain skills and learning ability? Push for skills-first hiring to widen your talent pool. Support internal training programs or apprenticeship-style roles. Champion mentorship circles for junior devs without formal backgrounds. Engage with academia and alternatives: advisory boards, guest lectures, feedback on curriculum gaps. Reflect this in your own career growth: real-world achievements and continuous learning matter more than additional degrees.</p><p>These scenarios aren’t mutually exclusive. Reality will draw elements from all of them. Some companies will reduce junior hiring while others expand it in new domains. AI will automate routine coding while raising standards for the code humans touch. Developers might spend mornings reviewing AI outputs and afternoons crafting high-level architecture.</p><p>The consistent thread: change is the only constant. By keeping a finger on technology trends (and skepticism around them), you avoid being caught off-guard by hype or doom. By updating skills, diversifying abilities, and focusing on uniquely human aspects (creativity, critical thinking, collaboration) you remain in the loop.</p><p>Whether the future brings a coding renaissance or a world where code writes itself, there will always be demand for engineers who think holistically, learn continuously, and drive technology toward solving real problems.</p><p>The best way to predict the future is to actively engineer it.</p>","contentLength":19570,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1r58zqv/the_next_two_years_of_software_engineering/"},{"title":"CKA Exam Cancelled for “Talking Aloud”, Received Warnings but Wasn’t Speaking","url":"https://www.reddit.com/r/kubernetes/comments/1r58703/cka_exam_cancelled_for_talking_aloud_received/","date":1771139395,"author":"/u/Physical-Section-270","guid":321,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Discord distances from age verification firm after ties to Peter Thiel surface","url":"https://kotaku.com/discord-palantir-peter-thiel-persona-age-verification-2000668951","date":1771135242,"author":"thisislife2","guid":284,"unread":true,"content":"<p><a href=\"https://www.pcgamer.com/hardware/someone-has-already-made-a-free-in-browser-3d-model-to-bypass-discord-age-verification-that-works-on-any-potato-computer/\"></a><a href=\"https://www.theguardian.com/media/2025/oct/09/hack-age-verification-firm-discord-users-id-photos\"></a><a href=\"https://kotaku.com/discord-will-force-you-to-scan-your-face-or-id-to-unlock-all-of-its-features-2000666884\"></a></p><p><a href=\"https://www.pcgamer.com/software/platforms/oh-good-discords-age-verification-rollout-has-ties-to-palantir-co-founder-and-panopticon-architect-peter-thiel/\"></a></p><p><a href=\"https://www.bloomberg.com/news/articles/2021-09-15/founders-fund-values-identity-startup-persona-at-1-5-billion\"></a></p><p><a href=\"https://www.404media.co/elite-the-palantir-app-ice-uses-to-find-neighborhoods-to-raid/\"></a><a href=\"https://www.wired.com/story/epstein-files-tech-elites-gates-thiel-musk/\"></a><a href=\"https://aftermath.site/jeffrey-epstein-files-kotick-thiel-xbox-rockstar/\"></a></p><p><a href=\"https://piunikaweb.com/2026/02/12/discord-uk-age-verification-persona-vendor-shift/\"></a><a href=\"https://www.pcgamer.com/hardware/discord-clarifies-it-is-not-requiring-everyone-to-complete-a-face-scan-or-upload-an-id-and-will-confirm-your-age-group-using-information-we-already-have/\"></a></p><p><a href=\"https://support.discord.com/hc/en-us/articles/30326565624343-How-to-Complete-Age-Assurance-on-Discord\"></a></p>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47021421"},{"title":"Flashpoint Archive – Over 200k web games and animations preserved","url":"https://flashpointarchive.org/","date":1771134239,"author":"helloplanets","guid":283,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47021354"},{"title":"Silverfir-nano: a Rust no_std WebAssembly interpreter hitting ~67% of single-pass JIT","url":"https://www.reddit.com/r/rust/comments/1r552pe/silverfirnano_a_rust_no_std_webassembly/","date":1771128800,"author":"/u/mbbill","guid":347,"unread":true,"content":"<p>I’ve been building Silverfir-nano, a WebAssembly 2.0 interpreter focused on speed + tiny footprint.</p><ul><li>67% of a single-pass JIT (Wasmtime Winch)</li><li>43% of a full-power Cranelift JIT (Wasmer Cranelift)</li></ul><p> // see below</p><p>Edit1: regarding the 200kb size, copy-pasting reply below.</p><p>&gt;you are going to run ahead of time and then generate more optimized handlers based on that</p><p>Not exactly, fusion is mostly based on compiler-generated instruction patterns and workload type, not on one specific app binary. Today, across most real programs, compiler output patterns are very similar, and the built-in fusion set was derived from many different apps, not a single target. That is why the default/built-in fusion already captures about ~90% of the benefit for general code. You can push it a bit further in niche cases, but most users do not need per-app fusion.</p><p>On the benchmark/build question: the headline numbers are from the fusion-enabled configuration, not the ultra-minimal ~200KB build. The ~200KB profile is for maximum size reduction (for example embedded-style constraints), and you should expect roughly ~40% lower performance there (still quite fast tbh, basically wasm3 level).</p><p>Fusion itself is a size/perf knob with diminishing returns: the full fusion set is about ~500KB, but adding only ~100KB can already recover roughly ~80% of the full-fusion performance. The ~1.1MB full binary also includes std due to the WASI support, so if you do not need WASI you can save several hundred KB more.</p><p>So number shouldn't be 200KB but 700KB for maximum performance. thanks for pointing out.</p>","contentLength":1571,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Vim 9.2 Released With Experimental Wayland Support, Better HiDPI Display Support","url":"https://www.phoronix.com/news/Vim-9.2-Released","date":1771119071,"author":"/u/anh0516","guid":327,"unread":true,"content":"<p>Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via <a href=\"https://twitter.com/MichaelLarabel\">Twitter</a>, <a href=\"https://www.linkedin.com/in/michaellarabel/\">LinkedIn</a>, or contacted via <a href=\"https://www.michaellarabel.com/\">MichaelLarabel.com</a>.</p>","contentLength":500,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1r51v41/vim_92_released_with_experimental_wayland_support/"},{"title":"X.Org Server's \"Master\" Branch Now Closed With Cleaned Up State On \"Main\"","url":"https://www.phoronix.com/news/X.Org-Server-On-Main","date":1771118852,"author":"/u/anh0516","guid":328,"unread":true,"content":"<p>Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via <a href=\"https://twitter.com/MichaelLarabel\">Twitter</a>, <a href=\"https://www.linkedin.com/in/michaellarabel/\">LinkedIn</a>, or contacted via <a href=\"https://www.michaellarabel.com/\">MichaelLarabel.com</a>.</p>","contentLength":500,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1r51sgb/xorg_servers_master_branch_now_closed_with/"},{"title":"NewPipe: YouTube client without vertical videos and algorithmic feed","url":"https://newpipe.net/","date":1771118656,"author":"nvader","guid":282,"unread":true,"content":"<p>Hash sum: </p><p>\n                                    Signing key (SHA256 fingerprint):\n                                        <code>CB:84:06:9B:D6:81:16:BA:FA:E5:EE:4E:E5:B0:8A:56:7A:A6:D8:98:40:4E:7C:B1:2F:9E:75:6D:F5:CF:5C:AB</code></p>","contentLength":216,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47020218"},{"title":"I love the work of the ArchWiki maintainers","url":"https://k7r.eu/i-love-the-work-of-the-archwiki-maintainers/","date":1771118458,"author":"panic","guid":281,"unread":true,"content":"<p>For this year's <a href=\"https://ilovefs.org\">\"I love Free Software Day\"</a> I\nwould like to thank the maintainers of Free Software documentation, and\nhere especially the maintainers of the\n<a href=\"https://wiki.archlinux.org/\">ArchWiki</a>. Maintainers in general, and\nmaintainers of documentation most of the time get way too little\nrecognition for their contributions to software freedom.</p><p><em>Myself, Arch Project Leader Levente, ArchWiki maintainer Ferdinand\n(Alad), and FSFE's vice president Heiki at FOSDEM 2026 after I handed\nthem over some hacker chocolate.</em></p><p>The ArchWiki is a resource, I myself and many people around me regularly\nconsult - no matter if it is actually about Arch or another Free Software\ndistribution. There are countless times, when I read articles there to\nget a better understanding of the tools I daily use, like e-mail\nprograms, editors, or all kinds of window managers I used over time. It\nhelped me to discover some handy features or configuration tips that\nwere difficult for me to find in the documentation of the software\nitself.</p><p>Whenever I run into issues setting up a GNU/Linux distribution for\nmyself or family and friends, the ArchWiki had my back!</p><p>Whenever I want to better understand a software, the ArchWiki is most\noften the first page I end up consulting.</p><p><em>You are one of the pearls of the internet!</em> Or in Edward Snowden's\nwords:</p><p>Thank you, to all the ArchWiki contributors for gathering all the\nknowledge to help others in society to better understand technology and for\nthe ArchWiki maintainers to ensure the long term availability and\nreliability of this crucial resource.</p><p>If you also appreciated the work of the ArchWiki maintainers for our\nsociety, tell them as well, and I encourage you to make a <a href=\"https://archlinux.org/donate/\">donation to\nArch</a>.</p><p>PS: Thanks also to Morton for connecting me with Ferdinand and Levente\nat FOSDEM.</p>","contentLength":1757,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47020191"},{"title":"Show HN: Off Grid – Run AI text, image gen, vision offline on your phone","url":"https://github.com/alichherawalla/off-grid-mobile","date":1771108764,"author":"ali_chherawalla","guid":217,"unread":true,"content":"<p>Your phone has a GPU more powerful than most 2018 laptops. Right now it sits idle while you pay monthly subscriptions to run AI on someone else's server, sending your conversations, your photos, your voice to companies whose privacy policy you've never read. Off Grid is an open-source app that puts that hardware to work. Text generation, image generation, vision AI, voice transcription — all running on your phone, all offline, nothing ever uploaded.</p><p>That means you can use AI on a flight with no wifi. In a country with internet censorship. In a hospital where cloud services are a compliance nightmare. Or just because you'd rather not have your journal entries sitting in someone's training data.</p><p>The tech: llama.cpp for text (15-30 tok/s, any GGUF model), Stable Diffusion for images (5-10s on Snapdragon NPU), Whisper for voice, SmolVLM/Qwen3-VL for vision. Hardware-accelerated on both Android (QNN, OpenCL) and iOS (Core ML, ANE, Metal).</p><p>MIT licensed. Android APK on GitHub Releases. Build from source for iOS.</p>","contentLength":1019,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47019133"},{"title":"You can't trust the internet anymore","url":"https://nicole.express/2026/not-my-casual-hobby.html","date":1771098685,"author":"panic","guid":280,"unread":true,"content":"<p>I like things that are strange and a bit obscure. It’s a habit of mine, and a lot of this blog is to document things I haven’t heard of before, because I wanted to learn about them. I mean, jeez, I’m certainly not writing blog posts about <a href=\"https://nicole.express/2026/put-your-clothes-back-on.html\">strip </a><a href=\"https://nicole.express/2026/spooky-ghost-stories.html\">mahjong</a> because the people demand it. But I can’t stop seeing misinformation everywhere, and I have to say something. This post is just a rant.</p><p>This is , a Japanese Sega Genesis game released in 1994 to commemorate the release of  by re-releasing the original. It has an interesting component: it is the Master System game, just packaged into a Genesis cart. The PCB wires the Genesis lines the same way your Power Base Converter would. My guess is the reason for this is because the Master System wasn’t very popular in Japan, and  tied together the whole series with a lot of tiebacks to the first one in particular.</p><p>As a Master System game disguised as a Genesis one, this game is technically interesting. Some Genesis consoles can’t play Master System games, and those ones can’t play this game either. Also, I love the  series; even if 2 is my favorite. This makes this cartridge a perfect subject for my interest, so I’ve talked about it before and will talk about it again. In fact, I have a post I’m working on where I mention it.</p><p>So there I was, writing a blog post, and wanted to look up the release date. The first result I found in DuckDuckGo, my search engine?</p><p>And here’s a thing about me. I want to trust new websites. I have a bias towards clicking on articles from sites I don’t know, because to be quite honest, I’ve read the TCRF page on  a thousand times. How else do you learn something new?</p><p>Also, I clicked it because the headline was “Phantasy Star Fukkokuban: A Classic Reimagined”. Because here’s the thing. It talks about how the graphics were improved:</p><blockquote><p>Phantasy Star Fukkokuban breathes new life into the classic with its updated graphics and sound design. The visual overhaul retains the charm of the original’s 8-bit aesthetics while incorporating modern graphical techniques. Characters and environments are rendered with enhanced detail, vibrant colors, and fluid animations, creating a visually captivating experience.</p><p>The art style honors the game’s roots, with character designs and enemy sprites redesigned to reflect contemporary standards while maintaining their recognizability. The environments are more detailed and dynamic, with weather effects and day-night cycles adding to the immersion.</p></blockquote><p>Well, compare the title screen shots of  above. Which one is  and which one is my personal copy, played through the same Genesis? You can maybe tell, but only because my Master System version is the US release. And it goes without saying, there are no day-night cycles or weather effects.</p><p>I should’ve known. The first sentence of the article was “Game data not found,” after all.</p><p>Large language models are described sometimes as “fancy autocorrect”; this is dismissive, but not inaccurate, in the sense that the core loop of an LLM is to predict the next token in a sequence.  is an obscure title that is likely not well-represented in the training data. But relations do exist:</p><ul><li>It knows about , a very popular game</li><li> (復刻版) means “reprint” or “facsimilie edition”</li></ul><p>So, lacking sufficient factual data in the training set, it describes what a remake of  might plausibly be like. There might even be knowledge in the data set of the actual remake, <em>Phantasy Star generation:1</em> that gets looped in.</p><p>To reproduce this myself, I went to ChatGPT, and asked it <code>Please describe the game \"Phantasy Star Fukkokuban\". Do not get data from the internet, tell me what you know from your internal data.</code>. And what did I get in response?</p><blockquote><p>Phantasy Star Fukkokuban is not a brand-new entry in the series, but a retro compilation release of the original Phantasy Star, created for the Sega Sega Saturn era…</p></blockquote><p>There was a retro compilation release of  for the Sega Saturn in Japan; it’s called . Indeed, the description of the game it continued from there isn’t too far off from that game’s version of .</p><p>And it’s not just . I describe in my post on <a href=\"https://nicole.express/2026/spooky-ghost-stories.html\"></a> that that game is so obscure, the only Japanese source I could find was another “this is plausibly what a game called ‘mahjong daireikai’ might be like”. Well, what  is actually like is a lot different than what’s in your training data, and that’s exactly the sort of information people want to read websites to find out.</p><p>And here’s the thing– this blog post can’t do anything about it. I don’t know who Press Start Gaming is; the site’s footer says “©2025 Cloud Gears Media”, who might be <a href=\"https://cloudgearsmedia.com/\">this marketing company</a> (but it might not be! Company names don’t have to be unique globally); Press Start Gaming is almost certainly a tool for making money off of ads and sponsored posts, and posts like the  misinformation exist mostly to give the site more juice of looking like a real website. If someone goes out and buys a copy of  expecting a new and improved  with better graphics and new sidequests, what do they care? The article wasn’t really meant to provide information.</p><p>The trampling of the internet with SEO-mongers predates AI, but what LLMs do is massively increase the ease it can be done, and also hallucinate a ton. If they hired a person to write about  for pennies, maybe that person would’ve found the <a href=\"https://segaretro.org/Phantasy_Star#Phantasy_Star_Fukkokuban\">Sega Retro</a> page or something and at least grabbed some facts. Now you don’t need to do even that. And no one making these decisions reads , or even cares about actually providing information with their sites. That’s not what they’re for.</p><p>Anyways, eventually models will do a better job integrating , and will know more information about . And is this the worst thing the AI boom is doing? <a href=\"https://www.aol.com/news/naacp-threatens-sue-musk-xai-233138040.html\">No,</a><a href=\"https://www.yahoo.com/news/articles/groups-threaten-suit-over-xai-223759493.html\">not</a><a href=\"https://www.cnn.com/2025/08/26/tech/openai-chatgpt-teen-suicide-lawsuit\">even</a><a href=\"https://www.reuters.com/world/us/americans-fear-ai-permanently-displacing-workers-reutersipsos-poll-finds-2025-08-19/\">close.</a> Even the <a href=\"https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/\">fully automated hit piece</a> against an open-source developer is probably worse than this.</p><p>But it’s a real shame. The commons of the internet are probably already lost, and while I might want to learn new things from new sites, I’ll just have to stick to those with pre-LLM reptuations that I trust. Well, until those sites burn their reputations to make a few extra pennies with AI, like <a href=\"https://mastodon.gamedev.place/@xot/116065688012051690\"></a> seems to just have. (link goes to a Mastodon thread in lieu of a better source for now)</p><p><a href=\"https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/\">Ars Technica</a> has admitted the article had fabricated quotations and has retracted it.</p><p>This post is just a rant. Thanks for listening, at least.</p>","contentLength":6435,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47017727"},{"title":"Descent, ported to the web","url":"https://mrdoob.github.io/three-descent/","date":1771097604,"author":"memalign","guid":279,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47017545"},{"title":"News publishers limit Internet Archive access due to AI scraping concerns","url":"https://www.niemanlab.org/2026/01/news-publishers-limit-internet-archive-access-due-to-ai-scraping-concerns/","date":1771094792,"author":"ninjagoo","guid":278,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47017138"},{"title":"uBlock filter list to hide all YouTube Shorts","url":"https://github.com/i5heu/ublock-hide-yt-shorts/","date":1771090605,"author":"i5heu","guid":277,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47016443"},{"title":"Show HN: Arcmark – macOS bookmark manager that attaches to browser as sidebar","url":"https://github.com/Geek-1001/arcmark","date":1771088124,"author":"ahmed_sulajman","guid":216,"unread":true,"content":"<p>Hey HN! I was a long-time Arc browser user and loved how its sidebar organized tabs and bookmarks into workspaces. I wanted to switch to other browsers without losing that workflow. So I built Arcmark, it's a macOS bookmark manager (Swift/AppKit) that floats as a sidebar attached to any browser window. It uses macOS accessibility API to follow the browser window around.</p><p>You get workspace-based links/bookmarks organization with nested folders, drag-and-drop reordering, and custom workspace colors. For the most part I tried replicating Arc's sidebar UX as close as possible.</p><p>1. Local-first: all data lives in a single JSON file ( ~/Library/Application Support/Arcmark/data.json). No accounts, no cloud sync.</p><p>2. Works with any browser: Chrome, Safari, Brave, Arc, etc. Or use it standalone as a bookmark manager with a regular window.</p><p>3. Import pinned tab and spaces from Arc: it parses Arc's  StorableSidebar.json to recreate the exact workspace/folder structure.</p><p>4. Built with swift-bundler rather than Xcode.</p><p>There's a demo video in the README showing the sidebar attachment in action.\nThe DMG is available on the releases page (macOS 13+), or you can build from source.</p><p>This is v0.1.0 so it's a very early version. Would appreciate any feedback or thoughts</p>","contentLength":1256,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47016058"},{"title":"I struggled with system design until I learned these 114 concepts","url":"https://newsletter.systemdesign.one/p/system-design-core-concepts","date":1771086026,"author":"Neo Kim","guid":39,"unread":true,"content":"<p>Following is the second of a premium 3-part newsletter series… If you’re just getting started with system design or want a super strong foundation, then this newsletter is for you.</p><p>On with part 2 of the newsletter:</p><p>Some of these are foundational, and some are quite advanced. ALL of them are super useful to software engineers building distributed systems…</p><p>Curious to know how many were new to you:</p><ol start=\"39\"><li><p>Block vs File vs Object Storage</p></li><li><p>Clock Synchronization Problem</p></li></ol><p>(…and much more in part 3!)</p><ul><li><p>What it is &amp; how it works--in simple words</p></li></ul><p> is the only AI code review tool that has a deep understanding of your codebase, docs, and past decisions, giving you thoughtful feedback that feels like it came from your best engineer.</p><blockquote><p>WebSockets provide full-duplex, bidirectional communication between client &amp; server over a single, long-lived TCP connection.</p></blockquote><p>Unlike HTTP, where the client always initiates requests, WebSockets allow the server to push data to clients in real-time.</p><p>After an initial HTTP handshake, the connection upgrades to the WebSocket protocol. Both the client and the server can then send messages at any time.</p><p>WebSockets is like a phone call where both people can talk and listen simultaneously…</p><p>Compare this to HTTP, which is like sending letters back and forth,,, where you wait for a reply before sending the next message.</p><p>They’re more complex to implement and scale since each connection consumes server resources. Also, load balancing becomes tricky because connections are long-lived and stateful.</p><p>Plus, some proxies/firewalls “block” WebSocket upgrades or long-lived connections, so compatibility can vary.</p><p>Use for real-time apps like chat systems, live sports scores, collaborative editing, online gaming, or stock trading platforms. But avoid for simple request-response patterns where HTTP is enough.</p><blockquote><p>An API gateway is a server that acts as a SINGLE entry point for all client requests to your microservices.</p></blockquote><p>It handles request routing, composition, and protocol translation. Instead of clients calling different microservices directly, they make ‘one call’ to the gateway.</p><p>An API gateway is like a hotel concierge:</p><p>Instead of guests figuring out which department to call, they call the concierge desk. The concierge knows which department to contact and gets back to the guest with answers.</p><p>They can become a bottleneck or a single point of failure if not deployed redundantly. Besides, they increase latency because of the extra network hop. So the gateway itself needs to scale &amp; be highly available.</p><p>Useful in microservices because it provides clients with a single entry point.</p><p>Also, it handles common tasks like authentication, authorization, and rate limiting in one place, and can return different responses for different clients, such as web or mobile apps.</p><blockquote><p>Distributed cache spreads cached data across many cache servers instead of a single cache instance.</p></blockquote><p>Each cache node stores a portion of the data, typically determined by consistent hashing. Popular implementations include Redis Cluster and Memcached.</p><p>Multiple fast-food locations across a city instead of one central kitchen.</p><p>Each location stores popular items for quick service. Total capacity increases by opening more locations, and no single location becomes overwhelmed during rush hour.</p><p>They add operational complexity (partitioning, rebalancing, replication) and can incur overhead during rebalancing/failover. Also, there’s a risk of cache misses when keys get redistributed.</p><p>Plus, debugging becomes harder with many nodes.</p><p>Use a distributed cache in high-traffic sites when one cache server can’t handle the traffic, when the data no longer fits in one machine’s memory, or when you need high availability.</p><p>Start with a single cache server…Move to a distributed cache setup only when you reach scaling or reliability limits.</p><h2><strong>42. Cache Eviction Policies</strong></h2><blockquote><p>Cache eviction policies decide which data to remove when the cache is full and new data needs space.</p></blockquote><ul><li><p>Least Recently Used () removes the data that has NOT been accessed for the longest time.</p></li><li><p>Least Frequently Used () removes the data that is accessed the least often.</p></li><li><p>First In, First Out () removes the oldest data first, based on when it was added.</p></li><li><p>Time To Live () automatically removes data after a fixed time period.</p></li></ul><p>Think of your phone storage:</p><ul><li><p>LRU deletes photos you haven’t opened in a long time.</p></li><li><p>LFU deletes photos you rarely look at.</p></li><li><p>FIFO deletes the oldest photos first.</p></li><li><p>TTL is like a message that automatically disappears after 24 hours.</p></li></ul><p>Different policies work well for different access patterns…</p><ul><li><p>LRU works well when recently accessed data is likely to be used again. Yet it can perform poorly if large amounts of data are accessed only once.</p></li><li><p>LFU works well when frequently accessed data stays popular over time, but it reacts slowly if usage patterns change.</p></li><li><p>FIFO is simple but does not consider how often or recently data is used.</p></li><li><p>TTL ensures data does not stay in the cache forever, but it may remove useful data too early or keep stale data too long.</p></li></ul><p>Each policy has overhead in tracking metadata for eviction decisions.</p><ul><li><p>LRU for general-purpose caching where recent data is likely to be reused.</p></li><li><p>LFU when certain data remains popular for long periods.</p></li><li><p>TTL when data naturally becomes stale after some time, such as API responses or session data.</p></li></ul><p>Most systems combine TTL with LRU or LFU.</p><h2><strong>43. Proxy vs Reverse Proxy</strong></h2><blockquote><p>A forward proxy sits between clients and the Internet. It sends requests to external servers on behalf of the client.</p><p>A reverse proxy sits in front of your servers. It receives requests from clients and forwards them to the correct backend server.</p></blockquote><p>With a forward proxy, client is configured to use it. With a reverse proxy, the client usually doesn’t know it exists.</p><p>A forward proxy is like an assistant who makes calls for you, so the person on the other end doesn’t talk with you directly.</p><p>A reverse proxy is like a company receptionist. Callers think they are contacting the company directly,,, but the receptionist routes the call internally.</p><p>Forward proxies can improve privacy, enforce security policies, and filter traffic. Yet they add extra network hops and can increase latency.</p><p>Reverse proxies provide load balancing, SSL termination, caching, and protection from direct exposure of backend servers. But they must be deployed redundantly to avoid becoming a single point of failure.</p><p>Both require proper configuration to prevent security risks…</p><ul><li><p>Use forward proxies in corporate networks for content filtering, monitoring &amp; privacy control.</p></li><li><p>Use reverse proxies in production systems for load balancing, SSL termination, traffic routing, and protection against attacks.</p></li></ul><p>Most apps use reverse proxies such as Nginx, HAProxy, or cloud load balancers.</p><blockquote><p>Hypertext Transfer Protocol (HTTP) sends data in ‘plain text’.</p><p>Hypertext Transfer Protocol Secure (HTTPS) is HTTP encrypted using Transport Layer Security (TLS).</p></blockquote><p>HTTPS encrypts communication between the client and server, protecting data from eavesdropping and tampering. The server provides a certificate to prove its identity. Modern browsers mark HTTP sites as “Not Secure.”</p><p>HTTP is like sending a postcard. Anyone who intercepts it can read the message.</p><p>HTTPS is like sending a sealed, locked box. Even if someone intercepts it, they cannot read or change what’s inside.</p><p>HTTPS requires managing digital certificates and adds a small performance cost because of the TLS handshake. Yet these costs are minimal compared to the security benefits.</p><p>HTTPS protects against eavesdropping and man-in-the-middle attacks, where attackers intercept or modify traffic.</p><p>HTTPS is also a positive ranking factor for search engines and is required for many modern web features, such as HTTP/2, service workers, and secure cookies.</p><blockquote><p>Transmission Control Protocol (TCP) is a connection-oriented protocol that provides reliable, ordered delivery of data.</p><p>User Datagram Protocol (UDP) is connectionless and sends packets without guaranteeing delivery, order, or protection against duplication.</p></blockquote><p>TCP establishes a connection using a handshake, retransmits lost packets, and performs congestion control.</p><p>UDP sends packets independently with minimal overhead &amp; no built-in reliability. i.e., UDP is faster but less reliable.</p><p>TCP is like certified mail with tracking and delivery confirmation.</p><p>UDP is like sending postcards. They usually arrive, but they might be lost or arrive out of order…</p><p>TCP adds latency due to the handshake, acknowledgments, retransmissions, and head-of-line blocking (where a lost packet delays subsequent packets).</p><p>UDP doesn’t guarantee delivery or order. If reliability is needed,,, the application code must handle it.</p><ul><li><p>Use TCP for web browsing, email, file transfers, database connections, and APIs where accuracy matters more than speed.</p></li><li><p>Use UDP for real-time applications such as video calls, live streaming, and online gaming, where low latency is more important than reliability.</p></li></ul><p>NOTE: DNS typically uses UDP for speed, but it can fall back to TCP for large responses or specific operations.</p><p><em><strong>Reminder: this is a teaser of the subscriber-only post, exclusive to my golden members.</strong></em></p><p>When you upgrade, you’ll get:</p><ul><li><p><strong>Full access to system design case studies</strong></p></li><li><p>FREE access to (coming) Design, Build, Scale newsletter series</p></li><li><p><strong>FREE access to (coming) popular interview question breakdowns</strong></p></li></ul><p>Get 10x the results you currently get with 1/10th the time, energy &amp; effort.</p>","contentLength":9359,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/e9e8cf9a-93be-4a9c-9512-1d9cdb098857_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"Platforms bend over backward to help DHS censor ICE critics, advocates say","url":"https://arstechnica.com/tech-policy/2026/02/platforms-bend-over-backward-to-help-dhs-censor-ice-critics-advocates-say/","date":1771084196,"author":"pjmlp","guid":276,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47015406"},{"title":"Vim 9.2","url":"https://www.vim.org/vim-9.2-released.php","date":1771083583,"author":"tapanjk","guid":275,"unread":true,"content":"<p>The Vim project is happy to announce that Vim 9.2 has been released.</p><p>Vim 9.2 brings significant enhancements to the Vim9 scripting language, improved diff mode, comprehensive completion features, and platform-specific improvements including experimental Wayland support.</p><ul><li><strong>Comprehensive Completion:</strong> Added support for  during insert-mode completion and the ability to complete words directly from  (). New  flags like  and  offer finer control over how matches are displayed and ordered.</li><li> Full support for the  UI and clipboard has been added. On Linux and Unix-like systems, Vim now adheres to the <strong>XDG Base Directory Specification</strong>, using  for user configuration.</li><li> A new  provides an alternative to the horizontal tabline. The  GUI now supports native dark mode for the menu and title bars, along with improved fullscreen support and higher-quality toolbar icons.</li><li> A new built-in  (started via ) provides a modernized learning experience beyond the traditional vimtutor.</li></ul><p>Significant language enhancements including native support for , , and the  data type. Built-in functions are now integrated as , and classes now support protected  methods and  for full method compilation.</p><div><h2>Vim9 Script Ecosystem &amp; AI Integration</h2><p>The maturity of Vim9 script's modern constructs is now being leveraged by advanced AI development tools. Contributor Yegappan Lakshmanan recently demonstrated the efficacy of these new features through two projects generated using GitHub Copilot:</p><ul><li> A complete implementation of the classic game, showcasing classes and type aliases. [<a href=\"https://github.com/yegappan/battleship.git\">GitHub</a>]</li><li> A logic game demonstrating the efficiency of modern Vim9 for interactive plugins. [<a href=\"https://github.com/yegappan/number-puzzle\">GitHub</a>]</li></ul></div><p>Vim 9.2 introduces significant enhancements to how changes are visualized and aligned in diff mode:</p><ul><li> Includes the \"linematch\" algorithm for the  setting. This aligns changes between buffers on similar lines, greatly improving diff highlighting accuracy.</li><li> The new  option allows you to specify anchor points (comma-separated addresses) to split and independently diff buffer sections, ensuring better alignment in complex files.</li><li> Improves highlighting for changes within a line. This is configurable via the  sub-option for . Note that  has been added to the default  value.</li></ul>\n    Here are some examples for the improved inline highlighting:\n    <p>Several long-standing defaults have been updated to better suit modern hardware and workflows. These values have been removed from  as they are now the internal defaults.</p><table><thead><tr></tr></thead><tbody><tr><td> (More undo/command history saved)</td></tr><tr><td> (Normal backspace behavior)</td></tr><tr><td><strong>\"internal,filler,closeoff,indent-heuristic,inline:char\"</strong></td></tr><tr><td> (Optimized for High-DPI monitors)</td></tr><tr><td> (Always visible in non-compatible mode)</td></tr><tr><td> (Shows cursor position by default)</td></tr></tbody></table><h2>Completion Feature Examples</h2><p>These examples demonstrate how to use the powerful new completion and introspection tools available in Vim 9.2.</p><div><p>Vim's standard completion frequently checks for user input while searching for new matches. It is responsive irrespective of file size. This makes it well-suited for smooth auto-completion.</p><pre><code>vim9script\ndef InsComplete()\n    if getcharstr(1) == '' &amp;&amp; getline('.')-&gt;strpart(0, col('.') - 1) =~ '\\k$'\n        SkipTextChangedIEvent()\n        feedkeys(\"\\&lt;c-n&gt;\", \"n\")\n    endif\nenddef\n\ndef SkipTextChangedIEvent(): string\n    # Suppress next event caused by &lt;c-e&gt; (or &lt;c-n&gt; when no matches found)\n    set eventignore+=TextChangedI\n    timer_start(1, (_) =&gt; {\n        set eventignore-=TextChangedI\n    })\n    return ''\nenddef\n\nset cot=menuone,popup,noselect inf\n\nautocmd TextChangedI * InsComplete()\n\ninoremap &lt;silent&gt; &lt;c-e&gt; &lt;c-r&gt;=&lt;SID&gt;SkipTextChangedIEvent()&lt;cr&gt;&lt;c-e&gt;\n</code></pre><h3>2. Live grep, fuzzy find file, fuzzy find buffer</h3><pre><code>vim9script\n\nvar selected_match = null_string\nvar allfiles: list&lt;string&gt;\n\ndef GrepComplete(arglead: string, cmdline: string, cursorpos: number): list&lt;any&gt;\n    return arglead-&gt;len() &gt; 1 ? systemlist($'grep -REIHns \"{arglead}\"' ..\n       ' --exclude-dir=.git --exclude=\".*\" --exclude=\"tags\" --exclude=\"*.swp\"') : []\nenddef\n\ndef VisitFile()\n    if (selected_match != null_string)\n        var qfitem = getqflist({lines: [selected_match]}).items[0]\n        if qfitem-&gt;has_key('bufnr') &amp;&amp; qfitem.lnum &gt; 0\n            var pos = qfitem.vcol &gt; 0 ? 'setcharpos' : 'setpos'\n            exec $':b +call\\ {pos}(\".\",\\ [0,\\ {qfitem.lnum},\\ {qfitem.col},\\ 0]) {qfitem.bufnr}'\n            setbufvar(qfitem.bufnr, '&amp;buflisted', 1)\n        endif\n    endif\nenddef\n\ndef FuzzyFind(arglead: string, _: string, _: number): list&lt;string&gt;\n    if allfiles == null_list\n        allfiles = systemlist($'find {get(g:, \"fzfind_root\", \".\")} \\!\n                   \\( -path \"*/.git\" -prune -o -name \"*.swp\" \\) -type f -follow')\n    endif\n    return arglead == '' ? allfiles : allfiles-&gt;matchfuzzy(arglead)\nenddef\n\ndef FuzzyBuffer(arglead: string, _: string, _: number): list&lt;string&gt;\n    var bufs = execute('buffers', 'silent!')-&gt;split(\"\\n\")\n    var altbuf = bufs-&gt;indexof((_, v) =&gt; v =~ '^\\s*\\d\\+\\s\\+#')\n    if altbuf != -1\n        [bufs[0], bufs[altbuf]] = [bufs[altbuf], bufs[0]]\n    endif\n    return arglead == '' ? bufs : bufs-&gt;matchfuzzy(arglead)\nenddef\n\ndef SelectItem()\n    selected_match = ''\n    if getcmdline() =~ '^\\s*\\%(Grep\\|Find\\|Buffer\\)\\s'\n        var info = cmdcomplete_info()\n        if info != {} &amp;&amp; info.pum_visible &amp;&amp; !info.matches-&gt;empty()\n            selected_match = info.selected != -1 ? info.matches[info.selected] : info.matches[0]\n            setcmdline(info.cmdline_orig) # Preserve search pattern in history\n        endif\n    endif\nenddef\n\ncommand! -nargs=+ -complete=customlist,GrepComplete Grep VisitFile()\ncommand! -nargs=* -complete=customlist,FuzzyBuffer Buffer exe 'b ' .. selected_match-&gt;matchstr('\\d\\+')\ncommand! -nargs=* -complete=customlist,FuzzyFind Find exe !empty(selected_match) ? $'e {selected_match}' : ''\n\nnnoremap &lt;leader&gt;g :Grep&lt;space&gt;\nnnoremap &lt;leader&gt;G :Grep &lt;c-r&gt;=expand(\"&lt;cword&gt;\")&lt;cr&gt;\n\nnnoremap &lt;leader&gt;&lt;space&gt; :&lt;c-r&gt;=execute('let fzfind_root=\".\"')\\|''&lt;cr&gt;Find&lt;space&gt;&lt;c-@&gt;\nnnoremap &lt;leader&gt;fv :&lt;c-r&gt;=execute('let fzfind_root=\"$HOME/.vim\"')\\|''&lt;cr&gt;Find&lt;space&gt;&lt;c-@&gt;\nnnoremap &lt;leader&gt;fV :&lt;c-r&gt;=execute('let fzfind_root=\"$VIMRUNTIME\"')\\|''&lt;cr&gt;Find&lt;space&gt;&lt;c-@&gt;\nnnoremap &lt;leader&gt;&lt;bs&gt; :Buffer &lt;c-@&gt;\n\nautocmd CmdlineEnter : allfiles = null_list\nautocmd CmdlineLeavePre : SelectItem()</code></pre><pre><code>vim9script\n\ndef CmdComplete()\n    var [cmdline, curpos] = [getcmdline(), getcmdpos()]\n    if getchar(1, {number: true}) == 0  # Typehead is empty\n            &amp;&amp; !pumvisible() &amp;&amp; curpos == cmdline-&gt;len() + 1\n            &amp;&amp; cmdline =~ '\\%(\\w\\|[*/:.-]\\)$' &amp;&amp; cmdline !~ '^\\d\\+$'\n        feedkeys(\"\\&lt;C-@&gt;\", \"ti\")\n        SkipCmdlineChanged()\n        timer_start(0, (_) =&gt; getcmdline()-&gt;substitute('\\%x00', '', 'g')-&gt;setcmdline())\n    endif\nenddef\n\ndef SkipCmdlineChanged(key = ''): string\n    set ei+=CmdlineChanged\n    timer_start(0, (_) =&gt; execute('set ei-=CmdlineChanged'))\n    return key != '' ? ((pumvisible() ? \"\\&lt;c-e&gt;\" : '') .. key) : ''\nenddef\n\nset wim=noselect:lastused,full wop=pum wcm=&lt;C-@&gt; wmnu\n\nautocmd CmdlineChanged : CmdComplete()\nautocmd CmdlineEnter : set bo+=error\nautocmd CmdlineLeave : set bo-=error\n\ncnoremap &lt;expr&gt; &lt;up&gt; SkipCmdlineChanged(\"\\&lt;up&gt;\")\ncnoremap &lt;expr&gt; &lt;down&gt; SkipCmdlineChanged(\"\\&lt;down&gt;\")\n</code></pre><h3>Optional: Autocompletion (Popup Menu)</h3><p>For automatic popup menu completion as you type in search or  commands, include this in your :</p><pre><code>vim9script\ndef CmdComplete()\n  var [cmdline, curpos, cmdmode] = [getcmdline(), getcmdpos(), expand('&lt;afile&gt;') == ':']\n  var trigger_char = '\\%(\\w\\|[*/:.-]\\)$'\n  var not_trigger_char = '^\\%(\\d\\|,\\|+\\|-\\)\\+$'\n  if getchar(1, {number: true}) == 0\n      &amp;&amp; !wildmenumode() &amp;&amp; curpos == cmdline-&gt;len() + 1\n      &amp;&amp; (!cmdmode || (cmdline =~ trigger_char &amp;&amp; cmdline !~ not_trigger_char))\n    SkipCmdlineChanged()\n    feedkeys(\"\\&lt;C-@&gt;\", \"t\")\n    timer_start(0, (_) =&gt; getcmdline()-&gt;substitute('\\%x00', '', 'ge')-&gt;setcmdline())\n  endif\nenddef\n\ndef SkipCmdlineChanged(key = ''): string\n  set ei+=CmdlineChanged\n  timer_start(0, (_) =&gt; execute('set ei-=CmdlineChanged'))\n  return key == '' ? '' : ((wildmenumode() ? \"\\&lt;C-E&gt;\" : '') .. key)\nenddef\n\nset wim=noselect:lastused,full wop=pum wcm=&lt;C-@&gt; wmnu\n\nautocmd CmdlineChanged :,/,? CmdComplete()\n\n# Optional: Preserve history recall behavior\ncnoremap &lt;expr&gt; &lt;Up&gt; SkipCmdlineChanged(\"\\&lt;Up&gt;\")\ncnoremap &lt;expr&gt; &lt;Down&gt; SkipCmdlineChanged(\"\\&lt;Down&gt;\")\n\n# Optional: Customize popup height\nautocmd CmdlineEnter : set bo+=error | exec $'set ph={max([10, winheight(0) - 4])}'\nautocmd CmdlineEnter /,? set bo+=error ph=8\nautocmd CmdlineLeave :,/,? set bo-=error ph&amp;</code></pre></div><h2>Other Improvements and Changes</h2><p>Many bugs have been fixed since the release of Vim 9.1, including security vulnerabilities, memory leaks and potential crashes.</p><h2>Charity: Transition to Kuwasha</h2><p>For over 30 years, Vim has been \"Charityware,\" supporting children in Kibaale, Uganda. Following the passing of Bram Moolenaar, the ICCF Holland foundation was dissolved, and its mission has been carried forward by a new partner.</p><ul><li><strong>ICCF Holland Dissolution:</strong> Because the charity could not be sustained in its original form without Bram, ICCF Holland was dissolved and its remaining funds were transferred to ensure continued support for the Kibaale project.</li><li><strong>Partnership with Kuwasha:</strong> To ensure that aid remained uninterrupted, all sponsorship activities were moved to <a href=\"https://www.kuwasha.net/ways-to-give/\">Kuwasha</a>, a long-term partner based in Canada that now manages the projects in Uganda.</li><li> Vim remains Charityware. We encourage users to continue supporting the needy children in Uganda through this new transition.</li></ul><p>For information on how to support this cause, please visit the <a href=\"https://www.vim.org/sponsor/index.php\">Sponsor page</a>.</p><p>We would like to thank everybody who contributed to the project through patches, translations, and bug reports. We are very grateful for any support.</p>","contentLength":9636,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47015330"},{"title":"My smart sleep mask broadcasts users' brainwaves to an open MQTT broker","url":"https://aimilios.bearblog.dev/reverse-engineering-sleep-mask/","date":1771083347,"author":"minimalthinker","guid":274,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47015294"},{"title":"Show HN: Sameshi – a ~1200 Elo chess engine that fits within 2KB","url":"https://github.com/datavorous/sameshi","date":1771076864,"author":"datavorous_","guid":215,"unread":true,"content":"<p>I made a chess engine today, and made it fit within 2KB.\nI used a variant of MinMax called Negamax, with alpha beta pruning. For the board representation I have used a 120-cell \"mailbox\". I managed to squeeze in checkmate/stalemate in there, after trimming out some edge cases.</p><p>I am a great fan of demoscene (computer art subculture) since middle school, and hence it was a ritual i had to perform.</p><p>For estimating the Elo, I measured 240 automated games against Stockfish Elo levels (1320 to 1600) under fixed depth-5 and some constrained rules, using equal color distribution.</p><p>Then converted pooled win/draw/loss scores to Elo through some standard logistic formula with binomial 95% confidence interval.</p>","contentLength":702,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47014500"},{"title":"Ooh.directory: a place to find good blogs that interest you","url":"https://ooh.directory/","date":1771076420,"author":"hisamafahri","guid":273,"unread":true,"content":"<li><p><a href=\"https://onestarrynight.com\">One Starry Night</a><q>A cozy constellation of stories, stardust, nostalgia, and chronic illness adventures. Still sparkling since 2001.</q>\n\n        \n\n  By Sarah DiLullo.\n\n\n        </p></li><li><p><a href=\"https://blog.miljko.org\">Infinite Regress</a><q>Clinical trials, cancer research, book reviews, coffee making, photography, and the like.</q>\n\n        \n\n  By Miloš Miljković.\n\n\n        </p></li>","contentLength":322,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47014449"},{"title":"Ars Technica makes up quotes from Matplotlib maintainer; pulls story","url":"https://infosec.exchange/@mttaggart/116065340523529645","date":1771061325,"author":"robin_reala","guid":272,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47013059"},{"title":"YouTube as Storage","url":"https://github.com/PulseBeat02/yt-media-storage","date":1771060215,"author":"saswatms","guid":271,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47012964"},{"title":"Zig – io_uring and Grand Central Dispatch std.Io implementations landed","url":"https://ziglang.org/devlog/2026/#2026-02-13","date":1771057331,"author":"Retro_Dev","guid":270,"unread":true,"content":"<div><p>As we approach the end of the 0.16.0 release cycle, Jacob has been hard at work, bringing  up to speed with all the latest API changes:</p><p>Both of these are based on userspace stack switching, sometimes called “fibers”, “stackful coroutines”, or “green threads”.</p><p>They are now , by constructing one’s application using . They should be considered  because there is important followup work to be done before they can be used reliably and robustly:</p><p>With those caveats in mind, it seems we are indeed reaching the Promised Land, where Zig code can have Io implementations effortlessly swapped out:</p><pre><code></code></pre><pre><code>$ strace ./hello_threaded\nexecve(\"./hello_threaded\", [\"./hello_threaded\"], 0x7ffc1da88b20 /* 98 vars */) = 0\nmmap(NULL, 262207, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f583f338000\narch_prctl(ARCH_SET_FS, 0x7f583f378018) = 0\nprlimit64(0, RLIMIT_STACK, NULL, {rlim_cur=8192*1024, rlim_max=RLIM64_INFINITY}) = 0\nprlimit64(0, RLIMIT_STACK, {rlim_cur=16384*1024, rlim_max=RLIM64_INFINITY}, NULL) = 0\nsigaltstack({ss_sp=0x7f583f338000, ss_flags=0, ss_size=262144}, NULL) = 0\nsched_getaffinity(0, 128, [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]) = 8\nrt_sigaction(SIGIO, {sa_handler=0x1019d90, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0\nrt_sigaction(SIGPIPE, {sa_handler=0x1019d90, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0\nwritev(1, [{iov_base=\"Hello, World!\\n\", iov_len=14}], 1Hello, World!\n) = 14\nrt_sigaction(SIGIO, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, NULL, 8) = 0\nrt_sigaction(SIGPIPE, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, NULL, 8) = 0\nexit_group(0)                           = ?\n+++ exited with 0 +++\n</code></pre><p>Swapping out only the I/O implementation:</p><pre><code></code></pre><pre><code>execve(\"./hello_evented\", [\"./hello_evented\"], 0x7fff368894f0 /* 98 vars */) = 0\nmmap(NULL, 262215, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f70a4c28000\narch_prctl(ARCH_SET_FS, 0x7f70a4c68020) = 0\nprlimit64(0, RLIMIT_STACK, NULL, {rlim_cur=8192*1024, rlim_max=RLIM64_INFINITY}) = 0\nprlimit64(0, RLIMIT_STACK, {rlim_cur=16384*1024, rlim_max=RLIM64_INFINITY}, NULL) = 0\nsigaltstack({ss_sp=0x7f70a4c28008, ss_flags=0, ss_size=262144}, NULL) = 0\nsched_getaffinity(0, 128, [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]) = 8\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f70a4c27000\nmmap(0x7f70a4c28000, 548864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f70a4ba1000\nio_uring_setup(64, {flags=IORING_SETUP_COOP_TASKRUN|IORING_SETUP_SINGLE_ISSUER, sq_thread_cpu=0, sq_thread_idle=1000, sq_entries=64, cq_entries=128, features=IORING_FEAT_SINGLE_MMAP|IORING_FEAT_NODROP|IORING_FEAT_SUBMIT_STABLE|IORING_FEAT_RW_CUR_POS|IORING_FEAT_CUR_PERSONALITY|IORING_FEAT_FAST_POLL|IORING_FEAT_POLL_32BITS|IORING_FEAT_SQPOLL_NONFIXED|IORING_FEAT_EXT_ARG|IORING_FEAT_NATIVE_WORKERS|IORING_FEAT_RSRC_TAGS|IORING_FEAT_CQE_SKIP|IORING_FEAT_LINKED_FILE|IORING_FEAT_REG_REG_RING|IORING_FEAT_RECVSEND_BUNDLE|IORING_FEAT_MIN_TIMEOUT|IORING_FEAT_RW_ATTR|IORING_FEAT_NO_IOWAIT, sq_off={head=0, tail=4, ring_mask=16, ring_entries=24, flags=36, dropped=32, array=2112, user_addr=0}, cq_off={head=8, tail=12, ring_mask=20, ring_entries=28, overflow=44, cqes=64, flags=40, user_addr=0}}) = 3\nmmap(NULL, 2368, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE, 3, 0) = 0x7f70a4ba0000\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE, 3, 0x10000000) = 0x7f70a4b9f000\nio_uring_enter(3, 1, 1, IORING_ENTER_GETEVENTS, NULL, 8Hello, World!\n) = 1\nio_uring_enter(3, 1, 1, IORING_ENTER_GETEVENTS, NULL, 8) = 1\nmunmap(0x7f70a4b9f000, 4096)            = 0\nmunmap(0x7f70a4ba0000, 2368)            = 0\nclose(3)                                = 0\nmunmap(0x7f70a4ba1000, 548864)          = 0\nexit_group(0)                           = ?\n+++ exited with 0 +++\n</code></pre><p>Key point here being that the  function is identical between those two snippets.</p><p>Moving beyond Hello World, the Zig compiler itself works fine using , both with io_uring and with GCD, but as mentioned above, there is a not-yet-diagnosed performance degradation when doing so.</p></div><div><p>If you have a Zig project with dependencies, two big changes just landed which I think you will be interested to learn about.</p><p>Fetched packages are now stored  in the  directory of the project root (next to your  file).</p><p>For example here are a few results from <a href=\"https://codeberg.org/awebo-chat/awebo\" target=\"_blank\">awebo</a> after running :</p><pre><code>$ du -sh zig-pkg/*\n13M    freetype-2.14.1-alzUkTyBqgBwke4Jsot997WYSpl207Ij9oO-2QOvGrOi\n20K    opus-0.0.2-vuF-cMAkAADVsm707MYCtPmqmRs0gzg84Sz0qGbb5E3w\n4.3M   pulseaudio-16.1.1-9-mk_62MZkNwBaFwiZ7ZVrYRIf_3dTqqJR5PbMRCJzSuLw\n5.2M   uucode-0.1.0-ZZjBPvtWUACf5dqD_f9I37VGFsN24436CuceC5pTJ25n\n728K   vaxis-0.5.1-BWNV_AxECQCj3p4Hcv4U3Yo1WMUJ7Z2FUj0UkpuJGxQQ\n</code></pre><p>It is highly recommended to add this directory to the project-local source control ignore file (e.g. ). However, by being outside of , it provides the possibility of distributing self-contained source tarballs, which contain all dependencies and therefore can be used to build offline, or for archival purposes.</p><p>Meanwhile, an  copy of the dependency is cached globally. After filtering out all the unused files based on the  filter, the contents are recompressed:</p><pre><code>$ du -sh ~/.cache/zig/p/*\n2.4M    freetype-2.14.1-alzUkTyBqgBwke4Jsot997WYSpl207Ij9oO-2QOvGrOi.tar.gz\n4.0K    opus-0.0.2-vuF-cMAkAADVsm707MYCtPmqmRs0gzg84Sz0qGbb5E3w.tar.gz\n636K    pulseaudio-16.1.1-9-mk_62MZkNwBaFwiZ7ZVrYRIf_3dTqqJR5PbMRCJzSuLw.tar.gz\n880K    uucode-0.1.0-ZZjBPvtWUACf5dqD_f9I37VGFsN24436CuceC5pTJ25n.tar.gz\n120K    vaxis-0.5.1-BWNV_BFECQBbXeTeFd48uTJRjD5a-KD6kPuKanzzVB01.tar.gz\n</code></pre><p>The motivation for this change is to make it easier to tinker. Go ahead and edit those files, see what happens. Swap out your package directory with a git clone. Grep your dependencies all together. Configure your IDE to auto-complete based on the  directory. <a href=\"https://codeberg.org/awebo-chat/awebo/issues/61\" target=\"_blank\">Run baobab on your dependency tree</a>. Furthermore, by having the global cache have compressed files instead makes it easier to share that cached data between computers. In the future, <a href=\"https://github.com/ziglang/zig/issues/23236\" target=\"_blank\">it is planned to support peer-to-peer torrenting of dependency trees</a>. By recompressing packages into a canonical form, this will allow peers to share Zig packages with minimal bandwidth. I love this idea because it simultaneously provides resilience to network outages, as well as a popularity contest. Find out which open source packages are popular based on number of seeders!</p><p>The second change here is the addition of the  flag to .</p><p>In retrospect, it seems so obvious, I don’t know why I didn’t think of it since the beginning. It looks like this:</p><p>This is a  option. Given a path to a source checkout of a project, all packages matching that project across the entire dependency tree will be overridden.</p><p>Thanks to the fact that package content hashes include name and fingerprint, <strong>this resolves before the package is potentially fetched</strong>.</p><p>This is an easy way to temporarily use one or more forks which are in entirely separate directories. You can iterate on your entire dependency tree until everything is working, while using comfortably the development environment and source control of the dependency projects.</p><p>The fact that it is a CLI flag makes it appropriately ephemeral. The moment you drop the flags, you’re back to using your pristine, fetched dependency tree.</p><p>If the project does not match, an error occurs, preventing confusion:</p><pre><code>$ zig build --fork=/home/andy/dev/mime\nerror: fork /home/andy/dev/mime matched no mime packages\n$\n</code></pre><p>If the project does match, you get a reminder that you are using a fork, preventing confusion:</p><pre><code>$ zig build --fork=/home/andy/dev/dvui\ninfo: fork /home/andy/dev/dvui matched 1 (dvui) packages\n...\n</code></pre><p>This functionality is intended to enhance the workflow of dealing with ecosystem breakage. I already tried it a bit and found it to be quite pleasant to work with. The new workflow goes like this:</p><ol><li>Fail to build from source due to ecosystem breakage.</li><li>Tinker with  until your project works again. During this time you can use the actual upstream source control, test suite, <code>zig build test --watch -fincremental</code>, etc.</li><li>Now you have a new option: be selfish and just keep working on your own stuff, or you can proceed to submit your patches upstream.</li></ol><p>…and you can probably skip the step where you switch your  to your fork unless you expect upstream to take a long time to merge your fixes.</p></div><div><p>The Windows operating system provides a large ABI surface area for doing things in the kernel. However, not all ABIs are created equally. As Casey Muratori points out in his lecture, <a href=\"https://www.youtube.com/watch?v=5IUj1EZwpJY\" target=\"_blank\">The Only Unbreakable Law</a>, the organizational structure of software development teams has a direct impact on the structure of the software they produce.</p><p>The DLLs on Windows are organized into a heirarchy, with some of the APIs being high-level wrappers around lower-level ones. For example, whenever you call functions of , ultimately, the actual work is done by . You can observe this directly by using ProcMon.exe and examining stack traces.</p><p>What we’ve learned empirically is that the ntdll APIs are generally well-engineered, reasonable, and powerful, but the kernel32 wrappers introduce unnecessary heap allocations, additional failure modes, unintentional CPU usage, and bloat.</p><p>This is why the Zig standard library policy is to <a href=\"https://codeberg.org/ziglang/zig/issues/31131\" target=\"_blank\">Prefer the Native API over Win32</a>. We’re not quite there yet - we have plenty of calls into kernel32 remaining - but we’ve taken great strides recently. I’ll give you two examples.</p><p>According to the official documentation, Windows does not have a straightforward way to get random bytes.</p><p>Unfortunately, starting with Windows 8, the first time you call this function, it dynamically loads  and calls <a href=\"https://learn.microsoft.com/en-us/windows/win32/seccng/processprng\" target=\"_blank\">ProcessPrng</a>. If loading the DLL fails (for example due to an overloaded system, which we have observed on Zig CI several times), it returns error 38 (from a function that has  return type and is documented to never fail).</p><p>The first thing  does is heap allocate a small, constant number of bytes. If this fails it returns  in a  (documented behavior is to never fail, and always return ).</p><p> apparently also runs a test suite every time you load it.</p><p>All that  is  doing is  on  and reading 48 bytes with  to get a seed, and then initializing a per-CPU AES-based CSPRNG.</p><p>So the dependency on  and  can both be avoided, and the nondeterministic failure and latencies on first RNG read can also be avoided.</p><h2>Example 2: NtReadFile and NtWriteFile</h2><pre><code></code></pre><p> looks like this:</p><pre><code></code></pre><p>As a reminder, <em>the above function is implemented by calling the below function</em>.</p><p>Already we can see some nice things about using the lower level API. For instance, the  API simply gives us the error code as the return value, while the kernel32 wrapper hides the status code somewhere, returns a  and then requires you to call  to find out what went wrong. Imagine! Returning a value from a function 🌈</p><p>Furthermore,  is a fake type. The Windows kernel doesn’t actually know or care about it at all! The actual primitives here are events, APCs, and .</p><p>If you have a synchronous file handle, then  and  must be . You get the answer in the  immediately. If you pass an APC routine here then some old bitrotted 32-bit code runs and you get garbage results.</p><p>On the other hand if you have an asynchronous file handle, then you need to either use an  or an .  uses events, which means that it’s doing extra, unnecessary resource allocation and management just to read from a file. Instead, Zig now passes an APC routine and then calls . This integrates seamlessly with cancelation, making it possible to cancel tasks while they perform file I/O, regardless of whether the file was opened in synchronous mode or asynchronous mode.</p><p>For a deeper dive into this topic, please refer to this issue:</p></div><div><p>Over the past month or so, several enterprising contributors have taken an interest in the <a href=\"https://codeberg.org/ziglang/zig/issues/30978\" target=\"_blank\">zig libc subproject</a>. The idea here is to incrementally delete redundant code, by providing libc functions as Zig standard library wrappers rather than as vendored C source files. In many cases, these functions are one-to-one mappings, such as  or , or trivially wrap a generic function, like :</p><pre><code></code></pre><p>So far, roughly 250 C source files have been deleted from the Zig repository, with 2032 remaining.</p><p>With each function that makes the transition, Zig gains independence from third party projects and from the C programming language, compilation speed improves, Zig’s installation size is simplified and reduced, and user applications which statically link libc enjoy reduced binary size.</p><p>Additionally, a <a href=\"https://codeberg.org/ziglang/zig/pulls/31037\" target=\"_blank\">recent enhancement</a> now makes zig libc share the Zig Compilation Unit with other Zig code rather than being a separate static archive, linked together later. This is one of the advantages of Zig having an integrated compiler and linker. When the exported libc functions share the ZCU, redundant code is eliminated because functions can be optimized together. It’s kind of like enabling LTO (Link-Time Optimization) across the libc boundary, except it’s done properly in the frontend instead of too late, in the linker.</p><p>Furthermore, when this work is combined with the recent <a href=\"https://codeberg.org/ziglang/zig/issues/30150\" target=\"_blank\">std.Io changes</a>, there is potential for users to seamlessly control how libc performs I/O - for example forcing all calls to  and  to participate in an io_uring event loop, even though that code was not written with such use case in mind. Or, <a href=\"https://codeberg.org/ziglang/zig/pulls/30788\" target=\"_blank\">resource leak detection</a> could be enabled for third-party C code. For now this is only a vaporware idea which has not been experimented with, but the idea intrigues me.</p><p>Big thanks to Szabolcs Nagy for <a href=\"https://wiki.musl-libc.org/libc-test.html\" target=\"_blank\">libc-test</a>. This project has been a huge help in making sure that we don’t regress any math functions.</p><p>As a reminder to our users, now that Zig is transitioning to being the static libc provider, if you encounter issues with the musl, mingw-w64, or wasi-libc libc functionality provided by Zig, <strong>please file bug reports in Zig first</strong> so we don’t annoy maintainers for bugs that are in Zig, and no longer vendored by independent libc implementation projects.</p></div>","contentLength":14190,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47012717"},{"title":"OpenAI should build Slack","url":"https://www.latent.space/p/ainews-why-openai-should-build-slack","date":1771055413,"author":"swyx","guid":269,"unread":true,"content":"<p><strong>well okay, Sam: You Should Build Slack. </strong><a href=\"https://www.bigtechnology.com/p/enterprise-will-be-a-top-openai-priority\" rel=\"\">Enterprise</a></p><p><strong>Everything could be better</strong><a href=\"https://youtu.be/CnaegIpkenA?si=dizG0NIKTYXG0Lwz&amp;t=832\" rel=\"\">complained on the latest All In podcast</a></p><p>Slack Connect is great though, definitely just clone that.</p><p>In the desktop wars, Anthropic has pursued a far more cohesive strategy than OpenAI: one app for Chat, Cowork, and Claude Code, with optional control of the browser via Claude in Chrome. </p><p><a href=\"https://betterthanrandom.substack.com/p/shipping-the-org-chart\" rel=\"\">shipped the org chart</a><a href=\"https://chatgpt.com/download\" rel=\"\">chat app here</a><a href=\"https://openai.com/index/introducing-chatgpt-atlas/\" rel=\"\">browser app</a><a href=\"https://openai.com/index/introducing-the-codex-app/\" rel=\"\">coding app</a></p><p><a href=\"https://latent.space/p/noam-brown\" rel=\"\">you care about the multiagent</a><a href=\"https://www.cnbc.com/2025/12/09/openai-slack-ceo-denise-dresser-chief-revenue-officer.html\" rel=\"\">Slack CEO Denise Dresser in Dec</a></p><p><a href=\"https://calv.info/openai-reflections\" rel=\"\">you guys use this thing more than email</a></p><p><a href=\"https://x.com/swyx/status/2021498862012334274\" rel=\"\">given your designer access to your coding agent</a><strong>God’s given orchestration interface: chat</strong></p><p><strong>reinvent the future of work</strong></p><ul><li><p><strong>Is it a big deal if you get it right?</strong></p></li><li><p><strong><a href=\"https://www.latent.space/p/ainews-context-graphs-hype-or-actually\" rel=\"\">context graph</a><a href=\"https://www.latent.space/p/ainews-ai-vs-saas-the-unreasonable\" rel=\"\">Frontier</a></strong></p></li></ul><blockquote><p><em><a href=\"https://x.com/swyx/status/2022580899737673810\" rel=\"\">Twitter</a></em></p></blockquote><p><a href=\"https://www.dwarkesh.com/p/dario-amodei-2\" rel=\"\">new Dwarkesh-Dario pod </a><a href=\"https://news.ycombinator.com/item?id=47006594\" rel=\"\">OpenAI claimed a big result</a></p><p><strong>MiniMax M2.5 open-sourcing: agent-native RL, speed/cost, and rapid ecosystem uptake</strong></p><ul><li><p><strong>MiniMax-M2.5 is now open source</strong><strong>RL across hundreds of thousands of real-world environments</strong><a href=\"https://twitter.com/MiniMax_AI/status/2022310932693897628\" rel=\"\">MiniMax announcement</a><a href=\"https://twitter.com/vllm_project/status/2022311342225678757\" rel=\"\">vLLM</a><a href=\"https://twitter.com/lmsysorg/status/2022319102560555401\" rel=\"\">lmsys</a></p></li><li><p><strong>The practical headline is economics + throughput, not just score</strong><a href=\"https://twitter.com/MiniMax_AI/status/2022379949336957254\" rel=\"\">MiniMax</a><a href=\"https://twitter.com/omarsar0/status/2022384166034190528\" rel=\"\">omarsar0</a><a href=\"https://twitter.com/pcuenq/status/2022336556326060341\" rel=\"\">pcuenq</a><a href=\"https://twitter.com/ivanfioravanti/status/2022338870172684655\" rel=\"\">ivanfioravanti</a></p></li><li><p><strong>Forge RL training system details leak into the narrative</strong><strong>process reward + completion-time reward</strong><strong>millions of trajectories/day</strong><a href=\"https://twitter.com/YouJiacheng/status/2022339475049947576\" rel=\"\">YouJiacheng</a><a href=\"https://twitter.com/MiniMax_AI/status/2022370086397624476\" rel=\"\">MiniMax reply</a></p></li><li><p><strong>Independent reviews: “viable for multi-turn work” but token-hungry</strong><a href=\"https://twitter.com/ZhihuFrontier/status/2022214461415993817\" rel=\"\">ZhihuFrontier</a><a href=\"https://twitter.com/teortaxesTex/status/2022223441005621556\" rel=\"\">teortaxesTex</a></p></li><li><p><strong>Ecosystem uptake is immediate</strong><a href=\"https://twitter.com/HaihaoShen/status/2022293472796180676\" rel=\"\">HaihaoShen</a></p></li></ul><p><strong>GLM‑5 and the “near-frontier” open model wave: performance, infra constraints, and eval chatter</strong></p><ul><li><p><a href=\"https://twitter.com/togethercompute/status/2022354579858289052\" rel=\"\">Together</a><a href=\"https://twitter.com/wandb/status/2022389206572765697\" rel=\"\">W&amp;B</a><a href=\"https://twitter.com/jon_durbin/status/2022291772617945546\" rel=\"\">jon_durbin</a></p></li><li><p><strong>GLM‑5 qualitative review highlights</strong><a href=\"https://twitter.com/ZhihuFrontier/status/2022161058321047681\" rel=\"\">ZhihuFrontier on GLM‑5</a></p></li><li><p><strong>Benchmarks as a moving target</strong><a href=\"https://twitter.com/jyangballin/status/2022367240293949772\" rel=\"\">jyangballin</a><a href=\"https://twitter.com/teortaxesTex/status/2022255213394948360\" rel=\"\">teortaxesTex</a></p></li><li><p><strong>Cross-checking with alternative evals</strong><a href=\"https://twitter.com/maximelabonne/status/2022401174549512576\" rel=\"\">maximelabonne</a></p></li></ul><p><strong>Agent engineering in practice: file-based coordination, terminal-first workflows, and “agent OS” framing</strong></p><ul><li><p><strong>Claude Code “Agent Teams” internals are surprisingly simple</strong><code>~/.claude/teams/inboxes/{agent}.json</code><a href=\"https://twitter.com/peter6759/status/2022156692985983266\" rel=\"\">peter6759</a></p></li><li><p><strong>Terminal agents are becoming the default UX</strong><a href=\"https://twitter.com/cline/status/2022341254965772367\" rel=\"\">cline</a><a href=\"https://twitter.com/cline/status/2022341258979717196\" rel=\"\">cline details</a><a href=\"https://twitter.com/testingcatalog/status/2022348951459172604\" rel=\"\">testingcatalog</a><a href=\"https://twitter.com/dr_cintas/status/2022387444189139367\" rel=\"\">dr_cintas</a><a href=\"https://twitter.com/arafatkatze/status/2022415192932651302\" rel=\"\">arafatkatze</a></p></li><li><p><strong>Agent scaffolds may matter less than expected (for some horizons)</strong><a href=\"https://twitter.com/nikolaj2030/status/2022398669337825737\" rel=\"\">nikolaj2030</a><a href=\"https://twitter.com/ajeya_cotra/status/2022419978495127828\" rel=\"\">ajeya_cotra</a><a href=\"https://twitter.com/gneubig/status/2022451119310655909\" rel=\"\">gneubig</a></p></li><li><p><strong>“Agents as OS / filesystem as substrate”</strong><a href=\"https://twitter.com/levie/status/2022375298097111160\" rel=\"\">levie</a><a href=\"https://twitter.com/skirano/status/2022387763421810989\" rel=\"\">skirano</a></p></li><li><p><strong>Key operational lesson: make codebases “agent-ready”</strong><a href=\"https://twitter.com/dok2001/status/2022339274767520246\" rel=\"\">dok2001</a></p></li></ul><p><strong>RL/post-training research themes: process rewards, exploration, and rubric-based evaluation</strong></p><ul><li><p><strong>Length-Incentivized Exploration (LIE) for reasoning</strong><a href=\"https://twitter.com/dair_ai/status/2022360649817526275\" rel=\"\">dair_ai</a></p></li><li><p><strong>DPPO vs PPO and “trust region” framing</strong><a href=\"https://twitter.com/TheTuringPost/status/2022326245745377562\" rel=\"\">TheTuringPost</a></p></li><li><p><strong>Rubrics-as-rewards and evolving rubrics</strong><a href=\"https://twitter.com/cwolferesearch/status/2022384365049892974\" rel=\"\">cwolferesearch</a><a href=\"https://twitter.com/davidad/status/2022361016995319850\" rel=\"\">davidad</a></p></li><li><p><strong>∆Belief‑RL / information-seeking agents</strong><a href=\"https://twitter.com/ShashwatGoel7/status/2022341054939185345\" rel=\"\">ShashwatGoel7</a></p></li><li><p><strong>Human simulation as an RL target</strong><a href=\"https://twitter.com/ShirleyYXWu/status/2022374624676421676\" rel=\"\">ShirleyYXWu</a></p></li></ul><p><strong>Systems/infra and tooling: FP4 MoE kernels, faster ZeRO loads, model “skills,” and observability</strong></p><ul><li><p><strong>vLLM on GB300 + FP4 MoE acceleration</strong><strong>FlashInfer FP4 MoE kernel</strong><code>VLLM_USE_FLASHINFER_MOE_FP4=1</code><a href=\"https://twitter.com/vllm_project/status/2022308974150975792\" rel=\"\">vllm_project</a></p></li><li><p><strong>DeepSpeed ZeRO load-time fix</strong><a href=\"https://twitter.com/StasBekman/status/2022354880049082658\" rel=\"\">StasBekman</a></p></li><li><p><strong>Gemini “Skills” and multimodal tool calling</strong><a href=\"https://twitter.com/osanseviero/status/2022259577232785866\" rel=\"\">osanseviero</a><strong>multimodal function calling</strong><a href=\"https://twitter.com/_philschmid/status/2022349886318928158\" rel=\"\">philschmid</a><a href=\"https://twitter.com/OfficialLoganK/status/2022409335465480346\" rel=\"\">OfficialLoganK</a><a href=\"https://twitter.com/GoogleAIStudio/status/2022409735287537999\" rel=\"\">GoogleAIStudio</a></p></li><li><p><strong>Agent harness instrumentation</strong><a href=\"https://twitter.com/ArtificialAnlys/status/2022358995739254800\" rel=\"\">ArtificialAnlys</a></p></li><li><p><strong>Local fine-tuning &amp; Apple Silicon workflows</strong><a href=\"https://twitter.com/awnihannun/status/2022322714548338962\" rel=\"\">awnihannun</a><a href=\"https://twitter.com/awnihannun/status/2022327214218657948\" rel=\"\">awnihannun</a><a href=\"https://twitter.com/ActuallyIsaak/status/2022414004623479014\" rel=\"\">ActuallyIsaak</a></p></li></ul><p><strong>“AI accelerates science” moment: GPT‑5.2 + QFT result and the scaffolding narrative</strong></p><ul><li><p><strong>OpenAI claims a novel theoretical physics result with GPT‑5.2</strong><a href=\"https://twitter.com/OpenAI/status/2022390096625078389\" rel=\"\">OpenAI</a><a href=\"https://twitter.com/OpenAI/status/2022390104237707667\" rel=\"\">arXiv pointer</a><strong>proved it after ~12 hours</strong><a href=\"https://twitter.com/kevinweil/status/2022388305434939693\" rel=\"\">kevinweil</a></p></li><li><p><strong>Community reactions range from “significant journal-paper tier” to skepticism about interpretation</strong><a href=\"https://twitter.com/polynoamial/status/2022413904757035167\" rel=\"\">polynoamial</a><a href=\"https://twitter.com/teortaxesTex/status/2022401945429000685\" rel=\"\">teortaxesTex</a><a href=\"https://twitter.com/scaling01/status/2022401147110318586\" rel=\"\">scaling01</a></p></li></ul><ul><li><p><strong><a href=\"https://huggingface.co/models?sort=modified&amp;search=minimax+m2.5\" rel=\"\">Hugging Face</a></strong><strong> parameters, contrary to expectations of an increase to </strong><strong> like the GLM5 model. It offers a cost-effective operation at </strong><strong>, and is enhanced by the Forge reinforcement learning framework, which improves training efficiency and task generalization.</strong></p><ul><li><p>A user expressed surprise at the model’s size, noting that while they expected an increase to 800 billion parameters to compete with models like GLM5, the MiniMax-M2.5 remains at 220 billion parameters. This is considered impressive given its ‘frontier strength’, suggesting high performance despite the parameter count.</p></li><li><p>Another user mentioned the model’s Q4_K_XL size, which is approximately 130GB. This size is significant as it places the model just beyond the capabilities of some hardware, indicating a need for more robust systems to fully utilize the model’s potential.</p></li><li><p>There is anticipation for the release of FP4/AWQ, indicating that users are looking forward to further advancements or optimizations in the model’s performance or efficiency. This suggests a community eager for improvements that could enhance usability or reduce resource requirements.</p></li></ul></li><li><p><strong>OpenHands has announced the release of the MiniMaxAI MiniMax-M2.5 model, which features </strong><strong> active parameters. This model is noted for its performance, ranking 4th in the OpenHands Index, and is </strong><strong><a href=\"https://huggingface.co/cerebras\" rel=\"\">Source</a></strong></p><ul><li><p>The MiniMax-M2.5 model by Moonshot is notable for its architecture, which utilizes 230 billion parameters but only activates 10 billion at a time. This design choice is likely aimed at optimizing computational efficiency, allowing the model to perform well on less powerful hardware, such as GPUs that are not top-of-the-line. This approach could potentially offer a balance between performance and resource usage, making it accessible for more users.</p></li><li><p>A comparison is drawn between MiniMax-M2.5 and other large models like GLM and Kimi. GLM has had to double its parameters to maintain performance, while Kimi has reached 1 trillion parameters. The implication is that MiniMax-M2.5 achieves competitive performance with fewer active parameters, which could be a significant advancement in model efficiency and scalability.</p></li><li><p>The potential for further optimization through quantization is highlighted, suggesting that MiniMax-M2.5 could be made even more efficient. Quantization could reduce the model’s size and increase its speed, making it feasible to run on machines with 128GB of RAM while still leaving room for additional tasks such as deep-context tool use. This could make the model particularly attractive for users with limited computational resources.</p></li></ul></li><li><p><strong>Minimax M2.5 has been officially released, showcasing impressive benchmark results: </strong><strong>. The model is noted for its cost efficiency, with operational costs significantly lower than competitors like Opus, Gemini 3 Pro, and GPT-5. Specifically, running M2.5 at </strong><strong><a href=\"https://www.minimax.io/news/minimax-m25\" rel=\"\">official Minimax page</a></strong></p><ul><li><p>The Minimax M2.5 model is highlighted for its cost-effectiveness, with operational costs significantly lower than competitors like Opus, Gemini 3 Pro, and GPT-5. Specifically, running M2.5 at 100 tokens per second costs $1 per hour, and at 50 tokens per second, it costs $0.3 per hour. This translates to an annual cost of $10,000 for four instances running continuously, making it a potentially disruptive option in terms of affordability.</p></li><li><p>There is anticipation for the release of open weights on Hugging Face, which would allow for broader experimentation and integration into various applications. This suggests a community interest in transparency and accessibility for further development and benchmarking.</p></li><li><p>The potential impact of Minimax M2.5 on existing models like GLM 5.0 and Kimi 2.5 is discussed, with some users suggesting that if the reported benchmarks are accurate, M2.5 could surpass these models in popularity due to its ease of use and cost advantages. This indicates a shift in preference towards models that offer better performance-to-cost ratios.</p></li></ul></li></ul>","contentLength":7248,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47012553"},{"title":"Show HN: SQL-tap – Real-time SQL traffic viewer for PostgreSQL and MySQL","url":"https://github.com/mickamy/sql-tap","date":1771043255,"author":"mickamy","guid":214,"unread":true,"content":"<p>sql-tap is a transparent proxy that captures SQL queries by parsing the PostgreSQL/MySQL wire protocol and displays them in a terminal UI. You can run EXPLAIN on any captured query. No application code changes needed — just change the port.</p>","contentLength":242,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47011567"},{"title":"Oh, good: Discord's age verification rollout has ties to Palantir co-founder","url":"https://www.pcgamer.com/software/platforms/oh-good-discords-age-verification-rollout-has-ties-to-palantir-co-founder-and-panopticon-architect-peter-thiel/","date":1771040958,"author":"absqueued","guid":268,"unread":true,"content":"<p>Last week, Discord invited the contempt of its users by announcing it will be <a data-analytics-id=\"inline-link\" href=\"https://www.pcgamer.com/games/discord-is-rolling-out-facial-scanning-and-id-checks-in-march-for-everyone-who-doesnt-want-to-be-locked-into-a-teen-appropriate-experience/\" target=\"_blank\" data-url=\"https://www.pcgamer.com/games/discord-is-rolling-out-facial-scanning-and-id-checks-in-march-for-everyone-who-doesnt-want-to-be-locked-into-a-teen-appropriate-experience/\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\" data-before-rewrite-localise=\"https://www.pcgamer.com/games/discord-is-rolling-out-facial-scanning-and-id-checks-in-march-for-everyone-who-doesnt-want-to-be-locked-into-a-teen-appropriate-experience/\">rolling out global age verification</a> restrictions in March, which will restrict viewable content and communities for users who don't scan either their faces or government IDs and haven't already been determined to be an adult by unspecified prediction algorithms. <a data-analytics-id=\"inline-link\" href=\"https://www.windowscentral.com/software-apps/discord-alternative-search-10000-percent-stoat\" target=\"_blank\" data-url=\"https://www.windowscentral.com/software-apps/discord-alternative-search-10000-percent-stoat\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">Approximately nobody</a> thought this was cool.</p><p>Impossibly, despite its attempts to pacify the ensuing outcry by issuing a clarification that merely users will be required to submit to its child detection matrix, Discord has managed to make the rollout of its global age assurance policy seem even grimier. The company has informed some users in the UK they may be part of \"an experiment\" with Persona, an age verification vendor whose investors include Peter Thiel, co-founder of ICE's premier surveillance provider, Palantir.</p><figure data-bordeaux-image-check=\"\"><figcaption itemprop=\"caption description\"></figcaption></figure><p>In the days since Discord's age assurance policy announcement, reports began <a data-analytics-id=\"inline-link\" href=\"https://x.com/GiveMeBanHammer/status/2021851054519001133?s=20\" target=\"_blank\" data-url=\"https://x.com/GiveMeBanHammer/status/2021851054519001133?s=20\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">bubbling up on social media</a> from users in the UK—where Discord already requires age verification as a result of <a data-analytics-id=\"inline-link\" href=\"https://www.pcgamer.com/hardware/brits-can-get-around-discords-age-verification-thanks-to-death-strandings-photo-mode-bypassing-the-measure-introduced-with-the-uks-online-safety-act-we-tried-it-and-it-works-thanks-kojima/\" target=\"_blank\" data-url=\"https://www.pcgamer.com/hardware/brits-can-get-around-discords-age-verification-thanks-to-death-strandings-photo-mode-bypassing-the-measure-introduced-with-the-uks-online-safety-act-we-tried-it-and-it-works-thanks-kojima/\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\" data-before-rewrite-localise=\"https://www.pcgamer.com/hardware/brits-can-get-around-discords-age-verification-thanks-to-death-strandings-photo-mode-bypassing-the-measure-introduced-with-the-uks-online-safety-act-we-tried-it-and-it-works-thanks-kojima/\">its 2025 Online Safety Act</a>—who were presented with prompts to consent to age verification processed by the company Persona.</p><p>Sure enough, <a data-analytics-id=\"inline-link\" href=\"https://support.discord.com/hc/en-us/articles/30326565624343-How-to-Complete-Age-Assurance-on-Discord\" target=\"_blank\" data-url=\"https://support.discord.com/hc/en-us/articles/30326565624343-How-to-Complete-Age-Assurance-on-Discord\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">Discord's support article</a> describing its age verification process now features a disclaimer informing UK users that they \"may be part of an experiment where your information will be processed by an age-assurance vendor, Persona.\" And while Discord had previously insisted that facial age verification recordings would only be stored and processed locally, the notice about Persona says that \"the information you submit will be temporarily stored for up to 7 days, then deleted.\"</p><p>While some users have speculated that Discord is testing alternate age verification providers because k-ID—its primary age authentication partner—has proven <a data-analytics-id=\"inline-link\" href=\"https://www.404media.co/free-tool-says-it-can-bypass-discords-age-verification-check-with-a-3d-model/\" target=\"_blank\" data-url=\"https://www.404media.co/free-tool-says-it-can-bypass-discords-age-verification-check-with-a-3d-model/\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">susceptible to creative workarounds</a>, Discord doesn't specify why some users will be processed by Persona instead.</p><figure data-bordeaux-image-check=\"\"><figcaption itemprop=\"caption description\"></figcaption></figure><p>Regardless of the reasoning, the partnership with Persona has compounded concerns about privacy due to the company's investors. In its two <a data-analytics-id=\"inline-link\" href=\"https://www.forbes.com/sites/rashishrivastava/2025/04/30/ai-is-making-the-internets-bot-problem-worse-this-2-billion-startup-is-on-the-front-lines/\" target=\"_blank\" data-url=\"https://www.forbes.com/sites/rashishrivastava/2025/04/30/ai-is-making-the-internets-bot-problem-worse-this-2-billion-startup-is-on-the-front-lines/\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">most recent</a> rounds of <a data-analytics-id=\"inline-link\" href=\"https://www.bloomberg.com/news/articles/2021-09-15/founders-fund-values-identity-startup-persona-at-1-5-billion\" target=\"_blank\" data-url=\"https://www.bloomberg.com/news/articles/2021-09-15/founders-fund-values-identity-startup-persona-at-1-5-billion\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">venture capital funding</a>, its lead investor has been Founders Fund—the venture fund co-founded and directed by Peter Thiel.</p><p>And listen, I know people harp on this a lot, but it's a company <em>literally named after an orb that lets the most evil force in the world spy on your thoughts.</em></p><p>If that's not enough for you to be unsettled by Thiel's money being involved in Discord's age verification rollout, the billionaire—who <a data-analytics-id=\"inline-link\" href=\"https://www.cato-unbound.org/2009/04/13/peter-thiel/education-libertarian/\" target=\"_blank\" data-url=\"https://www.cato-unbound.org/2009/04/13/peter-thiel/education-libertarian/\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">infamously wrote</a> \"I no longer believe that freedom and democracy are compatible\" in 2009—appeared <a data-analytics-id=\"inline-link\" href=\"https://www.wired.com/story/epstein-files-tech-elites-gates-thiel-musk/\" target=\"_blank\" data-url=\"https://www.wired.com/story/epstein-files-tech-elites-gates-thiel-musk/\" referrerpolicy=\"no-referrer-when-downgrade\" data-hl-processed=\"none\" data-mrf-recirculation=\"inline-link\">more than 2,200 times</a> in the latest release of the Epstein files, where he coordinated years of meetings with the convicted child predator and sex trafficker.</p>","contentLength":2783,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47011346"},{"title":"An AI agent published a hit piece on me – more things have happened","url":"https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/","date":1771029473,"author":"scottshambaugh","guid":267,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47009949"}],"tags":["dev"]}