{"id":"VMK7D8tQvwsLtnxKHzNdF9c4Yhtuqm","title":"Hacker News: Best","displayTitle":"HN","url":"https://hnrss.org/best","feedLink":"https://news.ycombinator.com/best","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":30,"items":[{"title":"A 10x Faster TypeScript","url":"https://devblogs.microsoft.com/typescript/typescript-native-port/","date":1741703543,"author":"DanRosenwasser","guid":249,"unread":true,"content":"<p>Today I’m excited to announce the next steps we’re taking to radically improve TypeScript performance.</p><p>The core value proposition of TypeScript is an excellent developer experience.\nAs your codebase grows, so does the value of TypeScript itself, but in many cases TypeScript has not been able to scale up to the very largest codebases.\nDevelopers working in large projects can experience long load and check times, and have to choose between reasonable editor startup time or getting a complete view of their source code.\nWe know developers love when they can rename variables with confidence, find all references to a particular function, easily navigate their codebase, and do all of those things without delay.\nNew experiences powered by AI benefit from large windows of semantic information that need to be available with tighter latency constraints.\nWe also want fast command-line builds to validate that your entire codebase is in good shape.</p><p>To meet those goals, we’ve begun work on a native port of the TypeScript compiler and tools.\nThe native implementation will <strong>drastically improve editor startup, reduce most build times by 10x, and substantially reduce memory usage</strong>.\nBy porting the current codebase, we expect to be able to preview a native implementation of  capable of command-line typechecking by mid-2025, with a feature-complete solution for project builds and a language service by the end of the year.</p><p>You can , which is offered under the same license as the existing TypeScript codebase.\nCheck the README for instructions on how to build and run  and the language server, and to see a summary of what’s implemented so far.\nWe’ll be posting regular updates as new functionality becomes available for testing.</p><p>Our native implementation is already capable of loading many popular TypeScript projects, including <a href=\"https://github.com/microsoft/TypeScript/tree/main/src/compiler\">the TypeScript compiler itself</a>.\nHere are times to run  on some popular codebases on GitHub of varying sizes:</p><table><thead><tr></tr></thead></table><p>While we’re not yet feature-complete, these numbers are representative of the order of magnitude performance improvement you’ll see checking most codebases.</p><p>We’re incredibly excited about the opportunities that this massive speed boost creates. Features that once seemed out of reach are now within grasp.\nThis native port will be able to provide instant, comprehensive error listings across an entire project, support more advanced refactorings, and enable deeper insights that were previously too expensive to compute.\nThis new foundation goes beyond today’s developer experience and will enable the next generation of AI tools to enhance development, powering new tools that will learn, adapt, and improve the coding experience.</p><p>Most developer time is spent in editors, and it’s where performance is most important.\nWe want editors to load large projects quickly, and respond quickly in all situations.\nModern editors like Visual Studio and Visual Studio Code have excellent performance as long as the underlying language services are also fast.\nWith our native implementation, we’ll be able to provide incredibly fast editor experiences.</p><p>Again using the Visual Studio Code codebase as a benchmark, the current time to load the entire project in the editor on a fast computer is about 9.6 seconds.\nThis drops down to about 1.2 seconds with the native language service, an <strong>8x improvement in project load time</strong> in editor scenarios.\nWhat this translates to is a faster working experience from the time you open your editor to your first keystroke in any TypeScript codebase.\nWe expect all projects to see this level of improvement in load time.</p><p>Overall memory usage also appears to be roughly half of the current implementation, though we haven’t actively investigated optimizing this yet and expect to realize further improvements.\nEditor responsiveness for all language service operations (including completion lists, quick info, go to definition, and find all references) will also see significant speed gains.\nWe’ll also be moving to the Language Server Protocol (LSP), a longstanding infrastructural work item to better align our implementation with other languages.</p><p>Our most recent TypeScript release was TypeScript 5.8, with TypeScript 5.9 coming soon.\nThe JS-based codebase will continue development into the 6.x series, and TypeScript 6.0 will introduce some deprecations and breaking changes to align with the upcoming native codebase.</p><p>When the native codebase has reached sufficient parity with the current TypeScript, we’ll be releasing it as .\nThis is still in development and we’ll be announcing stability and feature milestones as they occur.</p><p>For the sake of clarity, we’ll refer to them simply as TypeScript 6 (JS) and TypeScript 7 (native), since this will be the nomenclature for the foreseeable future.\nYou may also see us refer to “Strada” (the original TypeScript codename) and “Corsa” (the codename for this effort) in internal discussions or code comments.</p><p>While some projects may be able to switch to TypeScript 7 upon release, others may depend on certain API features, legacy configurations, or other constraints that necessitate using TypeScript 6.\nRecognizing TypeScript’s critical role in the JS development ecosystem, we’ll still be maintaining the JS codebase in the 6.x line until TypeScript 7+ reaches sufficient maturity and adoption.</p><p>Our long-term goal is to keep these versions as closely aligned as possible so that you can upgrade to TypeScript 7 as soon as it meets your requirements, or fall back to TypeScript 6 if necessary.</p><p>In the coming months we’ll be sharing more about this exciting effort, including deeper looks into performance, a new compiler API, LSP, and more.\nWe’ve written up some <a href=\"https://github.com/microsoft/typescript-go/discussions/categories/faqs\">FAQs</a> on the GitHub repo to address some questions we expect you might have.\nWe also invite you to join us for an AMA at the <a href=\"https://discord.gg/typescript\">TypeScript Community Discord</a> at  on March 13th.</p><p>A 10x performance improvement represents a massive leap in the TypeScript and JavaScript development experience, so we hope you are as enthusiastic as we are for this effort!</p>","contentLength":6051,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43332830"},{"title":"Happy 20th birthday, Y Combinator","url":"https://twitter.com/garrytan/status/1899092996702048709","date":1741702475,"author":"btilly","guid":248,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43332658"},{"title":"Show HN: Factorio Learning Environment – Agents Build Factories","url":"https://jackhopkins.github.io/factorio-learning-environment/","date":1741694522,"author":"noddybear","guid":203,"unread":true,"content":"<p>I'm Jack, and I'm excited to share a project that has channeled my Factorio addiction recently: the Factorio Learning Environment (FLE).</p><p>FLE is an open-source framework for developing and evaluating LLM agents in Factorio. It provides a controlled environment where AI models can attempt complex automation, resource management, and optimisation tasks in a grounded world with meaningful constraints.</p><p>A critical advantage of Factorio as a benchmark is its unbounded nature. Unlike many evals that are quickly saturated by newer models, Factorio's geometric complexity scaling means it won't be \"solved\" in the next 6 months (or possibly even years). This allows us to meaningfully compare models by the order-of-magnitude of resources they can produce - creating a benchmark with longevity.</p><p>The project began 18 months ago after years of playing Factorio, recognising its potential as an AI research testbed. A few months ago, our team (myself, Akbir, and Mart) came together to create a benchmark that tests agent capabilities in spatial reasoning and long-term planning.</p><p>Two technical innovations drove this project forward: First, we discovered that piping Lua into the Factorio console over TCP enables running (almost) arbitrary code without directly modding the game. Second, we developed a first-class Python API that wraps these Lua programs to provide a clean, type-hinted interface for AI agents to interact with Factorio through familiar programming paradigms.</p><p>Agents interact with FLE through a REPL pattern:\n1. They observe the world (seeing the output of their last action)\n2. Generate Python code to perform their next action\n3. Receive detailed feedback (including exceptions and stdout)</p><p>We provide two main evaluation settings:\n- Lab-play: 24 structured tasks with fixed resources\n- Open-play: An unbounded task of building the largest possible factory on a procedurally generated map</p><p>We found that while LLMs show promising short-horizon skills, they struggle with spatial reasoning in constrained environments. They can discover basic automation strategies (like electric-powered drilling) but fail to achieve more complex automation (like electronic circuit manufacturing). Claude Sonnet 3.5 is currently the best model (by a significant margin).</p><p>You'll need:\n- Factorio (version 1.1.110)\n- Docker\n- Python 3.10+</p><p>The README contains detailed installation instructions and examples of how to run evaluations with different LLM agents.</p><p>We would love to hear your thoughts and see what others can do with this framework!</p>","contentLength":2527,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43331582"},{"title":"Show HN: Seven39, a social media app that is only open for 3 hours every evening","url":"https://www.seven39.com/","date":1741655110,"author":"mklyons","guid":202,"unread":true,"content":"<p>Because social media is better when we're all online together.</p><p>No endless scrolling. No FOMO. Just 3 hours of fun every evening.</p><p>The domain was available.</p>","contentLength":152,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43328095"},{"title":"uBlock Origin is no longer available on the Chrome Store","url":"https://chromewebstore.google.com/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm?hl=en","date":1741627834,"author":"non-","guid":247,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43322922"},{"title":"Music labels will regret coming for the Internet Archive, sound historian says","url":"https://arstechnica.com/tech-policy/2025/03/music-labels-will-regret-coming-for-the-internet-archive-sound-historian-says/","date":1741624124,"author":"coloneltcb","guid":246,"unread":true,"content":"<p>But David Seubert, who manages sound collections at the University of California, Santa Barbara library, told Ars that he frequently used the project as an archive and not just to listen to the recordings.</p><p>For Seubert, the videos that IA records of the 78 RPM albums capture more than audio of a certain era. Researchers like him want to look at the label, check out the copyright information, and note the catalogue numbers, he said.</p><p>\"It has all this information there,\" Seubert said. \"I don't even necessarily need to hear it,\" he continued, adding, \"just seeing the physicality of it, it's like, 'Okay, now I know more about this record.'\"</p><p>Music publishers suing IA argue that all the songs included in their dispute—and likely many more, since the Great 78 Project spans 400,000 recordings—\"are already available for streaming or downloading from numerous services.\"</p><p>\"These recordings face no danger of being lost, forgotten, or destroyed,\" their filing claimed.</p><p>But Nathan Georgitis, the executive director of the Association for Recorded Sound Collections (ARSC), told Ars that you just don't see 78 RPM records out in the world anymore. Even in record stores selling used vinyl, these recordings will be hidden \"in a few boxes under the table behind the tablecloth,\" Georgitis suggested. And in \"many\" cases, \"the problem for libraries and archives is that those recordings aren't necessarily commercially available for re-release.\"</p><p>That \"means that those recordings, those artists, the repertoire, the recorded sound history in itself—meaning the labels, the producers, the printings—all of that history kind of gets obscured from view,\" Georgitis said.</p><p>Currently, libraries trying to preserve this history must control access to audio collections, Georgitis said. He sees IA's work with the Great 78 Project as a legitimate archive in that, unlike a streaming service, where content may be inconsistently available, IA's \"mission is to preserve and provide access to content over time.\"</p>","contentLength":1996,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43322245"},{"title":"Canon EF and RF Lenses – All Autofocus Motors","url":"https://exclusivearchitecture.com/03-technical-articles-CLT-12-autofocus-systems.html","date":1741612358,"author":"ExAr","guid":245,"unread":true,"content":"<div><div><div><p>The introduction of automatically focusing lenses has changed photography in numerous ways. Autofocus systems have significantly improved the reliability and accuracy with which fast moving objects can be shot. Round four decades ago, the new level of convenience offered by autofocus lenses has made photography more accessible to the masses. Since their first release of an autofocus lens in 1981, Canon has constantly developed their lens technology using different approaches. Over time, Canon has introduced seven different autofocus motor technologies that will be presented here.</p></div></div></div><div><p>In optics, focus describes the point at which incoming light rays converge and it is used synonymously as a concept of sharpness. Autofocus, by contrast, is a technology to automatically focus the lens at a desired subject. The <a href=\"https://exclusivearchitecture.com/03-technical-articles-DSLR-03-autofocus-systems.html\">autofocus detection system</a> inside the camera determines the ideal focusing lens position and instructs the lenses autofocus drive accordingly. In 1987, Canon has introduced both the EOS camera system and EF lenses which have been designed with autofocus as standard features. There have been some Canon autofocus lenses available before that date, but these have been discontinued with the introduction of EF lenses. For this reason, this chapter concentrates on all autofocus motor types that are used in EF, EF-S, EF-M, RF, and RF-S lenses that are marketed still today.</p></div><div><div><div><p>The autofocus group of lens elements always shifts along the optical axis in a linear way. While focusing automatically, the movement is generated by some type of actuator. Autofocus actuators can basically be divided into two categories:</p><ol><li> These generate a rotation that is translated into a linear sliding motion via precision mechanics. One common transmission type uses a focusing barrel with helical slots. The focusing group of lens elements is engaged with these slots and slides forwards or backwards axially when the helical slot barrel is turned. Another possible transmission type uses a lead screw with a lead nut that connects to the focusing group of lens elements.</li><li> Also called direct-drive systems. These perform a sliding movement that does not have to be translated. The focusing group of lens elements is directly connected to the linear actuator.</li></ol><p>The first types of autofocus drive systems used rotary movement and these include the Arc-Form Drive, Ring-Type USM, DC Micro Motor, Micro USM, Micro USM II, and Stepper Motor. Later, the switch was made to linear drives which include the Nano USM and the Voice Coil Motor. The following comparison chart shows all of the autofocus drive types that have ever been used in Canon's EF, EF-S, EF-M, RF, and RF-S lenses.</p></div></div><div><div><ul><li>The date indicates when a particular type of motor was first used in a lens. While some of the early types like the Arc-Form Drive have been discontinued, most other types are still in use today.</li><li>If an autofocus Canon lens has no indication on its barrel about the autofocus technology used, the lens either has an AFD or DC Micro Motor installed.</li><li>Note how the indication on lens barrels is often just USM but the exact type of built-in motor can be different. This is because Canon's USM autofocus drive system comprises several different mechanism families, the ring-type USM, the Micro USM (I and II), and the linear Nano USM. All USM drives use piezoelectric technology but with some variations.</li><li>The introduction date of Canon's STM autofocus motor coincides with the introduction date of their EF-M mount system. All of Canon's EF-M lenses are equipped with the Stepper Motor technology.</li></ul></div><div><h2>Full-Time Manual Focus (FTM) Override</h2><p> One key differentiator between these technologies is the capability of a lens to allow full-time manual (FTM) focus override. The ring-type ultrasonic Motor was the first autofocus system that allowed FTM focus override. Until 2012, most other lenses did not offer this type of manual focusing while autofocus is activated. The latest types of autofocus drives, including the Stepper Motor, Nano USM, and Voice Coil Motor, offer focus-by-wire. This is a concept where the manual focusing ring on the lens barrel is not mechanically coupled with the focusing group of lens elements but electronically controls the autofocus drive. Lenses that use focus-by-wire always offer full-time manual focus override.</p></div></div></div><div><h2>Arc-Form Drive (AFD)1987 - 1990</h2><p>Originally, the designation AFD stood for autofocus drive. Later, when other autofocus drive systems were introduced, the term was changed into Arc-Form Drive.</p></div><div><div><div><p>The Arc-Form Drive was the first autofocus motor that was used in EF lenses. The assembly included the motor unit, the gear drive, and a transmission that allowed the user to switch between manual focusing and autofocusing. The AFD assembly was shaped like an arc so that it could easily be installed inside a cylindrical lens barrel.</p><h2>Lenses with Arc-Form Drives</h2><ul><li>Canon EF 15mm F2.8 Fisheye (1987)</li><li>Canon EF 24mm F2.8 (1988)</li><li>Canon EF 28mm F2.8 (1987)</li><li>Canon EF 50mm F1.8 (1987)</li><li>Canon EF 50mm F2.5 Compact Macro (1987)</li><li>Canon EF 135mm F2.8 Softfocus (1987)</li></ul></div></div><div><div><p>The illustration shows an Arc-Form Drive inside a Canon EF 50mm F2.5 Compact Macro lens. The unit is driven by a 2-phase bipolar asymmetric stepper motor that consists of a stator core, two electromagnetic coils (each coil is also referred to as a phase), and a permanent magnet rotor. The bipolar construction of the motor allows current to flow through each coil in both directions. The term asymmetric refers to the shape of the stator that is not rotationally symmetric as in conventional stepper motors (but it is axially symmetrical though).</p><p>The motor drives a reduction gear train that has the purpose of reducing the output gear's speed but at the same time increase the torque of that gear. A lever is used to shift the output gear in one of two possible positions where it either engages with the gear train or with the manual input gear that is connected to the manual focusing ring of the barrel.</p><p>Two feedback systems are used to monitor the drive unit during operation. One system is used to confirm proper rotation of the rotor and another system is used to measure the number of turns the unit has performed:</p><ul><li>Two hall effect sensors are placed very closely at the rotor. These can detect changes in magnetic fields and are therefore used to confirm rotor movement.</li><li>An optical encoder wheel with alternating black and reflective zones is attached to one of the gears. An infrared reflective sensor is placed so that it can read the number of steps that the encoder wheel turns (each transition between two zones is a step). This provides crucial feedback to the lens controller as autofocus instructions typically include a predefined number of steps an autofocus motor has to move into a certain direction.</li></ul></div></div><div><div><p>The illustration is a front view of the stepper motor with the cover removed. The rotor has two magnetic polarities opposite to each other, north and south. The stator consists of two phases that are colored in cyan and green for reasons of better explainability. The stator cores run through the phase coils to conduct the electromagnetic flux towards the rotor.</p></div></div><div><div><p>During autofocus operation, the wire coils are excited via electrical impulses, which in turn magnetizes the stator core. The polarity of the voltage applied to the two coils is changed in a pre-defined sequence. The rotor performs a complete rotation in four steps:</p><ol><li>Phase B coil is turned off. Phase A coil is energized so that the left part of the stator core is magnetized, attracting the rotor to perform a rotation. (This is a 90 degree clockwise rotation if the previous step of the motor was step 4.)</li><li>Phase A coil is turned off. Phase B coil is energized so that the right part of the stator core is magnetized. This attracts the rotor so that it performs a 90 degree clockwise rotation. </li><li>Phase B coil is turned off. Phase A coil is energized with opposite polarity. This magnetizes the left part of the stator core again, but this time with opposite magnetic polarity. The rotor is attracted again so that it performs another 90 degree clockwise rotation.</li><li>Phase A coil is turned off. Phase B coil is energized with opposite polarity. This magnetizes the right part of the stator core again, but this time with opposite magnetic polarity. This induces the rotor to perform another 90 degree clockwise rotation.</li></ol><p>The sequence of steps is repeated as long as the rotor is required to turn. If the sequence is run in reverse from step 4 to step 1, the rotor turns counter-clockwise. The diagram summarizes these four steps.</p></div></div><div><div><p>The AFD motor was designed with a transmission element that is also the output gear, the one that actually drives the helical focusing barrel. Note how the focusing barrel has a wide gear rim along its perimeter that allows the transmission element to shift a certain amount while always remaining engaged with the focusing barrel. The metal lever is connected to the MF/AF switch on the lens barrel and it shifts the transmission element so that it connects the output gear either with the motorized gear train or with the manual input gear. If the output gear is connected to one option, it is disengaged from the other option. For that reason, the Arc-Form Drive does not have full-time manual focus override available.</p><p>In terms of overall performance and usability, the Arc-Form Drive is considered to be noisy during operation and slower than other autofocus drives. When following moving subjects, the system shows a noticeable reaction time. Lenses with an Arc-Form Drive have to sequentially focus and then stop down the aperture diaphragm. All other lenses with different autofocus motors are able to operate the autofocus motor and aperture diaphragm at the same time. Despite these weaknesses, AFD lenses still offer reliable autofocusing performance.</p></div></div></div><div><h2>Ring-Type Ultrasonic Motor (USM)1987 - Present</h2><p>Canon's ultrasonic motors are very exceptional types of actuators. They neither have electromagnetic coils or magnetic rotors, so their motion is not generated by magnetism like in traditional motors. Instead, they use an ingenious combination of piezoelectric effects and friction. Introduced in November 1987 with the Canon EF 300mm F2.8L USM lens, the ring-type USM was the first implementation of this piezoelectric technology in photographic lenses, and in the years that followed, some different types of USM drives would appear.</p></div><div><div><div><p>Canon's ring-type ultrasonic motor – as the name suggests – is shaped like a ring and, for that reason, fits perfectly inside the lens barrel. The optical system of the lens runs through the opening of that construction. At the time of its advent, this new technology was groundbreaking in its design and functionality, being ultra-fast and silent. They provide a high level of torque powerful enough to move even heavy groups of focusing lens elements inside super-telephoto lenses. Due to their high torque, no speed-reducing gear train is required when connecting the motor to the focusing mechanism. The ring-type USM has high holding torque maintained at zero input power and offers low inertia from its rotor providing rapid start and stop characteristics. In addition, this type of drive technology is unaffected by electromagnetic fields.</p></div></div><div><div><p>The ring-type USM can be divided into the rotor, the piezoelectric stator, and various support rings.</p><ul><li>The rotor is the only part of this motor that actually rotates around the optical axis while the USM is in operation. The rotor itself is a compound of metal and plastic parts bonded together. The rotor has a sliding rail on the side facing the stator.</li><li>The stator is an elastic metal body. In this context, elastic refers to the ability of the stator to oscillate to a certain extent, similar to a tuning fork. The stator has a ring of piezoelectric ceramic elements welded to its back (away from the rotor). Once this layer is electrically excited, it sets the stator into vibration. The vibrational energy is then transferred into the rotor via friction. Apart from its vibration, the stator does not move.</li><li>A felt ring is used to protect the sensitive piezoelectric layer from the metal support rings that are pressed against the stator, and to dampen the vibrations from being transmitted into the lens barrel.</li><li>The ring-type USM motor only works when the stator is firmly pressed against the rotor. The compression spring is what exerts this pressure on both the stator and rotor. This spring is an important part that ensures proper functionality of the ring-type USM.</li><li>the lock ring is an interface part that holds all parts of the unit tightly together. Three indents on the inner circumference of the lock ring slide into slots of an inner lens barrel, securing the ring in place.</li></ul></div></div><div><div><p>The following illustration is a cross-sectional view of the ring-type USM when it is fully assembled. The piezoelectric layer is what generates vibrations. A flex cable connects the piezoelectric elements with the lens circuit board, and therefore provides power to this element. Once the unit is installed inside a lens barrel, a dedicated contact surface on the rotor pushes against wheels on an output ring (not shown in this illustration) that ultimately drives the focusing mechanism.</p><p>The compression spring creates a tension that is also referred to as preload force. Flat surface finishes of the sliding rail and the stator teeth ensure a good friction coefficient between rotor and stator. The preload force and the friction between the rotor and the stator determine the passive holding torque of the motor at zero power input.</p></div></div><div><div><p>Canon uses stator rings of two different sizes. The medium sized stator has an outer diameter of 62&nbsp;mm, and the larger sized stator has an outer diameter of 77&nbsp;mm. There is a huge number of Canon lenses that use ring-type ultrasonic motors as their autofocus drives. The following list is only a very short excerpt:</p></div><div><ul><li>Canon EF 200mm F2.8 L II USM</li></ul><ul><li>Canon EF 400mm F2.8 L IS USM</li><li>Canon EF 600mm F4 L IS USM</li></ul></div></div><div><div><h2>The Piezoelectric Ceramic Ring</h2><p>The operation of the motor requires the stator to vibrate in a very precise way. This vibration is generated by a segmented piezoelectric ceramic ring that is welded to the back of the elastic stator body. The illustration of the piezoelectric array shows the distribution and configuration of piezo elements on the ring.</p><p>The individual piezo elements are grouped together into groups A and B. Each group can be energized individually, and set the ring into vibration to form a standing wave with wavelength λ. Two piezo elements cover one full wavelength λ, and therefore each single piezo element has a length of λ/2. One of the key factors to ensure proper wave excitation in the stator is that both piezo groups are offset by λ/4 as shown in the illustration. This is also referred to as a <b>spatial phase shift of λ/4</b>.</p></div></div><div><div><p>Piezoelectric ceramic elements are sandwiched between two electrodes. Electrode 1 is in direct contact with the metal stator ring and serves as ground (GND). In the following illustration, the lower electrodes of all piezo elements are covered by a layer of silver conductive adhesive so these elements are electrically connected to one group.</p><p>The piezoelectric ceramic elements have the property to deform when an electrical field is applied, an effect also described as the inverse piezoelectric effect. The direction in which piezo elements deform is defined by their piezoelectric polarization, expressed via positive and negative signs in this slightly simplified diagram. Depending on the polarity of the voltage applied across the electrodes, the individual piezo elements bend upwards or downwards. As piezo elements are arranged with alternating piezoelectric polarities, energizing the piezoceramic layer shapes the stator into a waveform. When the electrodes are subject to an alternating voltage of high frequency, the stator ring begins to oscillate. The amplitude of these oscillations is as small as 1-2&nbsp;µm.</p></div></div><div><div><h2>Piezo Group A is Energized</h2><p>For the sake of better understanding, the two piezoelectric groups are viewed from the top, and energized separately. Piezo group A is fed by a distinct sinusoidal voltage (phase A) while piezo group B remains de-energized. This not only generates a standing wave across group A but the wave unfolds across the entire stator ring. Looking at a snapshot in time, hollow circles indicate valleys in the stator, whereas solid black circles indicate peaks in the stator. Note how the peaks and valleys are exactly at the center of each piezo element of group A, whereas on the opposite side of the ring, peaks and valleys are exactly between the piezo elements. Over the course of one sine oscillation, peaks will turn into valleys and back into peaks. At the same time valleys turn into peaks and back into valleys. A clear standing wave is formed only if the excitation frequency is equal to the natural flexural vibration resonant frequency of the stator. The resonant frequency of Canon's ring-type USM is approximately 27,000&nbsp;Hz (oscillations per second). This frequency is in the ultrasonic range, which is why this type of autofocus technology is called ultrasonic. Enlarging the illustration shows an animation of phase A generating a standing wave.</p></div></div><div><div><h2>Piezo Group B is Energized</h2><p>Now piezo group B is fed by a distinct sinusoidal voltage (phase B) while piezo group A remains de-energized. Again, a standing wave is generated and unfolds across the entire stator ring. This time, peaks (hollow circles) and valleys (solid black circles) are at the center of each piezo element of group B, whereas on the opposite side of the ring, peaks and valleys are exactly between the piezo elements. This shows that the two standing waves generated by group A and B are not congruent. Enlarging the illustration shows an animation of phase B generating a standing wave.</p></div></div><div><div><h2>Both Groups are Energized</h2><p>When both piezo groups are energized at the same time, their vibration-induced standing waves are combined and form a new wave. When phase A and phase B are shifted by a quarter of a sine wavelength λ – called a <b>temporal phase shift of λ/4</b> – the resulting wavelength is a traveling wave. This temporal phase shift can be achieved, for example, by using a sine wave for phase A and a cosine wave for phase B. Unlike a standing wave, the peaks and valleys of a traveling wave move around the circumference of the stator ring similar to waves on the surface of water. This traveling wave is the source of the motor’s rotational energy. Enlarging the illustration shows an animation of both phases generating a traveling wave.</p><p> The sign of the temporal phase shift determines the propagating direction of the traveling wave, and  consequently also the rotating direction of the rotor. The stator has teeth cut into the material, and these are designed to amplify the movement of the ring.</p></div></div><div><div><p>Not all piezo elements on the stator ring are used to generate waves. One small piezo element is located between the wave-generating piezo groups A and B and it serves as a sensor to measure the intensity of stator oscillations. Like all other piezo elements, the sensor element is sandwiched between two electrodes 1 and 2 (not shown in the illustration). Electrode 1 is directly connected to the metal stator body and serves as ground, whereas electrode 2 is on the opposite side and connects to the sensor line.</p><p>It was described earlier that applying a voltage to a piezo element generates a deformation of that element, referred to as the inverse piezoelectric effect. The actual (non-inverted) piezoelectric effect, however, is that pressure or deformation (such as bending) of the piezo element will generate an electric voltage. Consequently, the piezo's electrical output reflects the wave amplitude of the stator at its location. This signal is picked up by the control circuitry and can be used to adjust the frequencies of phases A and B accordingly.</p><p>This feedback control system is required to monitor the proper excitation of the stator ring, and to achieve maximum amplitude of the traveling wave. The maximum amplitude can only be attained when the wave-generating phases precisely hit the natural resonance frequency of the stator body. That natural resonance frequency may vary from unit to unit due to small production related variations in dimensions, and for a given unit the natural resonance will vary with the temperature of the stator.</p></div></div><div><div><p>The illustration of the stator ring's electric connections shows a piece of flex cable (copper wire traces laminated onto a thin film) attached to the back of the stator ring.\n                \n            All piezo elements – both wave generating elements and the sensor element – have electrodes that are in direct contact with the conductive stator ring. The GND wire is directly connected to the metal stator body, and therefore all piezo elements share the metal body as a common ground connection. The phase A wire is connected to the exposed electrode of the first piezo element of group A, and a thin film of silver conductive adhesive electrically connects all other elements of phase A with the first element. The phase B wire is connected to phase B in a similar way. The sensor wire is connected to the exposed electrode of the sensor element.</p></div></div><div><div><h2>Inactive Stator – Excited Stator</h2><p>The following illustration shows 3D models of the ring-type USM stator. On the inactive stator ring, all teeth are in the same plane, allowing the stator to rest flat on the rotor. In this flat condition, the focusing lens group is automatically held in place due to the strong friction (similar to a disc brake). Once the stator is excited, it forms a traveling wave, here greatly exaggerated for the sake of clarification. The number of waves per cycle depends on the configuration of piezo elements. In this example, there are nine waves per cycle, but Canon also uses stators that form seven waves. The number n of waves formed on the stator means that one particular wave peak requires n excitation periods to completely travel around the stator one time.</p></div></div><div><div><h2>Traveling Wave of the USM Stator</h2><p>The animation shows nine waves traveling across the stator ring in a very slowed-down form. It is clearly visible that the stator itself does not turn around its axis but only the peaks and valleys move as it performs this undulating vibration.</p></div></div><div><div><p>The generation of a traveling wave can be considered as the first step in a two-step energy conversion process. The second step is the stator teeth transmitting their vibrational energy into a unidirectional continuous movement of the rotor via friction. Looking very closely at the stator teeth, the traveling wave induces elliptical motions at the tips of each tooth. In the animation, only one elliptical path of one tooth is shown, but all the other teeth carry out identical elliptical motions. Where the traveling wave forms peaks, the teeth are pressed against the rotor and push it in the direction of the elliptical motion. As a result, the rotor moves in the opposite direction of the traveling wave.</p><p>It can be calculated how fast the traveling wave propagates. It is assumed in this example that 27,000 Hz  is exactly the natural resonance frequency of the stator ring. With nine peaks formed across the stator, it requires nine excitation periods for one peak to completely run around the stator ring one time. Thus, if the excitation frequency is at 27,000 Hz, one peak will travel a full revolution around the stator ring 3,000 times per second. Although the peaks travel at an extremely fast speed, the speed of the rotor is comparatively low. The rotor typically turns at a rate of 70-90 revolutions per minute, if excited continuously. The speed can be lowered by exciting the stator via pulse-width modulation. The microscopic oscillations of the tooth tips are the reason why the ratio between rotor speed and traveling wave speed is very low. This low ratio is actually an advantage as no speed-reducing gearbox is required, and the rotor can be directly coupled to the focusing mechanism of the lens barrel.</p></div></div><div><div><h2>The Working Principle Summarized</h2><p>The ring-type ultrasonic motor operates a two-stage energy conversion process: In a first stage, electrical energy is converted into an undulating motion by the piezoelectric elements of the stator. In a second stage, these ultrasonic vibrations at around 27 kHz are converted into a continuous unidirectional rotating movement of the rotor by friction on the stator.</p><p>The traveling wave is generated by two main factors: Two groups of piezoceramic elements must be arranged with a spatial phase shift of λ/4, and these two groups must be energized with a temporal phase shift of λ/4. The elliptical motion of the stator teeth is transferred into the rotor due to friction between the stator and rotor, caused by the pressure contact (preload force) between stator and rotor.\n            Friction between stator and rotor.</p></div><div><p>Although being extremely well suited for photographic camera lenses, these motors show some drawbacks:</p><ul><li>This type of motor is not designed for continuous operation. Due to the friction involved, its life expectancy is lower than that of conventional electric motors.</li><li>Although the ultrasonic noise cannot be perceived by the human ear, it can be picked up by sensitive microphones which can be problematic during video shootings.</li><li>Ring-type USM motors are comparatively expensive to produce: The stator ring including all of its teeth are precisely cut by CNC milling machines. The production and application of piezoceramics is another difficult process. In addition, this type of autofocus motor requires complex power supply and driving circuits including high frequency generation and feedback control system.</li></ul></div></div><div><div><p>It was described in the beginning of this chapter that the ring-type ultrasonic motor was the first autofocus system that allowed full-time manual focus override. This is not a function of the ultrasonic drive unit itself, but rather of the cleverly designed differential mechanism.</p><p>The challenge with the implementation of full-time manual focusing in general is that the user must be able to manually override the autofocus system (by turning the focusing ring on the barrel) without forcing the motor or grinding the gears. The ring-type USM prevents this from happening via an additional output ring that connects to the focusing group of lenses via a link bracket. Once this output wheel is turned, the focusing group adjusts the focusing distance of the lens. They key feature of this output ring is that it has three small wheels installed along its outer periphery. These wheels are sandwiched between the two input options – the manual input ring and the motor input ring (the USM stator). This is a rotary differential mechanism, and it allows either one of these input options to turn the output ring without exerting a force on the other input option. For that reason, the manual focusing ring can be turned without forcing the rotor into any direction. Due to this rotary differential, full-time manual focusing has become a standard feature on all lenses with a ring-type ultrasonic motor.</p></div></div><div><div><p>The following illustration shows the output wheel with its small carrier wheels. The top right shows a schematic of both input options (manual input and motor input) and how they are arranged in the lens barrel. Note that due to the differential construction the output wheel does not turn at the same speed as the input wheels, but at a speed defined by the formula: v&nbsp;=&nbsp;&nbsp; where v refers to the speed of the manual input ring and v refers to the speed of the motor input ring. If one of the input rings is not moving (which is normally the case), the output speed v is half of the input speed.</p></div></div><div><div><p>This diagram is a front view of the rotary differential mechanism. It is clearly visible how the mechanical link is established between the output ring and the focusing lens cell. As the differential mechanism turns around the lens axis, the focusing lens cell is shifted forward or backward, while still remaining engaged with the link bracket via the connecting handle. To ensure smooth movements, Canon uses some lubrification on the sliding elements.</p></div></div></div><div><h2>DC Micro Motor1990 - 2012</h2></div><div><div><div><p>The DC Micro Motor – sometimes abbreviated MM – looks quite similar to the AFD motor. It has almost an identical shape. In addition, the DC Micro Motor also uses a reduction gear train to transmit the motor's power to the focusing lens barrel. However, the type of motor itself is different. Instead of a stepper motor as used in the AFD, this type of autofocus drive uses an ultra-compact direct current (DC) motor. This is an extremely common type of motor, and it is considered to be the least advanced autofocus motor used in Canon lenses along with the AFD. Canon primarily uses the DC Micro Motor in entry-level autofocus lenses. Here are some examples of lenses that use this type of drive system:</p><ul><li>Canon EF-S 18-55mm F3.5-5.6 (2003)</li><li>Canon EF-S 18-55mm F3.5-5.6 II (2005)</li><li>Canon EF 50mm F1.8 II (1990)</li><li>Canon EF 75-300mm F4-5.6 (1991)</li><li>Canon EF 75-300mm F4-5.6 II (1995)</li><li>Canon EF 75-300mm F4-5.6 III (1999)</li></ul></div></div><div><div><p>Once power is supplied to a direct current motor, the rotor starts to turn very fast. For that reason, the gear train attached to the motor uses a high reduction ratio to lower the speed of rotation. At the same time, rotational torque is increased towards the output gear.</p><p>The DC Micro Motor has a lever to shift one gear between two positions. One position closes the gear train so that the motor's rotation is forwarded to the output gear, and the other position interrupts the transmission of rotational force. A tiny metal spring holds this switching gear under slight pressure so that it remains in its default position engaged with the other gears. Only when the AF/MF switch on the barrel is moved to the MF position, the lever shifts the switching gear so that it disconnects from its adjacent gears, disconnecting the motor from the output gear. This type of transmission shows that the DC Micro Motor does not support full-time manual focus override.</p></div></div><div><div><p>An exploded view of the DC Micro Motor shows some more details of the unit. The rotor shaft is connected to a small pulley which drives another pulley via a rubber belt. This belt drive helps reduce vibrations that might be induced by the motor's operation. The larger pulley is connected to the first gear of the reduction gearbox. An encoder wheel with numerous tiny openings alongside its perimeter is attached to the first gear. Each transition between an opening and solid material is one step of the encoder wheel. A sensor runs an infrared beam through one of these openings, and records the signal on the other side. Once the wheel is turned, the signal is interrupted until the next opening where the signal is recorded again. This setup allows the lens electronics to count the number of steps the encoder wheel has turned and thus how far the focusing lens group has been moved.</p></div></div><div><div><p>The exact type of motor is a 2-pole 3-coil brushed DC motor. The description 2-pole refers to the two connection terminals at the back of the motor. These connections directly lead to the two metal brushes that touch the rotor's commutator from opposite sides. This is how electrical power is supplied to the rotor. The description 3-coil indicates that the rotor has three coil windings attached to its metal core. Each of these coils is an electromagnet that can change its polarity.</p></div></div><div><div><p>The following schematic shows the electrical configuration of the rotor. The commutator has three separate contact surfaces, and these are connected to the windings as depicted. As the brushes are 180 degrees apart, they only form electrical connections with two of the contact areas at a given time. This design is the key requirement for the coils to form correctly oriented magnetic fields.</p></div></div><div><div><h2>The DC Motor in Operation</h2><p>The two power terminals of the DC motor are energized with an operating DC voltage between 4 and 6 volts. The metal brushes pass on this voltage to the commutator, which in turn applies that voltage to the coils. The magnetic fields produced at each coil are either repelled or attracted by the stator's permanent magnets. Due to the commutator's design and the wiring configuration, each coil changes its electrical (and therefore magnetic) polarity as soon as it has reached maximum proximity to a permanent magnet. This switches the coils from being attracted to being repelled, ensuring a continuous rotation. This principle allows a small DC motor to run at speeds up to 6.000 rpm. When the voltage polarity of the brushes is reversed, the rotor turns in the opposite direction.</p><p>The advantage of the DC Micro Motor is that it runs on a DC voltage, and therefore does not require any complex driver electronics such as a stepper motor. Nevertheless, the control circuitry must be capable of handling comparatively large currents. Due to its limited torque, the DC Micro Motor is almost always used in compact lenses with smaller and lighter focusing lens groups. Another disadvantage of this autofocus drive is its relatively noisy operation. Nevertheless, it is a reliable autofocus system that is embedded in numerous Canon lenses.</p></div></div></div><div><h2>Micro USM and Micro USM II1992 - 2016</h2><p>The Micro USM and Micro USM II are different members of Canon's ultrasonic motor family. The first generation Micro USM was introduced in 1992. Ten years later in 2002, the second generation Micro USM II followed with an ultra-compact design half the size of the original version.</p></div><div><div><div><p>Canon's Micro USM actuators are small-diameter (11&nbsp;mm) cylindrical ultrasonic motors using piezoelectric ceramic elements to generate oscillations. Compared to the <a href=\"https://exclusivearchitecture.com/03-technical-articles-CLT-12-autofocus-systems.html#QJ_POS_02\">ring-type USM</a>, the Micro USM uses an ultra-compact design. The original Micro USM version has an overall length of 26.7&nbsp;mm whereas the Micro USM II is just 13.4&nbsp;mm long. Both versions of the Micro USM have an output gear that engages with a speed-reducing and torque-increasing gearbox that is connected to the focusing cam barrel.</p><p>The Micro USM motor in general is a stack of different parts pressed together via a metal shaft. The motor can be divided into the rotor, the stator, and some auxiliary parts and support structures. The attachment flange is usually described as the top of the unit.</p></div></div><div><div><div><a href=\"https://exclusivearchitecture.com/images/technical-articles/CLT/12_autofocus_systems/27_Micro_USM_Exploded_View.png\" data-lightbox=\"Large_Gallery\" data-title=\"Micro USM\"><img src=\"https://exclusivearchitecture.com/images/technical-articles/CLT/12_autofocus_systems/27_Micro_USM_Exploded_View.png\" alt=\"\"></a><p>The illustration shows an exploded view of the Micro USM unit (original version) inside a Canon EF lens.</p></div></div><div><ul><li>A flexible metal shaft has threads cut into both ends so that retaining nuts and discs can be screwed on to hold the entire stack of parts together. An attachment flange is used on the top of the motor to allow the Micro USM to be installed in the gearbox of the autofocus mechanism.</li><li>The metal rotor has two slots on one side where it engages with two protrusions on the surface of the output gear wheel. Therefore, every movement of the rotor is transmitted directly to the output gear wheel. On the opposite side, the rotor has a tiny lip (seen on the cross-sectional view) where it forms a pressure contact with one of the stator's oscillators. The pressure is formed by a small spring that is directly pushing onto the rotor from the top side.</li><li>The stator consists of a laminated piezoelectric element (LPE) that is sandwiched between two oscillators. These oscillators are cylindrical metal bodies that are pressed flat against the adjacent parts. The stator's oscillator 2 is held in place by a threaded disc. This threaded disc is omitted on the Micro USM II, as in this version the oscillator 2 is designed with an own thread.</li></ul></div></div><div><div><h2>The Principle of Operation</h2><p>Both versions of Micro USM autofocus drives use piezoelectric elements to generate ultrasonic vibrations in the stator. While this principle is similar to the ring-type USM, the Micro USM type of motors use an entirely different stator design. \n                \n            </p><h2>The Laminated Piezoelectric Element (LPE)</h2><p>The Micro USM uses piezoceramic discs to generate ultrasonic vibrations in the stator. As the vibrations of each individual disc are extremely small in amplitude, a stack of round 25 discs is laminated to a solid piezoceramic part. The resulting multi-layer cylindrical unit is called the laminated piezoelectric element (LPE). The illustration is a schematic view of one piezoceramic disc.</p><p>The two halves of these discs have been polarized in opposite directions. Each disc has four electrodes attached to either side, two on each half. This allows the discs to be energized in two phases A and B. If an electric voltage is applied to one phase, the electric field that forms across the electrodes causes one quarter of the disc to expand and one quarter to contract. This electrically induced deformation of piezoceramic material is referred to as the inverse piezoelectric effect. The reaction of piezoceramic material is roughly 10 times higher in the expanding way rather than in the contracting way. In the illustration, the level of deformation is hugely exaggerated to illustrate the principles involved.</p></div></div><div><div><p>The illustration shows the arrangement of discs inside the laminated piezoelectric element, and how electrical power is supplied to each disc. Layers with even numbers have their A+/- and B+/- electrodes on their top, while layers with uneven numbers (except for the first one) have AG and BG electrodes on their top. Each disc has a number of through-holes, tiny conductive paths that establish electrical connections between the different layers. Note how some electrodes are shaped with recesses so that there is enough space for through-holes into deeper layers of the stack. The discs and through-holes are arranged so that energizing the A-phase (applying a voltage between the A and AG contacts) will energize all the A-phase portions of all discs at the same time. The same applies for the B-phase. This synchronized activation of all discs causes a uniform deformation of the entire LPE. Electrical power is provided via a thin sheet of printed circuit board that is pressed against the top surface of the LPE, establishing a connection to all of the through-holes of that first disc. The individual layers are not visible to the naked eye.</p></div></div><div><div><p>With the LPE sandwiched between the two oscillator bodies, energizing the LPE with a sinusoidal voltage causes the oscillators to vibrate. Vibration is amplified by exciting the stator with the natural resonance frequency of the oscillators which is in the ultrasonic range. The illustration shows how the stator vibration even causes a lateral displacement of the stator body.</p></div></div><div><div><h2>Both Phases are Energized</h2><p>The two phases of the LPE are energized with high-frequency voltages that are shifted by λ/4 (temporal phase shift). The resulting vibrations from each phase combine and generate a nutation motion of the stator around its axis. This nutation forms a peak at the top surface of the larger oscillator that moves around the circumference similar to a traveling wave. The amplitude of that oscillation movement is as small as two micrometers, and therefore not visible to the naked eye. The oscillator has a small lip on its surface that is in pressure contact with the rotor.</p></div></div><div><div><p>The animation shows the nutation movement of the stator. The rotor and output gear, among other parts, are not shown here to most clearly illustrate the movement. The nutation is slowed down and greatly exaggerated in amplitude. Note that the stator itself does not rotate around its axis but only the peak on the top surface of the larger oscillator travels in a circular way. This traveling wave (one peak and one valley) is the source of rotational energy that is transferred into the rotor via friction.</p></div></div><div><div><p>This animation shows the complete Micro USM unit in operation. The principle of transferring the stator's energy into the rotor is similar to the frictional coupling used by the ring-type USM motor. The Micro USM rotor is in pressure contact with the top surface of the elastic body. Proper operation is achieved only when the stator is excited at the exact resonance frequency of the elastic metal bodies, which amplifies vibrations and thus energy transfer into the rotor. Although the Micro USM stator has no teeth cut into the oscillator body, the traveling wave exerts frictional force in the opposite direction of the nutation motion. This principle of frictional coupling is very similar to the ring-type USM. The animation shows that the rotor and output gear perform actual rotations around their axis, and their direction of rotation is opposite from the direction of the stator's traveling wave.</p></div></div><div><div><h2>The Working Principle Summarized</h2><p>The cylindrical ultrasonic motor operates a two-stage energy conversion process: In a first stage, electrical energy is converted into a nutation motion of the stator. In a second stage, these ultrasonic vibrations are converted into a continuous unidirectional rotating movement of the rotor by friction on the stator. The stator vibrations are generated by a multi-layer laminated piezoelectric element that is excited via two separate phases that are excited with a λ/4 phase-shifted sinusoidal voltage, generating the nutation mode. The stator's energy is transferred to the rotor due to friction between the stator and rotor, caused by the pressure contact (preload force) between stator and rotor.</p><p>This summary is similar in many respects to the summary of the ring-type USM motor. While the Micro USM and ring-type USM share the same general principles, they are still different types of motors. Here is a comparison of the similarities and the differences between the Micro USM and the ring-type USM:</p></div><div><p>Both types of motors use piezoelectric elements to generate flexural vibrations in the stator, as well as ultrasonic excitation to maximize vibrations in the oscillators. A traveling wave is generated at the surface of the stator, and friction is used to turn the rotor in the opposite way than the traveling wave. Both types are inaudible by the naked ear, but their noise can be picked up by sensitive microphones during video recordings. Neither of them is intended for long-term operation.</p><p>Ring-type USM and Micro USM types of autofocus drives use completely different stator geometries. Also, their piezoceramic elements are arranged in different ways. The stator of a ring-type USM forms seven to nine traveling waves whereas the stator of a Micro USM performs a nutation motion that is similar to a single traveling wave (one peak and one valley). The overall size of the Micro USM is considerably smaller than the ring-shaped USM. Output speed is relatively high on the Micro USM, and therefore a gearbox is used to lower the speed of the output gear. Overall production cost is comparatively low for the Micro USM and Micro USM II, which is why these types of motors have been used for the low- and mid-level lenses.</p></div></div><div><div><p>The following illustration shows two gearboxes used to connect Micro USM and Micro USM II motors to the focusing groups of lenses. Some examples of Canon lenses that use Micro USM and Micro USM II technology include:</p><ul><li>Canon EF 70-300mm F4-5.6 IS USM</li><li>Canon EF 90-300mm F4.5-5.6 USM</li></ul><ul><li>Canon EF 28-105mm F4-5.6 USM</li><li>Canon EF-S 18-55mm F3.5-5.6 II USM</li></ul></div></div></div><div><h2>Stepper Motor (STM)2012 - Present</h2><p>In June 2012, Canon announced the EF 40mm F2.8 STM and the EF-S 18-135mm F3.5-5.6 IS STM lenses. These were the first lenses that carried the designation STM in their name, an abbreviation that stands for stepper motor. Although the technology had already been used in the Arc-Form Drive, the stepper motor inside STM lenses has a clearly different design including a greatly reduced size.</p></div><div><div><div><p>Stepper motors are rotary drives that convert electrical energy into rotational energy of the motor shaft. Canon uses two different transmission types to convert the rotary motion into linear motion of the focusing lens groups:</p><ul><li> This type of transmission uses a worm drive to side the focusing lens unit axially along two guide rails.</li><li> This type of transmission uses gear wheels and is ultimately connected to a focusing barrel with helical slots. Once that internal barrel is turned, the focusing lens unit is shifted along the lens axis.</li></ul><p>While these are different types of transmissions, the actual stepper motors used are identical. Canon STM lenses offer very quiet and smooth autofocus operation. For that reason, the STM autofocus system is considered a good choice for both photography and video shooting. The STM system has become widely used not only in Canon's EF and EF-S series of lenses but also in their latest RF and RF-S lenses. Here is a short list of lenses that use the STM autofocus system:</p><ul><li>Canon EF 40mm F2.8 STM (2012)</li><li>Canon EF-S 24mm F2.8 STM (2014)</li><li>Canon RF 28-70mm F2.8 IS STM (2024)</li><li>Canon RF-S 18-45mm F4.5-6.3 IS STM (2022)</li></ul></div></div><div><div><p>The type of stepper motor used in STM lenses is a 2-phase bipolar stepper motor with permanent magnet rotor. Unlike the AFD stepper motor, the STM version uses a rotationally symmetrical stator. First, the general principle of stepper motor operation is shown, and then the actual design of Canon's stepper motors is examined.</p><p>The following illustration shows the general principle of a 2-phase bipolar stepper motor. The term 2-phase refers to the use of two separate coils. The description bipolar indicates that each of these coils can be energized with current flowing in two different directions, allowing each coil to generate two opposite magnetic field polarities. The ferromagnetic metal parts of the stator pointing towards the rotor are called field poles. The coil windings of both phases are split into two portions and are wound around opposite field poles to ensure simultaneous magnetization during operation. Each phase is labeled with two letters, one of them overlined to indicate the polarity in which the magnetic field is generated. Once phase A is energized, the magnetic polarity of field pole A and field pole Ā (Inverse-A) is always opposite from each other. The same applies for the second phase. In the illustration, the letters are also used to describe the polarities at which the voltage is applied to the coils.</p><p>In this simplified example, the stator consists of four field poles, two per phase, which results in a rather large step angle of 90 degrees. During operation, the two phases are energized as shown in the timing diagram below. Note how due to inverted polarities, the two coils are capable of generating four different magnetic field orientations, and the stator strictly follows these orientations. This mode of operation is called full-step mode. Four full steps are required to complete one turn of the rotor. The stepper motor can also be driven in half-step mode where between full-steps both phases are turned on at the same time, turning the rotor by 45 degrees. Eight half-steps are required to complete one turn of the rotor. In the context of autofocus systems, however, speed is more important than increasing the step precision, and therefore the half-step mode is not discussed further.</p></div></div><div><div><h2>Stepper Motor with Can-Stack Design</h2><p>The type of stepper motor used in Canon's STM lenses has 20 field poles, 10 per phase. This quantity of field poles makes it unpractical to apply coil windings directly at each field pole. For that reason, a very clever stator design is used:</p><p>The two phase windings are stacked on top of each other as shown in the cutaway diagram. Each phase winding is surrounded by a steel shell, and triangular teeth (field poles) are brought to the center. These teeth are arranged in an alternating fashion, five coming from the bottom of each coil pointing upwards, and five coming from the top of each coil pointing downwards. Once a coil is energized, the steel shell carries the magnetic flux into the teeth, one polarity to the teeth pointing up and the opposite polarity to the teeth pointing down. As a result, the teeth form an alternating ring of north and south magnetic poles and will attract the permanent magnet rotor accordingly.</p><p>Thanks to this design, one coil winding has a total of 10 field poles. Phase B is located below and has an equal number of 10 field poles. One key requirement of this design is that both rings of phase A and phase B stator teeth are offset by 18 degrees from each other. This is half the pitch between two teeth of one stator. This stepper motor construction is also referred to as can-stack design because it looks like a small stack of two steel cans. Another commonly used term is tin-can design.</p></div></div><div><div><p>Once all teeth of phases A and B are combined, the stator consists of 20 field poles. The rotor is a ferrite ceramic cylinder that is magnetized in the 10-pole pattern shown (five north and five south poles). The stepper motor is operated via four repetitive steps:</p><ul><li>Step 1: Phase B is de-energized. Phase A is energized so that field poles labeled A are magnetized as south poles (and Inverse-A as north poles). The rotor turns so that its five north poles align with the stator's A poles (and the rotor's five south poles align with the stator's Inverse-A poles).</li><li>Step 2: Phase A is de-energized. Phase B is energized so that field poles labeled B are magnetized as south poles (and Inverse-B as north poles). The rotor turns so that its five north poles align with the stator's B poles (and the rotor's five south poles align with the stator's Inverse-B poles).</li><li>Step 3: Phase B is de-energized. Phase A is energized in reverse so that field poles labeled A are magnetized as north poles (and Inverse-A as south poles). The rotor turns so that its five south poles align with the stator's A poles (and the rotor's five north poles align with the stator's Inverse-A poles).</li><li>Step 4: Phase A is de-energized. Phase B is energized in reverse so that field poles labeled B are magnetized as north poles (and Inverse-B as south poles). The rotor turns so that its five south poles align with the stator's B poles (and the rotor's five north poles align with the stator's Inverse-B poles).</li></ul><p>After four steps, the rotor has completed a 72 degree turn, and thus it requires 20 steps to complete one full rotation. The direction of rotation can be reversed by performing the sequence of steps backwards. The rotor follows the magnetic fields so precisely that no separate feedback control system is required. The autofocus control system of the lens sends an instruction to the stepper motor driver to perform a certain number of steps. After the same number of electrical pulses to the phase coils, the rotor will have performed an equal number of steps into the desired direction.</p></div></div><div><div><p>The can-stack is one of the most commonly used stepper motors designs. It is often used in scanners, printers, CNC mills, robots, and other devices. The illustration is an enlarged cutaway diagram of a stepper motor used in Canon's STM lenses. This is an extremely small unit of just eight millimeters diameter (this is smaller than the DC micro motor). Due to this size, the STM drive is more suitable for smaller focusing lens elements. It is therefore unlikely to ever be used in heavy super-telephoto lenses.</p><h2>Full-Time Manual Focus Override</h2><p>Canon STM lenses use focus-by-wire as the coupling method between the manual focusing ring and the autofocus drive. For that reason, all STM lenses do support full-time manual focus override at any time.</p></div></div><div><div><p>The following illustration is an exploded view of the stepper motor used in Canon's STM lenses. The long worm gear on the motor shaft is part of the lead-screw mechanism to move the focusing lens.</p></div></div></div><div><p>The Nano USM autofocus drive is the latest addition to Canon's ultrasonic motor family. Canon announced the EF‒S 18‒135mm F3.5‒5.6 IS USM lens, the first Canon lens with the new Nano USM technology installed. In that same year, Canon discontinued the previous ultrasonic motor – the Micro USM.</p></div><div><div><div><p>The Nano USM uses piezoceramic elements to generate vibrations that are translated into movement. The drive system does not generate rotational output, and therefore doesn't require a helical barrel or lead screw to translate rotation into linear movement. Instead, the Nano USM generates a linear movement that is directly forwarded to slide the focusing lens cell axially along guide rails. A position encoder with alternating dark and reflective stripes is attached to the focusing lens unit, allowing an infrared sensor to count the steps that the focusing mechanism has moved.</p></div></div><div><div><p>The heart of the system is the Nano USM actuator. That is a tiny piece of elastic metal around 20&nbsp;mm in length with piezoceramic elements attached to its lower side. The piezoceramic layer has three electrodes on the lower surface. Two small elevations on the top surface are in pressure contact with a stationary slide rail. The illustration summarizes this construction of the Nano USM actuator.</p><p>Although being extremely small, the Nano USM actuator generates comparatively high levels of output torque. In addition, it offers very rapid start and stop characteristics and fast, well controllable output speed.</p></div></div><div><div><p>During operation of the Nano USM drive, the USM actuator goes into two flexural vibration modes. Mode&nbsp;1 is an out-of-plane bending mode that turns the actuator into a saddle-shape. Mode&nbsp;2 is another out-of-plane bending mode that shapes the actuator into a waveform.</p></div></div><div><div><p>Both modes are excited with high-frequency voltages in the range of the natural resonance frequency of the elastic metal body. The result is that both vibrational modes combine and generate an elliptical motion of the contact points. Due to the pressure contact between the Nano USM actuator and the stationary slide rail, the elliptical motion exerts a frictional force on the surface. It is the counterforce on the actuator that ultimately generates the linear movement of the Nano USM frame.</p><p>The amplitudes of both bending modes are greatly exaggerated in the illustrations. In reality, the amplitudes are so small that no deformation can be seen during operation. Similarly, the ultrasonic frequencies involved in the excitation of the actuator are inaudible to the human ear, and unlikely to be picked up by microphones. Due to its slightly lower output power, the Nano USM is preferred when smaller groups of lens elements need to be moved.</p></div></div><div><div><p>The image shows a complete Nano USM assembly including the frame, the actuator socket, the slide rail, and the silver bracket that holds down the Nano USM actuator via four tension springs.</p><h2>Full-Time Manual Focus Override</h2><p>Canon's lenses with Nano USM autofocus drives allow full-time manual focus override via focus-by-wire. There is no mechanical connection between the manual focusing ring on the lens barrel and the focusing lens group inside a Nano USM lens. This is similar to lenses with <a href=\"https://exclusivearchitecture.com/03-technical-articles-CLT-12-autofocus-systems.html#QJ_POS_05\">STM</a> or <a href=\"https://exclusivearchitecture.com/03-technical-articles-CLT-12-autofocus-systems.html#QJ_POS_07\">VCM</a> autofocus drives.</p></div></div><div><div><p>Released in 2019, the Canon RF 70-200mm F2.8L IS USM was the first lens to feature Dual Nano USM technology. The innovation with Dual Nano USM is that two of these compact ultrasonic drive systems are installed in the lens barrel. Each AF drive moves one of two internal focusing groups – one focusing group and one floating group. The image shows the Dual Nano USM system that is integrated inside the Canon RF 100-300mm F2.8 L IS USM lens, a high-end telephoto zoom lens.</p></div></div></div><div><h2>Voice Coil Motor (VCM)2024 - Present</h2><p>The voice coil technology has a long history that is tied to the history of telecommunication. The first voice coil was patented at the end of the 19th century, but it was in the 1920s when the first voice coils were actually installed in telephone speakers. A wire coil was attached to a paper diaphragm, and a magnet was placed inside the coil. The resulting device was a transducer that converted electronic signals into the voice of the caller. This type of use gave voice coils their names. Over the last decades, voice coils kept their name but got increasingly used for other applications including hard disc drives, robotics, precision instrumentation, as well as camera systems.</p><p>Canon is already using voice coil motors for a long time to drive the <a href=\"https://exclusivearchitecture.com/03-technical-articles-CLT-18-image-stabilization.html\">image stabilization unit</a>. Voice coil motors have also been used for decades as autofocus drives in cine lenses. This is ideal for video shootings because they are completely silent even in the ultrasonic range. Then, in 2024, Canon first used voice coil motors as the autofocus drives in their photographic lenses. The Canon RF 35mm F1.4 L VCM was the first lens with a voice coil motor.</p></div><div><div><div><p>Voice coil motors combine a range of advantages:</p><ul><li>Voice coil motors are very compact and lightweight in their design. This makes them suitable for applications where space is limited or weight constraints are critical.</li><li>Fast response times: Unlike traditional motor technologies, such as DC or stepper motors, voice coil motors provide near-instantaneous response due to their direct electromagnetic actuation. In addition, their lightweight nature contributes to rapid acceleration and deceleration. This makes them an excellent choice for autofocus drives.</li><li>Due to their high acceleration, the coil can reach a high speed very fast.</li><li>High level of precision and accuracy: The design of voice coil motors allows for precise control and positioning, enabling the coil to be moved in sub-micrometer steps.</li><li>Voice coils generate a high force output to move even very large focusing lens groups.</li><li>Low power consumption: There are very low frictional losses due to the direct electromagnetic actuation. Therefore, voice coil motors have a very low power consumption which leads to extended battery life.</li><li>Due to its linear design, no helical barrel or lead screw is required to translate rotation into linear movement. The voice coil is therefore directly connected to the focusing lens group.</li><li>Voice coil motors are virtually silent even when recorded by sensitive microphones. This makes Canon's RF lenses with VCM autofocus drives perfect choices not only for photography but also for videography.</li></ul></div></div><div><div><h2>The Principle of Operation</h2><p>The image shows the VCM unit inside the Canon RF 35mm F1.4 L VCM lens. There are two identical voice coil motors attached to the focusing lens cell. This symmetrical construction prevents one-sided stress on the mechanism and therefore ensures a smooth sliding operation. Each voice coil is supported by a sliding rail that passes through its center and which defines the range of axial movement. On either side there are two strong permanent magnets placed above and below the voice coils so that their magnetic field runs through the coil.</p></div></div><div><div><p>The following illustration is a cross-sectional view of the VCM unit. The voice coil is exposed to the stationary magnetic field of the permanent magnets at any time. Once a current runs through the wire coil, a force (called Lorentz force) is exerted on the coil so that it moves axially along the sliding rail. The force generated is proportional to the flux density of the magnetic field and the intensity of the electric current. The direction in which the Lorentz force acts is depending on the direction of the current. By applying ultra-short voltage pulses to the voice coil, the unit can be driven into the desired direction with an extreme level of precision.</p><p>A slight drawback of the technology is that even when the focusing lens is not moved, the position control must be active in order to retain the coil's position.</p></div></div><div><div><p>The use of voice coils in Canon's RF lenses made it possible to enter a new field. The smooth and silent operation of the VCM system not only convinces photographers but for the first time also satisfies the requirements of videographers. For that reason, Canon has introduced a new series of specially designed RF lenses, called hybrid lenses. These are L-lenses of the RF mount system that are specially designed to combine the benefits of photo and video technologies (such as a manual aperture ring normally found only on cine lenses). Some examples of these hybrid RF lenses include:</p><ul><li>Canon RF 24mm F1.4 L VCM (2024)</li><li>Canon RF 35mm F1.4 L VCM (2024)</li><li>Canon RF 50mm F1.4 L VCM (2024)</li></ul><p>The illustration is a transparent view of the Canon RF 35mm F1.4 L VCM hybrid RF lens. It can be seen that this lens is equipped with two autofocus drive systems. The pair of voice coil motors drives the main focusing lens group while a Nano USM unit drives the floating lens element.</p></div></div><div><div><p>The following illustration is a block diagram of the same lens. Note that the main focusing lens group consists of four lens elements, a considerable weight that requires a powerful autofocus system. The two symmetrically arranged coils of the voice coil motor actually generate a significant force to even allow rapid movements of these focusing lenses. The floating lens is a single element only, and therefore the smaller Nano USM is a sufficiently powerful drive system.</p></div></div></div><div><div><a href=\"https://exclusivearchitecture.com/03-technical-articles-CLT-11-focus.html\">Back - Focus</a><a href=\"https://exclusivearchitecture.com/03-technical-articles-CLT-00-table-of-contents.html\">Main Menu</a><a href=\"https://exclusivearchitecture.com/03-technical-articles-CLT-13-aperture.html\">Next - Aperture</a></div></div>","contentLength":60589,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43320230"},{"title":"Go European: Discover European products and services","url":"https://www.goeuropean.org/","date":1741601747,"author":"doener","guid":244,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43318798"},{"title":"Performance of the Python 3.14 tail-call interpreter","url":"https://blog.nelhage.com/post/cpython-tail-call/","date":1741589067,"author":"signa11","guid":243,"unread":true,"content":"<p>Unfortunately, as I will document in this post, these impressive performance gains turned out to be <strong>primarily due to inadvertently working around a regression in LLVM 19.</strong> When benchmarked against a better baseline (such GCC, clang-18, or LLVM 19 with certain tuning flags), the performance gain drops to 1-5% or so depending on the exact setup.</p><p>When the tail-call interpreter was announced, I was surprised and impressed by the performance improvements, but also confused: I’m not an expert, but I’m passingly-familiar with modern CPU hardware, compilers, and interpreter design, and I couldn’t explain why this change would be so effective. I became curious – and perhaps slightly obsessed – and the reports in this post are the result of a few weeks of off-and-on compiling and benchmarking and disassembly of dozens of different Python binaries, in an attempt to understand what I was seeing.</p><p>At the end, I <a href=\"https://blog.nelhage.com/post/cpython-tail-call/#reflections\">will reflect</a> on this situation as a case study in some of the challenges of benchmarking, performance engineering, and software engineering in general.</p><p>I also want to be clear that I still think the tail-calling interpreter is a great piece of work, as well as a genuine speedup (albeit more modest than initially hoped). I am also optimistic it’s a more robust approach than the older interpreter, in ways I’ll explain in this post. I also really don’t want to blame anyone on the Python team for this error. This sort of confusion turns out to be very common – I’ve certainly misunderstood many a benchmark myself – and I’ll have some reflections on that topic at the end.</p><p>In addition, the impact of the LLVM regression doesn’t seem to have been known prior to this work (and the bug wasn’t fixed as of publishing this post, although it <a href=\"https://github.com/llvm/llvm-project/pull/114990\">since has been</a>); thus, in that sense, the alternative (without this work) probably really was 10-15% slower, for builds using clang-19 or newer. For instance, Simon Willison <a href=\"https://simonwillison.net/2025/Feb/13/python-3140a5/\">reproduced the 10% speedup</a> “in the wild,” as compared to Python 3.13, using builds from <a href=\"https://github.com/astral-sh/python-build-standalone\"></a>.</p><p>Here are my headline results. I benchmarked several builds of the CPython interpreter, using multiple different compilers and different configuration options, on two machines: an Intel server (a <a href=\"https://www.intel.com/content/www/us/en/products/sku/230580/intel-core-i513500-processor-24m-cache-up-to-4-80-ghz/specifications.html\">Raptor Lake i5-13500</a> I maintain in Hetzner), and my Apple M1 Macbook Air. You can reproduce these builds <a href=\"https://github.com/nelhage/cpython-interp-perf/\">using my  configuration</a>, which I found essential for managing so many different moving pieces at once.</p><p>All builds use LTO and PGO. These configurations are:</p><ul><li>: Built using Clang 18.1.8, using computed gotos.</li><li> (Intel only): Built with GCC 14.2.1, using computed gotos.</li><li>: Built using Clang 19.1.7, using computed gotos.</li><li>: Built using Clang 19.1.7, using the new tail-call interpreter.</li><li>: Built using Clang 19.1.7, computed gotos and some  tuning flags which work around the regression.</li></ul><p>I’ve used  as the baseline, and reported the bottom-line “average” reported by /. You can find the complete output files and reports <a href=\"https://github.com/nelhage/cpython-interp-perf/tree/data/\">on github</a>.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr></tbody></table><p>Observe that the tail-call interpreter still exhibits a speedup as compared to clang-18, but that it’s far less dramatic than the slowdown from moving to clang-19. The Python team has also observed larger speedups than I have (after accounting for the bug) on some other platforms.</p><p>You’ll notice I didn’t benchmark the tail-call interpreter on the older Clang release (what would be ). The tail-call interpreter relies on new compiler features which only landed in Clang 19, meaning we can’t test it on earlier versions. This interaction, I think, is a big reason this story was so confusing, and why it took me so many benchmarks to be  I understood the situation.</p><p>A classic bytecode interpreter consists of a  statement inside of a  loop, looking something like so:</p><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><p>Most compilers will compile the  into a jump table – they will emit a table containing the address of each  block, index into it with the opcode, and perform an indirect jump.</p><p>It’s <a href=\"https://link.springer.com/content/pdf/10.1007/3-540-44681-8_59.pdf\">long been known</a> that you can speed up a bytecode interpreter of this style by replicating the jump table dispatch into the body of each opcode. That is, instead of ending each opcode with a , each opcode contains a separate instance of the “decode next instruction and index through the jump table” logic.</p><p>Modern C compilers support <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Labels-as-Values.html#Labels-as-Values\">taking the address of labels</a>, and then using those labels in a “computed goto,” in order to implement this pattern. Thus, many modern bytecode interpreters, including CPython (before the tail-call work), employ an interpreter loop that looks something like:</p><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><p>For performance reasons (performance of the compiler, not the generated code), it turns out that Clang and LLVM, internally, actually merges all of the s in the latter code into a <a href=\"https://llvm.org/docs/LangRef.html#indirectbr-instruction\"> LLVM instruction</a>, which each opcode will jump to. That is, the compiler takes our hard work, and deliberately rewrites into a control-flow-graph that looks essentially the same as the -based interpreter!</p><p>Then, during code generation, LLVM performs “tail duplication,” and copies the branch  into each location, restoring the original intent. This dance is documented, at a high level, <a href=\"https://blog.llvm.org/2010/01/address-of-label-and-indirect-branches.html\">in an old LLVM blog post</a> introducing the new implementation.</p><p>The whole reason for the deduplicate-then-copy dance is that, for technical reasons, creating and manipulating the control-flow-graph containing many  instructions can be quite expensive.</p><p>In order to avoid catastrophic slowdowns (or memory usage) in certain cases, LLVM 19 implemented <a href=\"https://github.com/llvm/llvm-project/pull/78582\">some limits on tail-duplication pass</a>, causing it to bail out if duplication would blow up the size of the IR past certain limits.</p><p>Unfortunately, on CPython those limits resulted in Clang <strong>leaving all of the dispatch jumps merged</strong>, and entirely undoing the whole purpose of the computed -based implementation! This bug was <a href=\"https://github.com/llvm/llvm-project/issues/106846\">first identified</a> by another language implementation with a similar interpreter loop, but had not been known (as far as I can find) to affect CPython.</p><p>In addition to the performance impact, we can observe the bug directly by disassembling the resulting object code and counting the number of distinct indirect jumps:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>I am confident that the change to the tail-call duplication logic caused the regression: if <a href=\"https://blog.nelhage.com/post/cpython-tail-call/#the-fix\">you fix it</a>, performance matches clang-18. However, I can’t fully explain the  of the regression.</p><p>Historically, the optimization of replicating the bytecode dispatch into each opcode has been cited to speed up interpreters anywhere from <a href=\"https://github.com/python/cpython/blob/c718c6be0f82af5eb0e57615ce323242155ff014/Misc/HISTORY#L15252-L15255\">20%</a> to <a href=\"https://link.springer.com/content/pdf/10.1007/3-540-44681-8_59.pdf\">100%</a>. However, on modern processors with improved branch predictors, <a href=\"https://inria.hal.science/hal-01100647/document\">more recent work</a> finds a much smaller speedup, on the order of 2-4%.</p><p>We can verify this 2-4% number in practice, because Python still supports the “old-style” interpreter, which uses a single  statement, via a configuration option. Here’s what we see if we benchmark that interpreter (\".nocg\" for “no computed gotos” in the following table):</p><table><thead><tr></tr></thead><tbody><tr></tr></tbody></table><p>Notice that \" is only 2% slower than , even though the base  build is 9% slower! I interpret that “2%” as a fairer estimate for the cost/benefit of duplicating opcode dispatch, alone, and I don’t fully understand the other one.</p><p>I haven’t mentioned the  benchmark, which you may notice claims to be  than \" It was at this point that I discovered an additional, and very funny, twist to the story.</p><p>I explained earlier that Clang and LLVM:</p><ol><li>Compiles the  into a jump table and an indirect jump, very similar to the one we create by hand using computed gotos</li><li>Compiles computed gotos into a control-flow graph that closely resembles the classic  graph, which a single instance of the opcode dispatch, and</li><li>Is able to reverse the transformation during codegen in order to duplicate the dispatch</li></ol><p>Those facts taken together, might lead you to ask, “Couldn’t we just start with the -based interpreter, and have the  do tail-duplication, and get the same benefits?”</p><p>clang-18 (or clang-19 with appropriate flags), when presented with the “classic” -based interpreter, <strong>goes ahead and duplicates the dispatch logic into each the body of each opcode anyways</strong>. Here’s another table, showing the same builds with the number of indirect jumps, using the  test from earlier:</p><table><thead><tr></tr></thead><tbody><tr></tr></tbody></table><p>Thus, there’s a case to be made that the entire “computed goto” interpreter turns out to be entirely unnecessary complexity (at least for modern Clang). The compiler is perfectly capable of performing the same transformation itself, and (apparently) the computed gotos don’t even suffice to guarantee it!</p><p>That said, I did also test GCC, and GCC (at least as of 14.2.1) does not replicate the , but does implement the desired behavior for when using computed goto. So at least in that case we see the expected behavior.</p><p><a href=\"https://github.com/llvm/llvm-project/pull/114990\">LLVM pull request 114990</a> merged shortly after I published this post, and fixes the regression. I was able to benchmark it before merge and confirm it restores the expected performance.</p><p>For releases before that fix, the <a href=\"https://github.com/llvm/llvm-project/pull/78582\">PR that caused the regression</a> added a tunable option to choose the threshold at which tail-duplication will abort. We can restore similar behavior on clang-19 by simply setting that limit to a very large number.</p><p>I will freely admit that I got nerdsniped quite effectively by this topic, and have gone far deeper than was really necessary. That said, having done so, I think there are a number of interesting lessons and reflections to be taken away, which generalize to software engineering and performance engineering, and I will attempt to extract and meditate upon some of them.</p><p>When optimizing a system, we generally construct some set of benchmarks and benchmarking methodology, and then evaluate proposed changes using those benchmarks.</p><p>Any set of benchmarks or benchmark procedures embeds (often implicitly) what I like to call a “theory of performance.” Your theory of performance is a set of beliefs and assumptions that answer questions like “which variables (may) effect performance, in what ways?” and “what is the relationship between results on benchmarks and the “true” performance in “production”?”</p><p>The benchmarks ran on the tail-call interpreter showed a 10-15% speedup when compared with the old computed-goto interpreter. Those benchmarks were accurate, in that they were accurately measuring (as far as I know) the performance difference between those builds. However, in order to generalize those specific data points into the statement “The tail-call interpreter is 10-15% faster than the computed-goto interpreter, more generally,” or even “The tail-call interpreter will speed up Python by 10-15% for our users,” we need to bring in more assumptions and beliefs about the world. In this case, it turns out the story was more complex, and those broader claims were not true in full generality.</p><p>(Once again, I really don’t want to blame the Python developers! This stuff is  and there are a million ways to get confused or to reach somewhat-incorrect conclusions. I had to do ~three weeks of intense benchmarking and experimenting to reach a better understanding. My point is that this is a very general challenge!)</p><p>This example highlights another recurring challenge, not only in software performance, but in many other domains: “What baseline do you compare against?”</p><p>Any time you propose a new solution or method for some problem, you typically have a way of running your new method, and producing some relevant performance metrics.</p><p>Once you have metrics for  system, however, you need to know what to compare them against, in order to decide if they’re any good! Even if you score well on some absolute scale (assuming there  a sensible absolute scale to evaluate), if your method is worse than an existing solution, it’s probably not that interesting.</p><p>Typically, you want to compare against “the current best-known approach.” But sometimes that can be hard to do! Even if you understand the current approach in theory, you may or may not be an expert in applying it in practice. In the case of software this may mean something like, tuning your operating system or compiler options or other flags. The current-best approach may have published benchmarks, but they’re not always relevant to you; for instance, maybe it was published years ago on older hardware, and so you can’t do an apples-to-apples comparison with the public numbers. Or maybe their tests were run at a scale you can’t afford to replicate.</p><p>I work in machine learning at Anthropic these days, and we see this all the time in ML papers. When a paper comes out claiming some algorithmic improvement or other advance, I’ve noticed that the first detail our researchers ask is often not “What did they do?” but “What baseline did they compare against?” It’s easy to get impressive-looking results if you’re comparing against a poorly-tuned baseline, and that observation turns out to explain a surprising fraction of supposed improvements.</p><h2>On software engineering&nbsp;<a href=\"https://blog.nelhage.com/post/cpython-tail-call/#on-software-engineering\"></a></h2><p>One other highlight, for me, is just how complex and interconnected our software systems are, and how rapidly-moving, and how hard it is to keep track of all the pieces.</p><p>If you’d asked me, a month ago, to estimate the likelihood that an LLVM release caused a 10% performance regression in CPython and that no one noticed for five months, I’d have thought that a pretty unlikely state of affairs! Those are both widely-used projects, both of which care a fair bit about performance, and “surely” someone would have tested and noticed.</p><p>And probably that  situation was quite unlikely! However, with so many different software projects out there, each moving so rapidly and depending on and being used by so many other projects, it becomes practically-inevitable that  regressions “like that one” happen, almost constantly.</p><p>The saga of the computed-goto interpreter illustrates recurring tensions and unresolved questions around optimizers and optimizing compilers, to which we don’t yet have agreed-upon answers as a field.</p><p>We generally expect our compilers to respect the programmer’s intent, and to compile the code that was written in a way that preserves the programmer’s intent.</p><p>We also, however, expect our compilers to optimize our code, and to transform it in potentially-complex-and-unintuitive ways in order to make it run faster.</p><p>These expectations are in tension, and we have a dearth of patterns and idioms to explain to the compiler “why” we wrote code in various ways, and whether we were  trying to trigger a certain output, or make a certain performance-related decision, or not.</p><p>Our compilers typically only  to emit code with “the same behavior” as the code we write; performance is something of a best-effort feature on top of that guarantee.</p><p>Thus, we end up in this odd world where clang-19 compiles the computed-goto interpreter “correctly” – in the sense that the resulting binary produces all the same value we expect – but at the same time it produces an output completely at odds with the intention of the optimization. Moreover, we also see other versions of the compiler applying optimizations to the “naive” -based interpreter, which implement the exact same optimization we “intended” to perform by rewriting the source code.</p><p>In hindsight, it appears that the “computed goto” interpreter, at a source code level, and “replicating the dispatch at a machine-code level” end up being almost-orthogonal notions! We’ve seen examples of every instance of the resulting 2x2 matrix! Because all of those  binaries compute the same values when run, our current tools are essentially unable to talk about the distinctions between them in a coherent way.</p><p>This confusion is one way in which I think the tail-calling interpreter (and the compiler features behind it) represent a genuine, and useful, advance in the state of the art. The tail-call interpreter is built on <a href=\"https://clang.llvm.org/docs/AttributeReference.html#musttail\">the  attribute</a>, which represents a relatively new kind of compiler feature.  does not affect the “observable program behavior,” in the classic sense that compilers think, but is rather a conversation with the ; it requires that the compiler be able to make certain optimizations, and requires that compilation fail if those optimizations don’t happen.</p><p>I’m hopeful this framework will turn out to be a much more robust style for writing performance-sensitive code, especially over time and as compilers evolve. I look forward to continued experiments with features in that category.</p><p>Concretely, I find myself wondering if it would be viable to replace the computed-goto interpreter with something like a (hypothetical) <code>[[clang::musttailduplicate]]</code> attribute on the interpreter  loop. I’m not expert enough in all the relevant IRs and passes to have confidence in this proposal, but perhaps someone with more familiarity can weigh in on the feasibility.</p><p>I want to close with a call-out of how helpful  was for this project. I have been experimenting with nix and NixOS for my personal infrastructure over the last year or so, but they turned out to be a total lifesaver for this investigation.</p><p>In the course of these experiments, I have built and benchmarked  of different Python interpreters, across four different compilers (, , , and ) and using numerous combinations of compiler flags. Managing all of that by hand would have strained my sanity, and I’m  I would have made numerous mistakes during which I mixed up which compiler and which flags went into which build, and so on.</p><p>Using , I was able to keep all of these parallel versions straight, and build them in a reproducible, hermetic style. I was able to write some short abstractions which made them very easy to define, and then know with absolute confidence  any given build in my  store came from, with which compilers and which flags. After a small amount of work to build some helper functions, the core definitions of my build matrix is <a href=\"https://github.com/nelhage/cpython-interp-perf/blob/afd2123bef6ec3fd872d628f2bb519b20684e161/python.nix#L105-L143\">shockingly concise</a>; here’s a taste:</p><div><pre tabindex=\"0\"><code data-lang=\"nixos\"></code></pre></div><p>I was even able to build a custom version of LLVM (with the bugfix patch), and do Python builds using that compiler. Doing so required <a href=\"https://github.com/nelhage/cpython-interp-perf/blob/afd2123bef6ec3fd872d628f2bb519b20684e161/llvm.nix#L14-L25\">all of about 10 lines of code</a>.</p><p>That said, not everything was rosy. For one,  is, by necessity, “weird” in various ways compared to the ways “normal people” use software, and I worry that some of that weirdness may have affected some of my benchmarks or conclusions in ways I didn’t notice. For instance, early on I discovered that nix (by default) builds projects using certain hardening flags that <a href=\"https://github.com/python/cpython/issues/130961\">disproportionately impact the tail-call interpreter</a>. I’ve handled that one, but are there more?</p><p>In addition, Nix is incredibly extensible and customizable, but figuring out how to make a specific customization can be a real uphill battle, and involve a lot of trial and error and source-diving. My patched LLVM build ended up being pretty short and clean, but getting there required me to read a lot of  source code, mixing and matching two under-documented extensibility mechanisms ( and  – not to be confused with , used elsewhere), and one failed attempt which successfully patched , but then silently built a new  against the unpatched version.</p><p>Still,  was clearly enormously helpful here, and on net it definitely made this kind of multi-version exploration and debugging  saner than any other approach I can imagine.</p>","contentLength":19177,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43317592"},{"title":"Tesla created secret team to suppress driving range complaints (2023)","url":"https://www.reuters.com/investigates/special-report/tesla-batteries-range/","date":1741560799,"author":"mathgenius","guid":242,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43314781"},{"title":"Ecosia is teaming up with Qwant to build a European search index","url":"https://blog.ecosia.org/eusp/","date":1741542038,"author":"amarcheschi","guid":241,"unread":true,"content":"<p>If you’ve been following <a href=\"https://blog.ecosia.org/choice-screen/\"><u>our work on the Digital Markets Act</u></a>, you know we’re always pushing for tech that’s more fair, competitive, and more democratic. We are proud to share the next step in our journey towards tech independence - building our very own search index! We've joined forces with our friends at Qwant to build the <a href=\"https://www.eu-searchperspective.com/\" rel=\"noreferrer\"><em>European Search Perspective</em></a> which will provide a solid foundation for future technologies, including AI infrastructure.</p><p>A search index is a database used by search engines to retrieve information and present them in the most relevant order; the same way libraries label and sort books.&nbsp;</p><p>Currently, we rely on a mix of both Google and Bing libraries to provide you with answers to your searches. Starting in 2025, our new index will be added into the database pool to serve results in both the French and German language. We are starting small and in the home countries of both Qwant and Ecosia respectively.&nbsp;</p><h2><strong>Why build our own search index?</strong></h2><p>Through the <em>European Search Perspective </em>we’re aiming to build digital sovereignty within Europe and provide a transparent and secure data pool for emerging AI technologies. We will develop a privacy-first search index, which will be used by both Ecosia and Qwant, and unlike proprietary solutions, we are making the index available to others.&nbsp;</p><p>We’re excited to mark the next stage of tech autonomy because it means that we are giving ourselves more freedom to build the future of green tech that we want. The amount of climate impact Ecosia can bring about has always been dependent on how well our search engine works for you, so as we see it, developing this innovative technology is essential for the planet.&nbsp;</p>","contentLength":1689,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43311573"},{"title":"It is as if you were on your phone","url":"https://pippinbarr.com/it-is-as-if-you-were-on-your-phone/info/","date":1741527635,"author":"bookofjoe","guid":240,"unread":true,"content":"<p><em>Look at you! On your phone! But you’ve got a secret! And you won’t tell! You’re not on your phone! It is only as if you were on your phone! You’re just pretending to be on your phone! On your phone!</em></p><p><em>It is as if you were on your phone</em> is an  game about an  in which we’re all simultaneously under significant pressure to be on our phones all the time, but also to not be on our phones all the time. Our fingers want to touch the screen, our eyes want to watch the surface, our brains want to be occupied efficiently and always. But it’s also exhausting liking photos, swiping profiles, watching short-form video, and everything else we’re always doing. <em>It is as if you were on your phone</em> presents an alternative:  to be on your phone so that you pass as human, but actually do essentially nothing instead. Follow the prompts and be free.</p><p><em>It is as if you were on your phone</em> was created using <a href=\"https://p5js.org\">p5</a> along with <a href=\"https://hammerjs.github.io/\">Hammer.js</a> for touch gestures.</p>","contentLength":945,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43308994"},{"title":"US Ends Support For Ukrainian F-16s","url":"https://ukrainetoday.org/us-ends-support-for-ukrainian-f-16s-but-french-mirages-will-be-salvation-forbes/","date":1741518507,"author":"ctack","guid":239,"unread":true,"content":"<p>The Donald Trump administration has cut off vital support for F-16 jamming capabilities.</p><p>The United States, having decided to end its support for Ukraine, cannot simply turn off the Ukrainian Air Force’s U.S.-designed&nbsp;<a href=\"https://www.unian.net/world/f-16-dlya-ukrainy-aviaekspert-nazval-veroyatnuyu-prichinu-zaderzhki-postavki-belgiyskih-istrebiteley-12937956.html\" target=\"_blank\" rel=\"noreferrer noopener\">F-16</a>&nbsp;fighters . But the Trump administration has cut off vital support for their jamming capabilities, which could deprive the Ukrainian Air Force of a critical air countermeasure.</p><p><a href=\"https://www.forbes.com/sites/davidaxe/2025/03/07/france-to-the-rescue-french-made-mirage-2000-jets-could-become-ukraines-most-important-aerial-radar-jammers/\" rel=\"noreferrer noopener\" target=\"_blank\">However, as Forbes</a>&nbsp;analyst David Ax writes&nbsp;, the Ukrainians are not powerless and can shift the burden of air jamming onto the French Dassault Mirage 2000 fighters.</p><p>As Aks points out, the Ukrainian Air Force is taking full advantage of the ability of F-16s equipped with AN/ALQ-131 pods to flood Russian radar screens with electronic noise. They act as “flying air defenses” with advanced missile warning technology, notes the Conflict Intelligence Team.</p><p>But the Russian Air Force can circumvent the jamming by reprogramming its radars to different frequencies. As Axe points out, while the Biden Air Force was able to keep up with the Russian adaptation by constantly tweaking the AN/ALQ-131 frequencies, under Trump, Ukrainian pilots are not receiving updates, and the programs could soon become obsolete.</p><p>However, France’s Mirage 2000s are equipped with their own powerful jammers, and the Americans are not involved in their programming, the analyst notes.</p><p>The Mirage 2000-5F currently in service with the French Air Force flies with a combination of the Serval radar warning receiver, Sabre jammer and Eclair flare dispenser. This system was cutting edge in the 1980s, but within a generation it was falling behind.</p><p>“Recognizing this weakness and understanding the seriousness of the Russian missile threat over Ukraine, the French Ministry of Defense promised to install new electronic countermeasures on the Mirage 2000s before handing them over to Ukraine. The ministry probably had in mind the predominantly analog Integrated Countermeasures Suite Mark 2 or the all-digital Integrated Countermeasures Suite Mark 3,” Ax notes.</p><p>Either system is an improvement over the older system and a potential replacement for the AN/ALQ-131, as the American pods lag behind the Russian adaptation. The French are firm allies of Ukraine and are willing to reprogram the jammers if necessary.</p><p>In the longer term, the Ukrainians could refit their F-16s with non-American electronic countermeasures, Axe notes. But that could take time and money that Ukraine cannot afford.</p>","contentLength":2470,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43307996"},{"title":"My 16-month theanine self-experiment","url":"https://dynomight.net/theanine/","date":1741489692,"author":"dynm","guid":238,"unread":true,"content":"<p>The internet <a href=\"https://en.wikipedia.org/wiki/Theanine\">theanine</a>. This is an amino acid analog that’s naturally found in tea, but now sold as a nutritional supplement for anxiety or mood or memory.</p><p>Biologically speaking, it’s plausible. Theanine is structurally related to the neurotransmitter <a href=\"https://en.wikipedia.org/wiki/Glutamate_(neurotransmitter)\">glutamate</a> (theanine = C₇H₁₄N₂O₃, glutamate = C₅H₈NO₄-). For some reason, everyone is obsessed with stupid flashy dopamine and serotonin, and no one cares about glutamate. But it’s the most common neurotransmitter and theanine is both metabolized into glutamate and seems to itself have various <a href=\"https://en.wikipedia.org/wiki/Theanine#In_vitro\">complicated</a> effects on glutamate receptors.</p><p>Of course, there are lots of supplements that  act on the brain, but are useless when taken orally. That’s because your brain is isolated from your circulatory system by a <a href=\"https://en.wikipedia.org/wiki/Blood%E2%80%93brain_barrier\">thin layer of cells</a> that are extremely picky about what they let through. But it appears that theanine <a href=\"https://doi.org/10.1271/bbb.63.615\"></a> get through these cells and into the brain.</p><p>So that sounds good. But do these low-level effects actually lead to changes in mood in real humans? When I looked into the academic research, I was surprised by how weak it was. Personally, on <a href=\"https://dynomight.net/aspartame/#the-european-food-safety-authority-efsa\">these kinds of issues</a>, I find the European Food Safety Authority to be the single most trustworthy scientific body. They did an <a href=\"https://www.efsa.europa.eu/en/efsajournal/pub/2238\">assessment</a> in 2011 and found:</p><table><tbody><tr><td>Improvement of cognitive function</td><td>cause and effect relationship has not been established</td></tr><tr><td>Alleviation of psychological stress</td><td>cause and effect relationship has not been established</td></tr><tr><td>Maintenance of normal sleep</td><td>cause and effect relationship has not been established</td></tr><tr><td>Reduction of menstrual discomfort</td><td>cause and effect relationship has not been established</td></tr></tbody></table><p><a href=\"https://examine.com/supplements/theanine/\">Examine</a> is an independent website that’s respected for summarizing the scientific literature on health and supplements. They looked into if theanine helped with various things, like alertness, anxiety, and attention. In all cases found  for .</p><p>A <a href=\"https://doi.org/10.1007/s11130-019-00771-5\">2020 review</a> of eight randomized double-blind placebo controlled trials found that theanine  help with stress and anxiety. While this review seems generally good, I found it to be insufficiently paranoid. One study they review found that theanine worked better than <a href=\"https://en.wikipedia.org/wiki/Alprazolam\">alprazolam</a> (xanax) for acute anxiety. The correct response would be, “That’s , and the fact that normal scientific practices could lead to such a conclusion casts doubt on everything.” But the review sort of takes it at value and moves on.</p><p>After 2020, the only major trial I could find was <a href=\"https://doi.org/10.1089/jmf.2020.4803\">this 2021 study</a> that took 52 healthy older Japanese people and gave them theanine (or placebo) for 12 weeks. They tested for improvements in a million different measures of cognitive functioning and mostly found nothing.</p><p>I’ve long found that tea makes me much less nervous than coffee, even with equal caffeine. Many people have suggested theanine as the explanation, but I’m skeptical. Most tea only has ~5 mg of theanine per cup, while when people supplement, they take 100-400 mg. Apparently grassy shade-grown Japanese teas are particularly high in theanine. And I  find those teas particularly calming. But they still only manage ~25 mg per cup. (Maybe it’s because tea is better than coffee?)</p><p>Still, I’ve supplemented theanine on and off for more than 10 years, and it seems helpful. So after seeing the weak scientific evidence, I thought: Why not do a self-experiment?</p><p>Theanine seems ideal because it’s a supplement with short term effects. So you can test it against placebo. (Try that with meditation.) And you can build up a large sample using a single human body without waiting weeks for it to build up in the body before each measurement.</p><p>Everyone agrees theanine is <a href=\"https://www.fda.gov/media/182086/download\">safe</a>. It’s biologically plausible. While academic studies haven’t proven a benefit, they haven’t  one either. Given the vast  evidence, I saw a chance to stick it to the stodgy scientific establishment, to show the power of internet people and give the first rigorous evidence that theanine really works. Stockholm, prepare thyself.</p><p>First, I needed placebos. This was super annoying. The obvious way to create them would be to buy some empty capsules and fill some with theanine and others with some inert substance. But that doesn’t sound fun. Isn’t the whole idea of modernity that we’re supposed to replace labor with capital?</p><p>So I went searching for a pair of capsules I could buy off the shelf, subject to the following constraints:</p><ol><li>Capsule A contains 200 mg of theanine.</li><li>Capsule B contains something with minimal acute effects on anxiety, stress, memory, concentration, etc.</li><li>Capsule B contains something I don’t mind putting into my body.</li><li>Both capsules are exactly the same size and weight.</li><li>Both capsules are almost but not  the same color.</li><li>Both capsules are made by some company with a history of making at least a modest effort to sell supplements that contain what they say they contain, and that don’t have terrifying levels of heavy metals.</li></ol><p>After a ludicrous amount of searching, I found that NOW® sells these veggie capsules:</p><p> 200 mg L-Theanine</p><p> 25 mcg (1,000 IU) Vitamin D</p><p>These are exactly the same size, exactly the same weight, exactly the same texture, and  close in color. They’re so close in color that under warm lighting, they’re indistinguishable. But under cold/blue lighting, the vitamin D capsules are  more yellow. Vitamin D might have some effects on mood, but no one seems to claim that they’re , that you’d feel them within an hour.</p><p>For dosing, I decided to take a capsule whenever I was feeling stressed or anxious. Some people worry this invalidates the results. Not so! I’m still choosing randomly, and this better reflects how people use theanine in practice.</p><p>Theanine is often recommended for reducing anxiety from caffeine. While I didn’t explicitly take caffeine as part of this experiment, I had almost always taken some anyway.</p><p>Statistically, it would have been best to randomize so I had a 50% chance of taking theanine and a 50% chance of taking vitamin D. But I decided that would be annoying, since I was taking these capsules when stressed. So I decided to randomize so I got theanine ⅔ of the time and vitamin D ⅓ of the time.</p><p>Randomization was very easy: I took two theanine capsules and one vitamin D capsule and put them into a little cup. I then closed my eyes, shook the cup around a bit and took one. I then covered the cup with a card.</p><p>This picture shows one vitamin D capsule (top) and two theanine capsules.</p><p>For each trial, I recorded my subjective starting stress level on a scale of 1-5, then set an alarm for an hour, which is <a href=\"https://doi.org/10.3945/jn.112.166371\">enough</a> to reach near-peak concentrations in the blood. After the alarm sounded (or occasionally later, if I missed it) I recorded the end time, my end stress level, and my percentage prediction that what I’d taken was actually theanine. Then, and only then, I looked into the cup. If the two remaining pills were different colors, I’d taken theanine. If not, it was vitamin D.</p><p>After ~14 months, I got frustrated by how slowly data was coming in. This was the first time in my life I’ve had  much chill. At that point, I decided to start taking the capsules once or twice a day, even if I wasn’t stressed. I’ll show the transition point in the graphs below.</p><p>Ultimately, I collected 94 data points, which look like this:</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>Here are the raw stress levels. Each line line shows one trial, with the start marked with a tiny horizontal bar. Note the clear change when I started dosing daily:</p><p>Alternatively, here’s the  in stress (end - start) as a function of time. If “Δ Stress” is negative, that means stress went down.</p><p>Here are the start and end stress levels for each trial, ignoring time. The dotted line shows equal stress levels, so anything below that line means stress went down:</p><p>Finally, here are the probabilities I gave that each capsule was in fact theanine.</p><p>My stress level  usually go down, at least provided I was stressed at the start. But it went down regardless of if I took theanine or not. And I was  at guessing what I’d taken.</p><p>Why did my stress decrease when I took vitamin D? Maybe it’s the placebo effect. But I suspect it’s mostly reversion to the mean: If you mark down the times in your life when you’re most stressed, on average you’ll be less stressed an hour later. You can see some evidence for this in that stress tended to decrease more when it started at a higher level.</p><p>So, eyeballing the above figures, theanine doesn’t appear to do anything. (We can argue about statistics below.) Why? I think these are the possibilities:</p><ol><li>Theanine works, but I got fake theanine.</li><li>Theanine works, but vitamin D works equally well.</li><li>Theanine works, but I was unlucky.</li><li>Theanine works, but I’m disembodied and unable to report my internal states.</li><li>Theanine works on some people, but not me.</li></ol><p>It’s hard to disprove the idea that theanine works. But I tell you this: I expected it to work. And I  tried. For almost 100 trials over 16 months, I paid attention to what I was feeling and tried to detect  sign that I’d taken theanine, even if it wasn’t a change in stress. I could detect nothing. Even after months of failure, I’d often feel confident that  time I could tell, only to be proven wrong.</p><table><tbody></tbody></table><p>Should I have been surprised by these results? Well, the scientific literature on theanine hasn’t found much of an effect. And the only other  self-experiment on theanine I’ve found is by <a href=\"https://niplav.site/nootropics#LTheanine\">Niplav</a>, who found it did slightly worse than chance and declared it a “hard pass”.</p><p>What about other blinded self-experiments with other substances? They’re surprisingly scarce, but here’s what I could find:</p><p>Stimulants work! But for everything else…</p><p>I particularly encourage you to read the sleep support post. He was confident it worked, he’d recommended it to lots of friends, but it totally failed when put to the test.</p><p>I’ve seen  other self-experiments (including for theanine), but they’re non-blinded and I’d be doing you a disservice if I linked to them. People often mention that  this means the results aren’t scientific, but treat it like a small niggling technicality. It’s not.</p><p>So I propose a new rule: Blind trial or GTFO.</p><p>I know many people reading this probably use and like theanine. Maybe it works for you! But given the weak academic results, and given the fact that I actually did a blinded experiment, I think you now have the burden of proof. Doing this kind of test isn’t hard. If you’re sure theanine (or anything else) works, prove it.</p><h2>Appendix: OK fine let’s argue about statistics</h2><p>Do you demand p-values? Are you outraged I just plotted the data and then started talking about it qualitatively?</p><p>I think faith in statistics follows a U-shaped curve. By default, people don’t trust them. If you learn a  statistics, they seem great. (Particularly if you’re part of a community that’s formed a little cult around one set of statistical practices and convinced each other that they’re more reliable than they are.) But if you learn a  of statistics, then you realize all the assumptions that are needed and all the ways things can go wrong and you become very paranoid.</p><p>If you want p-values, I’ll give you p-values. But first let me point out a problem.</p><p>While I was blinded during each trial, I saw the theanine/D result when I wrote it down. Over time I couldn’t help but notice that my stress dropped even when I took vitamin D, and that I was terrible at predicting what I’d taken. So while this experiment is randomized and blinded, the data isn’t  or . If I did this again, I’d make sure I couldn’t see any outcomes until the end, perhaps by making 100 numbered envelopes, putting three capsules in each, and only looking at what was left at the end.</p><p>But if you want to compute p-values anyway, OK! Here are the basic numbers for the trials when I took theanine:</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>Stress went down, p &lt; .0000001. But here are the the numbers for vitamin D:</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>Technically, I did find two significant results. But the second row says that end stress was slightly  with theanine than with vitamin D, and the last row says that I gave slightly  probabilities that I’d taken theanine when I’d actually taken vitamin D.</p><p>Of course, I don’t think this means I’ve proven theanine is harmful. I just think this confirms my general paranoia. To a first approximation, if it ain’t visible in the raw data, I ain’t going.</p><p>Speaking of raw data, you can download mine <a href=\"https://dynomight.net/img/theanine/data.csv\">here</a>.</p>","contentLength":12343,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43305803"},{"title":"Kill your Feeds – Stop letting algorithms dictate what you think","url":"https://usher.dev/posts/2025-03-08-kill-your-feeds/","date":1741457506,"author":"tom_usher","guid":237,"unread":true,"content":"<div data-intro=\"\">\nWe are being boiled like frogs. It happened gradually, one algorithmic tweak at a time. What started as a way to connect with friends has become a system that gives the corporations that run social media control over what we consume and the ability to subtly shape how we think.\n</div><p>We used to control apps like Facebook and Instagram with our own choices. They became daily comforts, making the world seem a little bit smaller and closer by bringing the people that we cared about together in to one place.</p><p>But from the perspective of these companies, that’s a problem. Our personal worlds, our friends, family, and connections, are finite. Once we’ve caught up, we put the app down. That’s bad for business.</p><p>Social media companies need us flicking through their apps as long as they can keep us there. More eyes on ads is more money. So they play the system a bit. You’ve lingered on enough photos of cute puppies, they know what you like.</p><p>Before long those feeds of finite content are replaced by infinite algorithmic content pulled from millions of users trying to optimise their posts to be picked up by the omnipotent algorithms. Algorithms which are completely opaque to us.</p><p>Sci-fi imagines megacorporations controlling our minds with brain implants. Some worry that companies are already listening in. But they don’t have to - they already control our eyes.</p><p>The creators of TikTok, Instagram etc. have gained control over exactly what we see. What we see strongly influences how we think. <a href=\"https://en.m.wikipedia.org/wiki/2021_Facebook_leak\">They know</a> that their feeds make us angry, they know the negative effects on our mental health (particularly that of teens), and they know that they have an influence on our opinion.</p><p>With the power to shape what we see comes the power to shape what we believe. Whether through deliberate manipulation or the slow creep of algorithmic recommendations, engagement is fueled by outrage, and outrage breeds extremism. The result is a feedback loop that isolates users, reinforces beliefs, and deprioritises opposing viewpoints.</p><p>We live in times where being able to form our own opinion is more important than ever. Where knowing how to source and identify truthful information is a critical skill.</p><p>Our reliance on being spoon fed ideas is destroying those abilities, Alec of Technology Connections calls this <a href=\"https://youtu.be/QEJpZjg8GuA\">algorithmic complacency</a>, referencing our increasing inability to look outside our algorithmically created bubble. The social media companies don’t care, the only person who has any interest in fixing this is you.</p><p>It’s time to take back control of how we think. We’ve identified the problem, now it’s time to take action.</p><p>We don’t all have the freedom, interest or willpower to delete social media from our lives entirely. It’s still where our friends are, an occasional distraction from reality and a source of entertainment. You don’t have to become a digital outcast to hold back this influence.</p><ol><li>Go directly to the source - if you like a particular TikTok creator, Facebook page or YouTube channel, skip the feed and go directly to their pages. Consider bookmarking their profiles individually.</li><li>Learn to find information and entertainment without a feed - try to find a creator making videos or writing about a topic of interest without having to stumble across them in a feed.</li><li>Use platforms and platform features that let you control your experience - Instagram’s ‘Following’ feed, YouTube’s Subscriptions page, <a href=\"https://bsky.app\">Bluesky</a>, <a href=\"https://mastodon.social\">Mastodon</a> and <a href=\"https://zapier.com/blog/how-to-use-rss-feeds/\">RSS feeds</a></li><li>Be mindful of engagement traps - recognise how algorithmic feeds are designed to keep you engaged and scrolling. Take a breath and stop the cycle.</li><li>Talk about it - if you’re reading this you a already know this is a problem. Your friends and family may not be aware of how their feeds are manipulating their attention and beliefs. Without intervention, the radicalisation of opinions, and the consequences we’re already seeing, will only escalate.</li></ol><p>The internet should serve you, not the other way around. Take back control. Kill your feeds before they kill your ability to think independently.</p>","contentLength":4057,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43302132"},{"title":"The DOJ still wants Google to sell off Chrome","url":"https://www.wired.com/story/the-doj-still-wants-google-to-divest-chrome/","date":1741438638,"author":"hydrolox","guid":236,"unread":true,"content":"<p>The proposal, filed Friday afternoon, says that Google must “promptly and fully divest Chrome, along with any assets or services necessary to successfully complete the divestiture, to a buyer approved by the Plaintiffs in their sole discretion, subject to terms that the Court and Plaintiffs approve.” It also would require Google to stop paying partners for preferential treatment of its search engine.</p><p>The DOJ also demands that Google provide prior notification of any new joint venture, collaboration, or partnership with any company that competes with Google in search or in search text ads. However, the company no longer has to divest its artificial intelligence investments, which was part of an initial set of recommendations issued by the plaintiffs last November. The company would still be required to give prior notification of future AI investments.</p><p>“Through its sheer size and unrestricted power, Google has robbed consumers and businesses of a fundamental promise owed to the public—their right to choose among competing services,” the DOJ statement accompanying the filing claims. “Google’s illegal conduct has created an economic goliath, one that wreaks havoc over the marketplace to ensure that—no matter what occurs—Google always wins.”</p><p>The DOJ formally brought its case against Google back in 2020, the most significant tech antitrust case since the DOJ’s years-long battle against Microsoft in the 1990s. The lawsuit alleged that Google has used anticompetitive tactics to protect its search dominance and forge contracts that ensure it’s the default search engine on web browsers and smartphones. Because of its hold on search, the lawsuit claimed, Google can adjust the auction system through which it sells ads and increase prices for advertisers, and rake in more revenue from that.</p><p>Google has argued that its overwhelming success in search—it has a nearly 90 percent share in the US market—stems from the company offering the best search technology. It also says consumers are easily able to change their default search engine, and that Google does face competition from Microsoft and others.</p><p>“DOJ’s sweeping proposals continue to go miles beyond the court’s decision, and would harm America’s consumers, economy and national security,” said Google spokesperson Peter Schottenfels in an emailed statement.</p><p>Much of the ruling centered on the contracts Google has with device makers and browser partners, which use Google as their default search technology. According to Mehta’s ruling, around 70 percent of search queries in the US happen through portals in which Google is the default search engine. Google then shares revenues with those partners, paying out billions of dollars to them, which disincentivizes smaller search rivals who can’t compete with those contracts, Mehta said.</p>","contentLength":2847,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43299886"},{"title":"Volkswagen reintroducing physical controls for vital functions","url":"https://www.autocar.co.uk/car-news/new-cars/volkswagen-reintroducing-physical-controls-vital-functions","date":1741418749,"author":"zfg","guid":235,"unread":true,"content":"<p>All future <a href=\"https://www.autocar.co.uk/car-review/volkswagen\">Volkswagen</a> models will feature physical controls for the most important functions, design chief Andreas Mindt has said.</p><p>The German firm has been criticised over the past few&nbsp;years for moving many of the vital controls in its cars from physical buttons and dials to the infotainment touchscreen. Volkswagen also introduced haptic ‘sliders’ below the touchscreen for the heating and volume&nbsp;and it started using haptic panels instead of buttons for controls mounted on the steering wheel.</p><p>More recently, the firm has reintroduced physical steering wheel buttons and Mindt said it is committed to reintroducing physical buttons, starting with the production version of the <a href=\"https://www.autocar.co.uk/car-news/new-cars/2025-volkswagen-id-2-will-be-even-better-concept\">ID 2all concept</a> that will arrive next year.</p><p>“From the ID 2all onwards, we will have physical buttons for the five most important functions – the volume, the heating on each side of the car, the fans and the hazard light – below the screen,” said Mindt. “They will be in every car that we make from now on. We understood this.</p><p>“We will never, ever make this mistake any more. On the steering wheel, we will have physical buttons. No guessing any more. There's feedback, it's real, and people love this. Honestly, it's a car. It's not a phone: it's a car.”</p><p>Mindt said VW will continue to offer cars with touchscreens, in part due to new legal requirements that, as in the US, will require all cars to feature a reversing camera.&nbsp;</p><p>“There are a lot of functions you have to deliver in certain areas, so the screen will be big and you will find a lot of HMI [human-machine interface] contents in the depths of the system,” he added. “But the five main things will always be on the first physical layer. That’s very important.”</p>","contentLength":1726,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43298271"},{"title":"AI tools are spotting errors in research papers","url":"https://www.nature.com/articles/d41586-025-00648-5","date":1741388098,"author":"kgwgk","guid":234,"unread":true,"content":"<figure><picture><img alt=\"A large stack of papers and folders with coloured tabs.\" loading=\"lazy\" src=\"//media.nature.com/lw767/magazine-assets/d41586-025-00648-5/d41586-025-00648-5_50703894.jpg\"><figcaption></figcaption></picture></figure><p>Late last year, media outlets worldwide warned that black plastic cooking utensils contained worrying levels of cancer-linked flame retardants. The risk was found to be overhyped — a mathematical error in the underlying research suggested a key chemical exceeded the safe limit when in fact it was ten times lower than the limit. Keen-eyed researchers quickly showed that an artificial intelligence (AI) model could have spotted the error in seconds.</p><p>The incident has spurred two projects that use AI to find mistakes in the scientific literature. The Black Spatula Project is an open-source AI tool that has so far analysed around 500 papers for errors. The group, which has around eight active developers and hundreds of volunteer advisers, hasn’t made the errors public yet; instead, it is approaching the affected authors directly, says Joaquin Gulloso, an independent AI researcher based in Cartagena, Colombia, who helps to coordinate the project. “Already, it’s catching many errors,” says Gulloso. “It’s a huge list. It’s just crazy.”</p><p>The other effort is called YesNoError and was inspired by the Black Spatula Project, says founder and AI entrepreneur Matt Schlicht. The initiative, funded by its own dedicated cryptocurrency, has set its sights even higher. “I thought, why don’t we go through, like, all of the papers?” says Schlicht. He says that their AI tool has analysed more than 37,000 papers in two months. Its website flags papers in which it has found flaws – many of which have yet to be verified by a human, although Schlicht says that YesNoError has a plan to eventually do so at scale. Currently, the YesNoError site lists errors which are not real and the initiative has not yet published a full account of how well the tool works.</p><p>Both projects want researchers to use their tools before submitting work to a journal, and journals to use them before they publish, the idea being to avoid mistakes, as well as fraud, making their way into the <a href=\"https://www.nature.com/articles/d41586-025-00026-1\" data-track=\"click\" data-label=\"https://www.nature.com/articles/d41586-025-00026-1\" data-track-category=\"body text link\">scientific literature</a>.</p><p>The projects have tentative support from academic sleuths who work in research integrity. But there are also concerns over the potential risks, including that the tools could be used maliciously and before they are ready. How well the tools can spot mistakes, and whether their claims have been verified, must be made clear, says Michèle Nuijten, a researcher in metascience at Tilburg University in the Netherlands. “If you start pointing fingers at people and then it turns out that there was no mistake, there might be reputational damage,” she says.</p><p>Others add that although there are risks and the projects need to be cautious about what they claim, the goal is the right one. It is much easier to churn out shoddy papers than it is to retract them, says James Heathers, a forensic metascientist at Linnaeus University in Växjö, Sweden. As a first step, AI could be used to triage papers for further scrutiny, says Heathers, who has acted as a consultant for the Black Spatula Project. “It’s early days, but I’m supportive” of the initiatives, he adds.</p><p>Both the Black Spatula Project and YesNoError use large language models (LLMs) to spot a range of errors in papers, including ones of fact as well as in calculations, methodology and referencing.</p><p>The systems first extract information, including tables and images, from the papers. They then craft a set of complex instructions, known as a prompt, which tells a ‘reasoning’ model — a specialist type of LLM — what it is looking at and what kinds of error to hunt for. The model might analyse a paper multiple times, either scanning for different types of error each time, or to cross-check results. The cost of analysing each paper ranges from 15 cents to a few dollars, depending on the length of the paper and the series of prompts used.</p><p>The rate of false positives, instances in which the AI claims an error where there is none, is a major hurdle. Currently, the Black Spatula Project’s system is wrong about an error around 10% of the time, says Gulloso. Each alleged error must be checked with experts in the subject, and finding them is the project’s greatest bottleneck, says Steve Newman, the software engineer and entrepreneur who founded the Black Spatula Project.</p><p>So far, Schlicht’s YesNoError team has quantified the false positives in only around 100 mathematical errors that the AI found in an initial batch of 10,000 papers. Of the 90% of authors who responded to Schlicht, all but one agreed that the error detected was valid, he says. Eventually, YesNoError is planning to work with ResearchHub, a platform which pays PhD scientists in cryptocurrency to carry out peer review. When the AI has checked a paper, YesNoError will trigger a request to verify the results, although this has not yet started.</p>","contentLength":4812,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43295692"},{"title":"Age Verification Laws: A Backdoor to Surveillance","url":"https://www.eff.org/deeplinks/2025/03/first-porn-now-skin-cream-age-verification-bills-are-out-control","date":1741372442,"author":"hn_acker","guid":233,"unread":true,"content":"<h3><b>Age Verification Laws: A Backdoor to Surveillance</b></h3><p><a href=\"https://www.route-fifty.com/digital-government/2025/02/alabama-house-bills-would-limit-social-media-access-minors/403172/?oref=rf-homepage-river\"></a></p><ol><li><a href=\"https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202520260AB728\"></a></li><li><a href=\"https://www.nysenate.gov/legislation/bills/2025/A3323\"></a></li><li><a href=\"https://app.leg.wa.gov/billsummary?BillNumber=5622&amp;Initiative=False&amp;Year=2025\"></a></li></ol><h3><b>The Problem with Age Verification: No Solution Is Safe</b></h3><p><b>no method of age verification is both privacy-protective and entirely accurate</b><a href=\"https://www.eff.org/deeplinks/2024/10/eff-new-york-age-verification-threatens-everyones-speech-and-privacy\"></a></p><p><a href=\"https://www.eff.org/deeplinks/2025/01/face-scans-estimate-our-age-creepy-af-and-harmful\"></a><a href=\"https://www.eff.org/deeplinks/2024/06/hack-age-verification-company-shows-privacy-danger-social-media-laws\"></a></p><p><a href=\"https://www.eff.org/deeplinks/2024/03/analyzing-kosas-constitutional-problems-depth\"></a><a href=\"https://www.eff.org/wp/privacy-first-better-way-address-online-harms\"></a></p>","contentLength":181,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43292820"},{"title":"Differentiable Logic Cellular Automata","url":"https://google-research.github.io/self-organising-systems/difflogic-ca/?hn","date":1741304617,"author":"eyvindn","guid":232,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43286161"},{"title":"Succinct data structures","url":"https://blog.startifact.com/posts/succinct/","date":1741283317,"author":"pavel_lishin","guid":231,"unread":true,"content":"<p>A few months ago, searching for ideas on how to make some code faster, I found\nmyself reading a bunch of computer science papers. I don't pretend to be good\nat this - but I don't mind some confusion or being overwhelmed, and I'm okay to\nadmit my ignorance. . I ran into this 15 year old paper \nthat introduced several concepts entirely new to me. I struggled to understand\nthem.</p><p>So what do you do then? You look for more papers to help explain things. This\nis a risky endeavor, because they might confuse you even more, but it cannot be\navoided. I discovered a paper for a relevant data structure that mentioned\nsource code on a website. The source code was in C++ and I am working in Rust,\nbut I figured I'd take a look anyway. But when I went to the website the\nresource wasn't there. So I mailed the owner of the website, who happened to be\na computer science professor.</p><p>This professor (<a href=\"https://users.dcc.uchile.cl/~gnavarro/\">Gonzalo Navarro</a>) was\nvery friendly and immediately mailed me back . Only during\nour conversation did I realize I was seeing his name on a  of papers in\nthe field. Turned out I had stumbled into talking to one of the world experts in\nthe field of succinct data strucures, within a few days of my discovery they\neven existed. Ignorance can bring you far.</p><p>So what are succinct data structures? If you've taken computer science courses\nin recent decades you might have, but I didn't run into them before as a\nprogrammer, or if I did, I immediately forgot. But now I think they're data\nstructures with fascinating properties.</p><p>We all use arrays, and <a href=\"https://en.wikipedia.org/wiki/Hash_table\">hashmaps</a>, and various trees are common too. We don't have to fully\nunderstand how they work in order to be able to leverage their properties\neffectively. Now I found msyelf wondering why people don't use these succinct\ndata structures more often.</p><p>So I figured I'd talk a bit about them.</p><p>To introduce succinct data structures it's useful to compare them to\ncompression. You use compression to shrink the size required to represent this\ndata. Compression can be useful to save disk space, or transmit less data over\nthe network, or to save memory. But to do anything useful with compressed data,\nsuch as access it or query it, you first need to uncompress it again. Then\nafterwards if you want to save space, you need to compress it again.</p><p>Succinct data structures are different: they store their content in a compact\nfashion like compression, but the compact form of the data has useful\nproperties. You can still use it!</p><p>This is a field that seems to have emerged in computer science relatively\nrecently; many of the important data structures were invented in the last 25\nyears.</p><p>In this article I going to give a tour of some of the succinct data structures\nI have run into. I do not claim any expertise in this area at all - I only have\nthe vaguest notion of how many of these data structures work. Heck, I only\ndiscovered they existed a few months ago! But as I said, you don't need to know\nhow they work in order to use them.</p><p>In systems programming one cares more about the particular characteristics\n(memory, performance) of data structures than usual. It strikes me there are\nquite a few potential applications for them in this field. Much of the original\nresearch work with compact data structures was done with C++. I myself like to\nuse Rust for my systems programming, so I looked for implementations in Rust.\nI'm going to share what I found in the hopes other developers who use Rust find\nthem interesting. But the general overview is not limited to Rust in any way,\nso if you're not interested in Rust I invite you to read on as well.</p><p>Consider a vector (array) of bits. For instance </p><p>What I'm going to say is pretty\nobvious, but I think it's useful to highlight anyway. The bit vector above is 8\nentries long. This means it fits into a single byte of memory.</p><p>On a 64 bit computer, 64 bits fit in a single native integer. That's a bit\nvector of 64 entries fitting inside 8 bytes, which is quite a lot if you\nconsider that a normal array takes that many bytes for a  integer\nvalue. Even a bool in Rust takes a byte of storage.</p><p>Bit vectors themselves aren't succinct data structures. In the end computer\nmemory is a giant array of bits. But succinct data structures try to make every\nbit count.</p><p>It's also important to note that a data structure might present itself as a bit\nvector but actually stores the information inside in some special way that\nmakes certain operations fast. That's what we're going to see next.</p><p>The rank/select bit vector is a core succinct data structure that many others\nare built on. When I was hunting for source code I had only just realized that\nthese weren't just plain bit vectors but supported special operations, \nand .</p><p>Let's look at our bit vector from before: .</p><p>We give each entry an index (from 0 to 8, not inclusive).</p><p>The  operation, given an index, counts how many bits have been set before\nit in the array:</p><p>So,  is 0 as no bits have been set at this position yet,  is\n1,  is 1 as well (there's a 0 in that location, so no more bits have\nbeen set).  is 2.  is 4.</p><p>The  operation is the inverse of rank. You can give it a rank and get\nthe index where that bit was set.</p><p>So  is 1,  is 3,  is 4, and  is 6.\nJust the subsequent indexes where you see a .</p><p>A succinct implementation of a rank/select bit vector can do these operations\nin constant time. Only a little bit more data than is taken up by the bit\nvector itself is required to support these operations.</p><p>So what are the use cases for this? Let's consider a simple one.</p><p>Let's say you have a big string that is actually composed of lots of little\nstrings. You want to track where all of these strings start. Now there are many\ndata structures you could use for this, and often they might be better, but\nlet's use a rank/select bit vector.</p><p>Here's string with positions under it:</p><pre><code></code></pre><p>Note the special  markers. These could be encoded as  in practice.</p><p>So, this big string has 4 substrings, which we can view as an array:</p><pre><code></code></pre><p>We can identify each substring with a number that is the index to this array:</p><pre><code></code></pre><p>Now let's consider a rank/select bit vector. For the points in this string\nwhere the substring starts, at each location you have an , you set a bit in\nit.</p><pre><code></code></pre><p>Now when you have any position in this you can efficiently determine which\nsub-string it belongs to using  - you get a substring identifier. For\ninstance, position 12 is in \"I am a string\" and  gets me .</p><p>If you add 1 to an identifier you get the next substring identifier - a useful\nproperty.</p><p>You can turn the substring identifier back into a position using . For\ninstance  gets you , the position of the first  in the string,\ni.e the start of . Add 1 to that and you have the start of the\nnext substring. So if you want to find the end of a string, you can add 1 to\nthe substring identifier and do a select on that.</p><p>This allows you to maintain unique identifiers for slices in a block of data in\na compact way.</p><p>With a normal rank/select bit vector you'd use 1 bit times the length of the\nstring as overhead, plus a little. For a string a megabyte long, that's 128\nkilobytes extra, and some change. But if the set bits are relatively uncommon\nyou can use a  rank/select bit vector to store this additional\ninformation very efficiently, in far less space than would be required for the\noriginal bit vector.</p><p>In Rust I've really enjoyed working with\n<a href=\"https://crates.io/crates/vers-vecs\"></a> which has both excellent\nperformance and very minimal overhead over the original bit vector. The author\nis very responsive and is working a range of exciting new features.</p><p>Another worthwhile library is <a href=\"https://crates.io/crates/sucds\"></a>. Of\nparticular interest is its implementation of , which is a sparse\nimplementation.  in my opinion however has a better design for efficient\nconstruction of these data structures than  does. I'm therefore glad to\nreport that  is in the process of adding a sparse implementation as well.</p><p>A  sounds like something out of science fiction. \"Doc, the\nwavelet matrix is out of sync! We cannot get back to 1985!\". Related other\nstructures are , including the  which also\nhas a pretty cool scifi name.</p><p>What these data structures do is generalize rank/select over \"arbitrary\nalphabets\". The alphabet of a bit vector consists of 0 and 1, but many\nreal-world data has a bigger alphabet. Of particular interest in the succinct\ndata structure space is DNA, which has the alphabet of its nucleotides \"G\",\n\"C\", \"A\" and \"T\", size 4. Another very common alphabet is text. If you use\nUTF-8 and store its bytes its alphabet is of size 256. </p><p>Generally the smaller the alphabet, the better: the data structures need less\nspace and can be faster.</p><p>So let's consider the string \"banana\" in some text alphabet like ASCII.</p><p>We can now rank and select particular symbols in the alphabet. Let's consider\nthe letter (symbol) :</p><p> is 0, as there are no s yet at index 0. But \ngets you rank 3. Similarly  lets you find the index of a symbol in the\nstring:  gets you index 3, the index of the second .</p><p>The implementation of a wavelet matrix uses rank/select bit vectors underneath.</p><p>In Rust the <a href=\"https://crates.io/crates/vers-vecs\"></a> crate also has an\nimplementation of the wavelet matrix data structure.</p><p>An FM-index is data structure that lets you store text (any vector of symbols)\nin a compact way, but still allows important query operations. It doesn't use\nmuch more space than the original text (or in some cases, less).</p><p>The important queries here are:</p><ul><li><p> which counts how many occurrences of a certain pattern\n(substring) exist in the stored text.</p></li><li><p> which gives the index for each occurrence of the pattern in\nthe original text</p></li></ul><p>The ability to load up a huge string of DNA data into memory and then being\nable to find substrings in it fast is extremely useful in bioinformatics. But\nany use where you have a lot text against which you want to support search\noperations could potentially benefit from an FM-Index.</p><p>In Rust the <a href=\"https://crates.io/crates/fm-index\"></a> crate provides this\nfunctionality.</p><p>Originally the  crate used the\n<a href=\"https://docs.rs/fid/latest/fid/\"></a> crate (by the same author) for its\nunderlying rank/select bit vector. But I've recently ported  over to\nuse  instead, which boosted the performance of  considerably.</p><p>I've been working with the wonderful author of  to improve its API\nand functionality, and a lot more is coming in this space, including support\nfor storing and searching large strings consisting of multiple substrings.</p><p>Let's consider a tree of data, where each node can have arbitrary amounts of\nchildren. These are very common structures in programming. Both XML and JSON\ncan be represented by trees like this; so can programming language ASTs.</p><p>If you want to allow arbitrary navigation within the tree, you need the\nfollowing operations on nodes in the trees:</p><ul><li><p>: gives the node that this node is a child of</p></li><li><p>: gives the first child node of a node</p></li><li><p>: gives the next sibling of a node (within its parent)</p></li><li><p>: gives the previous sibling of a node (within its\nparent)</p></li></ul><p>And often this is how these trees are represented in memory. Along these lines:</p><pre data-lang=\"rust\"><code data-lang=\"rust\"></code></pre><p>This is quite a bit of information per node: on a 64 bit operating system this\nnode clocks in at 32 bytes, or 256 bits. A balanced parentheses tree allows the\nsame operations but takes only 2 bits per node! Well, there's a little overhead\ntoo used by the rank/select bit vector underneath, and a bit more in a\nmanagement data structure, but it's still impressively tiny.</p><p>How does it do this? In a very brief sketch, it basically encodes a tree as a\nseries of parentheses. Let's consider a single tree with a root node  and\ntwo child node  and :</p><p>This can be represented as \"(()())\".</p><p>The outer parentheses encode the root node  and the two inner  pairs\nencode its child nodes. Since we have only an opening parenthesis  and a\nclosing parenthesis , this information can be stored in a rank/select bit\nvector, with 1 for open and 0 for close.</p><p>And thanks to various clever operations using  and  and a bit\nof supplementary information it can support all of the navigation I mentioned\nabove, and quite a few operations more.</p><p>The amazing author of  is working on a Rust implementation on the\n branch of the  crate. I've been using it a lot in my own work\nand it's looking great!</p><h2>\nBuilding on these structures</h2><p>You can use these and other succinct data structures to build new functionality\nwith very interesting properties.</p><p>I'm working on XML processing in Rust , and the paper I mentioned in\nthe beginning described a way to store XML data using succinct data structures.</p><p>It use a balanced parenthesis tree to store the XML tree. This does not allow\none to attach information to nodes such as the XML tag information (i.e. the\n in  and ). But you can attach information to each node by\nmaintaining a sparse rank/select bit vector for each tag that marks the\nrelevant parenthesis with additional information.</p><p>This rank/select bit vector then allows fundamental new operations: you can\n\"jump\" to the first descendant node with a particular tag without having to\ntraverse the intervening nodes!</p><p>XML also contains text nodes. These can be attached to the tree by tracking\nwhich opening parenthesis have the text node tag. The paper also uses an\n to store the text nodes and allow fast queries over them.</p><p>While XML is perhaps a rather quaint application for these techniques, imagine\na programming language that stores its AST in such a way. Huge ASTs could be\nstored relatively compactly but still support interesting search operations,\nwhich might open up new ways to implement programming language compilers.</p><p>Now that I've discovered these data structures I'm left wondering where they\nwere in all my programming life. I suspect there's a lot of untapped potential\nin them for general computing. While data structures that use a lot more memory\ncan generally do many of these operations more efficiently, the ability to use\nless memory has performance implications all of its own. And until last\nDecember I had no idea they even existed! I'm sure there are a lot of\ndevelopers out there that could find interesting uses for them.</p><p>The experiences I've had recently with professors, as well as the open\nsource developers in the Rust succinct space, give me some badly needed new\nfaith in humanity.</p>","contentLength":13966,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43282995"},{"title":"Mistral OCR","url":"https://mistral.ai/fr/news/mistral-ocr","date":1741282779,"author":"littlemerman","guid":230,"unread":true,"content":"<p dir=\"ltr\">Throughout history, advancements in information abstraction and retrieval have driven human progress. From hieroglyphs to papyri, the printing press to digitization, each leap has made human knowledge more accessible and actionable, fueling further innovation.&nbsp;</p><p dir=\"ltr\">Today, we’re at the precipice of the next big leap—to unlock the collective intelligence of all digitized information. Approximately&nbsp;<a href=\"https://resources.data.gov/glossary/unstructured-data/\">90%</a> of the world’s organizational data is stored as documents, and to harness this potential, we are introducing <a href=\"https://docs.mistral.ai/capabilities/document/\">Mistral OCR</a>. <p>Mistral OCR is an Optical Character Recognition API that sets a new standard in document understanding. Unlike other models, Mistral OCR comprehends each element of documents—media, text, tables, equations—with unprecedented accuracy and cognition. It takes images and PDFs as input and extracts content in an ordered interleaved text and images.</p></p><p dir=\"ltr\">As a result, Mistral OCR is an ideal model to use in combination with a RAG system taking multimodal documents (such as slides or complex PDFs) as input.</p><p dir=\"ltr\">We have made Mistral OCR as the default model for document understanding across millions of users on Le Chat, and are releasing the API  at 1000 pages / $ (and approximately double the pages per dollar with batch inference). The API is available today on our developer suite&nbsp;<a href=\"http://console.mistral.ai\">la Plateforme</a>, and coming soon to our cloud and inference partners, as well as on-premises.</p><ol><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">State of the art understanding of complex documents</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Natively multilingual and multimodal</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Doc-as-prompt, structured output</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Selectively available to self-host for organizations dealing with highly sensitive or classified information</p></li></ol><h3 dir=\"ltr\">State of the art understanding of complex documents</h3><p dir=\"ltr\">Mistral OCR excels in understanding complex document elements, including interleaved imagery, mathematical expressions, tables, and advanced layouts such as LaTeX formatting. The model enables deeper understanding of rich documents such as scientific papers with charts, graphs, equations and figures.&nbsp;</p><p dir=\"ltr\">Below is an example of the model extracting text as well as imagery from a given PDF into a markdown file. You can access the notebook <a href=\"https://colab.research.google.com/drive/11NdqWVwC_TtJyKT6cmuap4l9SryAeeVt?usp=sharing\" target=\"_blank\" rel=\"noopener\">here</a>.&nbsp;</p><p dir=\"ltr\">Below we have side-by-side comparisons of PDFs and their respective OCR's outputs. Hover the slider&nbsp; to switch between input and output.&nbsp;</p><p dir=\"ltr\">Mistral OCR has consistently outperformed other leading OCR models in rigorous benchmark tests. Its superior accuracy across multiple aspects of document analysis is illustrated below. We extract embedded images from documents along with text. The other LLMs compared below, do not have that capability. For a fair comparison, we evaluate them on our internal “text-only” test-set containing various publication papers, and PDFs from the web; below:</p><div dir=\"ltr\" align=\"left\"><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table></div><p dir=\"ltr\">Since Mistral’s founding, we have aspired to serve the world with our models, and consequently strived for multilingual capabilities across our offerings. Mistral OCR takes this to a new level, being able to parse, understand, and transcribe thousands of scripts, fonts, and languages across all continents. This versatility is crucial for both global organizations that handle documents from diverse linguistic backgrounds, as well as hyperlocal businesses serving niche markets.</p><div dir=\"ltr\" align=\"left\"><table><thead><tr><th>Fuzzy Match in Generation</th></tr></thead><tbody><tr></tr></tbody></table></div><div dir=\"ltr\" align=\"left\"><table><thead><tr></tr></thead><tbody></tbody></table></div><p dir=\"ltr\">Being lighter weight than most models in the category, Mistral OCR performs significantly faster than its peers, processing up to 2000 pages per minute on a single node. The ability to rapidly process documents ensures continuous learning and improvement even for high-throughput environments.</p><h3 dir=\"ltr\">Doc-as-prompt, structured output</h3><p dir=\"ltr\">Mistral OCR also introduces the use of documents as prompts, enabling more powerful and precise instructions. This capability allows users to extract specific information from documents and format it in structured outputs, such as JSON. Users can chain extracted outputs into downstream function calls and build agents.</p><h3 dir=\"ltr\">Available to self-host on a selective basis</h3><p dir=\"ltr\">For organizations with stringent data privacy requirements, Mistral OCR offers a self-hosting option. This ensures that sensitive or classified information remains secure within your own infrastructure, providing compliance with regulatory and security standards. If you would like to explore self-deployment with us, please <a href=\"https://mistral.ai/contact\">let us know</a>.</p><p dir=\"ltr\">We are empowering our beta customers to elevate their organizational knowledge by transforming their extensive document repositories into actions and solutions. Some of the key use cases where our technology is making a significant impact include:</p><p dir=\"ltr\"><strong>Digitizing scientific research</strong>: Leading research institutions have been experimenting with Mistral OCR to convert scientific papers and journals into AI-ready formats, making them accessible to downstream intelligence engines. This has facilitated measurably faster collaboration and accelerated scientific workflows.</p><p dir=\"ltr\"><strong>Preserving historical and cultural heritage</strong>: Organizations and nonprofits that are custodians of heritage have been using Mistral OCR to digitize historical documents and artifacts, ensuring their preservation and making them accessible to a broader audience.</p><p dir=\"ltr\"><strong>Streamlining customer service</strong>: Customer service departments are exploring Mistral OCR to transform documentation and manuals into indexed knowledge, reducing response times and improving customer satisfaction.</p><p dir=\"ltr\"><strong>Making literature across design, education, legal, etc. AI ready</strong>: Mistral OCR has also been helping companies convert technical literature, engineering drawings, lecture notes, presentations, regulatory filings and much more into indexed, answer-ready formats, unlocking intelligence and productivity across millions of documents.</p><p dir=\"ltr\">Mistral OCR capabilities are free to try on <a href=\"http://chat.mistral.ai\">le Chat</a>. To try the API, head over to <a href=\"http://console.mistral.ai\">la Plateforme</a>. We’d love to get your feedback; expect the model to continue to get even better in the weeks to come. As part of our strategic engagement programs, we will also offer on-premises deployment on a <a href=\"https://mistral.ai/contact\">selective basis</a>.</p>","contentLength":5916,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43282905"},{"title":"Anime fans stumbled upon a mathematical proof","url":"https://www.scientificamerican.com/article/the-surprisingly-difficult-mathematical-proof-that-anime-fans-helped-solve/","date":1741279054,"author":"classichasclass","guid":229,"unread":true,"content":"<p data-block=\"sciam/paragraph\">Math solutions can be found in surprising places, including the dark realms of the Internet. In 2011 an anonymous poster on the now infamously controversial image board 4chan posed a mathematical puzzle about the cult classic anime series <i>The Melancholy of Haruhi Suzumiya</i>. Though the bulletin board has become littered with hateful, violent and extreme content, that original post led to a solution to the sophisticated math problem.</p><p data-block=\"sciam/paragraph\">The first season of this anime series consists of 14 episodes that were designed so that you can watch them in any order you like. (For people who are as unfamiliar with the anime world as I am: an eight-part live-action thriller called  on Netflix follows the same principle.) At some point in a 2011 discussion of the series on 4chan, someone asked the minimum number of episodes they would have to watch to have seen it in every possible order.</p><p data-block=\"sciam/paragraph\">In fact, this question is related to so-called superpermutations. And as it turns out, this mathematical area holds many puzzles: to this day, mathematicians are still unable to fully answer the problem that the 4chan user had posed.</p><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<a href=\"https://www.scientificamerican.com/getsciam/\">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><p data-block=\"sciam/paragraph\">But amazingly, in that discussion, one of the anonymous users made an estimate of the minimum amount of all episodes to watch with an approach that was previously unknown to mathematicians. “I’ll need to [elaborate on] this in multiple posts. Please look it over for any loopholes I might have missed,” wrote the user, who explained in several steps how they arrived at their estimate. Other users then took up the arguments and discussed them—but outside of 4chan, none of this made any waves. No one seemed to take any notice.</p><p data-block=\"sciam/paragraph\">In mathematics, two objects permutate when they are rearranged or recombined. For example, you can permutate AB to BA. If an anime series consisted of only two parts, you could either watch the first and then the second episode (1-2) or the second and then the first (2-1).</p><p data-block=\"sciam/paragraph\">If you want to watch a series in multiple arrangements—perhaps to figure out which sequence of episodes makes the most sense—you need a superpermutation. This is a sequence of all possible permutations. Imagine a marathon showing where you watch the first episode, followed by the second, and then watch the second episode, followed by the first (1-2-2-1). To avoid watching the second episode twice in a row, a shorter superpermutation would be 1-2-1; you would only have to watch three episodes to still have every possible order covered.</p><p data-block=\"sciam/paragraph\">If a series consists of three episodes, it becomes a little trickier to find the shortest superpermutation. In this case, there are 3! = 6 different sequences: 1-2-3, 1-3-2, 2-3-1, 2-1-3, 3-1-2, 3-2-1. Fortunately, you don’t have to watch 3 × 6 = 18 parts but can find a clever shortcut, in this case: 1-2-3-1-2-1-3-2-1. That order contains all possible permutations of the numbers 1, 2 and 3, but you only have to watch nine episodes!</p><p data-block=\"sciam/paragraph\">Mathematicians have also calculated the shortest superpermutations for a series consisting of  = 4 and  = 5 episodes (33 and 153 episodes, respectively). Beyond that, however, they are in the dark. The shortest superpermutations for  &gt; 5 are not known.</p><p data-block=\"sciam/paragraph\">In fact, the challenge relates to one of the most intractable problems in algorithmics: <a href=\"https://www.scientificamerican.com/article/the-math-mystery-that-connects-sudoku-flight-schedules-and-protein-folding/\">the traveling salesperson problem</a>. In this problem, a person wants to visit different cities and end up back in their hometown. The task is to find the shortest route that connects all the cities. The shortest superpermutation is a variation of this problem in which the individual permutations represent different cities. In this case, you assign different distances between cities by determining the overlap of the permutations. For example, cities 1-2-3 and 2-3-1 have a large overlap: the last two digits of the first permutation match the first two digits of the second, so they can be combined to form 1-2-3-1. We can therefore assign a short distance between those two cities. On the other hand, 1-2-3 and 2-1-3 do not overlap. (To see both sequences, you have to look at a full six parts; no shortcut is possible.) Thus, these cities have a large distance between them.</p><p data-block=\"sciam/paragraph\">To find the shortest route within permutations, you connect the permutations that overlap the most. There is only one difficulty: there is no known algorithm that solves the traveling salesperson problem quickly. If we are dealing with a few cities—or, in the case of an anime series, a few episodes—this is not a major drawback. But as soon as the  becomes large, computers fail at the task because the computing time grows exponentially with .</p><p data-block=\"sciam/paragraph\">Computers are able to calculate superpermutations for  = 4 and  = 5 but not for anything beyond that. And although it is possible to calculate elaborate superpermutations for larger numbers, finding the shortest superpermutation becomes more difficult.</p><p data-block=\"sciam/paragraph\">Experts must therefore make do with estimates. For example, there is an algorithm that helps estimate the length of the shortest possible superpermutation for  objects: 1! + 2! + 3! + ... + ! Using that algorithm, if  = 2, you get a superpermutation of length 1 + 2 = 3. For  = 3, this results in a length of 1 + 2 + 6 = 9. For  = 4, you get 33. And for  = 5, you get 153, which corresponds to the shortest superpermutation in each case.</p><p data-block=\"sciam/paragraph\">For larger  however, this algorithm no longer applies: computers have been able to find shorter superpermutations than it would suggest exists. In fact, the formula 1! + 2! + 3! + ... + ! massively overestimates the length of the shortest superpermutation for large . Although the algorithm offers only an approximate answer, mathematicians use it as a starting place, with the goal of narrowing down options to find more precise answers.</p><h2 data-block=\"sciam/heading\">Coincidences and Rediscoveries</h2><p data-block=\"sciam/paragraph\">In 2013 Nathaniel Johnston, now a mathematics professor at Mount Allison University in New Brunswick, landed on a <i>Melancholy of Haruhi Suzumiya</i> fandom page. Johnston himself was not an anime fan. He had arrived at the site after Googling some search terms related to superpermutations. There he came across the discussion that had been held on 4chan almost two years earlier, which a user had copied to the fandom site.</p><p data-block=\"sciam/paragraph\">Then in October 2018 mathematician Robin Houston came across his colleague’s blog post through a curious coincidence. Houston had just learned that Australian science fiction author Greg Egan had found a new length for the shortest superpermutations, expressed as:</p><p data-block=\"sciam/paragraph\">! +( –1)! + ( – 2)! + ( – 3)! + – 3</p><p data-block=\"sciam/paragraph\">That in itself was bizarre. But when Houston started learning more about this result, he realized that the minimum length of a superpermutation had been given a new value by an anonymous anime fandom user (he didn’t know about the origins on 4chan at that time). The formula for the minimum length is:</p><p data-block=\"sciam/paragraph\">! +( – 1)! + ( – 2)! +  – 3</p><p data-block=\"sciam/paragraph\">Houston shared <a href=\"https://x.com/robinhouston/status/1054637891085918209?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1054637891085918209%7Ctwgr%5Eaa026a45fed15b42edf702c30c79bae8cc6e60c7%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.spektrum.de%2Fkolumne%2Fsuperpermutation-und-anime-4chan-user-gelingt-mathematischer-beweis%2F2251925\">his discovery on Twitter</a> (now X) on October 23 of that year. “A curious situation. The best known lower bound for the minimal length of superpermutations was proven by an anonymous user of a wiki mainly devoted to anime,” he wrote.</p><p data-block=\"sciam/paragraph\">Along with his colleagues, mathematicians Jay Pantone and Vince Vatter, Houston decided to check the 4chan user’s proof and write it down in a mathematical way. <a href=\"https://oeis.org/A180632/a180632.pdf\">The researchers posted their mathematical work</a> to the Online Encyclopedia of Integer Sequences that same month, and the first author is listed as “Anonymous 4chan Poster.”</p><p data-block=\"sciam/paragraph\">So what do these formulas tell us? If you want to watch all episodes of an -part series in all possible combinations, you must sit through at least ! +(– 1)! + ( – 2)! +  – 3 episodes—that’s the 4chan user’s contribution—and at most ! +( – 1)! + ( – 2)! + ( – 3)! +  – 3, which we know through Egan’s work.</p><p data-block=\"sciam/paragraph\">In the case of the eight-episode series  you would have to watch at least 46,085 and, at most, 46,205 episodes. For <i>The Melancholy of Haruhi Suzumiya, </i>or  with 14 episodes, the number increases drastically: a minimum of 93,884,313,611 episodes and a maximum of 93,924,230,411. Recall that this is not a complete solution—it’s just setting a range for the size of a superpermutation that would allow you to efficiently watch the series in every possible order.</p><p data-block=\"sciam/paragraph\">Fortunately, Egan also provided an algorithm for constructing the corresponding superpermutation. This allows  fans to work out the best viewing order of episodes. But with an average episode length of around 24 minutes, it would take about 4 million years to sit through this superpermutation.</p>","contentLength":8739,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43282133"},{"title":"Age and cognitive skills: Use it or lose it","url":"https://www.science.org/doi/full/10.1126/sciadv.ads1560?af=R","date":1741264407,"author":"nabla9","guid":228,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43279494"},{"title":"Buy European Made. Support European Values","url":"https://www.buy-european-made.eu/","date":1741258737,"author":"doener","guid":227,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43278705"},{"title":"Revolt: Open-Source Alternative to Discord","url":"https://revolt.chat/","date":1741250852,"author":"OuterVale","guid":226,"unread":true,"content":"<p data-astro-cid-5njangeo=\"\">\nRespects your privacy. No ads, no trackers.\nMade in Europe, motherland of GDPR.\n</p>","contentLength":81,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43277918"},{"title":"The US stops sharing air quality data from embassies worldwide","url":"https://apnews.com/article/us-air-quality-monitors-8270927bbd0f166238243ac9d14bce03","date":1741222412,"author":"geox","guid":225,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43274821"},{"title":"QwQ-32B: Embracing the Power of Reinforcement Learning","url":"https://qwenlm.github.io/blog/qwq-32b/","date":1741201779,"author":"nwjsmith","guid":224,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43270843"},{"title":"Tailscale is pretty useful","url":"https://blog.6nok.org/tailscale-is-pretty-useful/","date":1741201759,"author":"marban","guid":223,"unread":true,"content":"<p>It’s probably old news for most, but I’ve recently started using <a href=\"https://tailscale.com\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Tailscale</a> and wanted to share my experience with it.</p><p>I’ve heard of Tailscale many times before, but didn’t get the appeal until recently. That happened when I started running a simple server from my trusty old Raspberry Pi version 1.</p><p>I know its local IP address and can  into it easily when I’m home, but when I’m outside, that’s not possible as it’s not exposed to the internet. For that reason, I have used DDNS in the past. The bad news is that it’s no longer possible thanks to a cursed thing called CGNAT. I don’t want to derail this post too much, but unfortunately port forwarding is no longer a thing that you can do. (And maybe it wasn’t such a good idea to expose your home server to the internet to begin with.)</p><p>This reminded me of Tailscale, and I decided to give it a go. From what I could remember, it creates a virtual private network so you can access your devices anywhere with domain shorthands created by Tailscale.</p><p>Long story short, it worked! I could connect from anywhere with  command. But my old Raspberry Pi was too weak to run it, so I ended up uninstalling it, and unrelatedly my pet project grew out and has its place in the cloud now.</p><p>To get started, you need to install the client software on the devices, which are mostly open-source. Then you need to log in with your account, which is an easy process. I won’t go into detail about how to install and use it, since this isn’t an ad, and such instructions can quickly go out-of-date.</p><p>Some additional and surprising benefits:</p><ol><li>Exposing a port from your laptop to your phone: When developing a web application, once in a while you’ll have to test on an actual device. (You do that, right?) The kind of thing you’d reach for <a href=\"https://ngrok.com\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ngrok</a> for. You can use the Tailscale-generated domain name (e.g. <code>http://my-macbook-air:3000</code>) to effortlessly connect to your development server.</li><li><a href=\"https://tailscale.com/kb/1106/taildrop\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Taildrop</a>: There’s been a lot of times when I needed to move files from my Macbook to my Windows HTPC, which is hard. I’d used Snapdrop, which is excellent for the limitations it has to work around, but I was always on the lookout for a click-less solution. With Taildrop, you can drop files as easily as Airdrop, even when you’re not in close proximity!</li><li><a href=\"https://tailscale.com/kb/1103/exit-nodes\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Exit nodes</a>: I clarified that Tailscale is a different kind of VPN, but I still need a VPN service from time to time, and I don’t like having two clients for a similar job. With Tailscale, you can appoint a machine to be an exit node, ideally one in a VPS in a different country, so you can get comparable benefits to a VPN service.</li><li><a href=\"https://tailscale.com/kb/1258/mullvad-exit-nodes\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Mullvad exit nodes</a>: Related to the previous point, I know that VPN services allow you to exit from a large list of countries, and don’t collect logs (if you believe them). With the <a href=\"https://mullvad.net/en/blog/tailscale-has-partnered-with-mullvad\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Mullvad partnership</a>, Tailscale allows you to have the best of both worlds. And from what I can understand, it’s essentially a two-tier VPN, like <a href=\"https://support.apple.com/en-us/102602\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">iCloud Private Relay</a>. Tailscale can’t see your traffic, and Mullvad doesn’t know who you are. If you’re a privacy nerd, you may find this to be a good setup.</li></ol><p>Disclaimer: I haven’t yet tried exit nodes or Mullvad integration, so your actual experience may not turn out as I described.</p><p>I have used Tailscale only for personal reasons so far, using the free tier; they have enterprise plans for enterprise use cases that I have no idea about. I found it useful and wanted to share it in case it helps you too. I wasn’t paid by them, and if you don’t want to use their services for any reason, there’s an open-source server implementation called <a href=\"https://headscale.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Headscale</a>, which works with their client software.</p><p>If you have more use cases, feel free to share them with me!</p>","contentLength":3720,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43270835"},{"title":"Apple takes UK to court over 'backdoor' order","url":"https://www.theregister.com/2025/03/05/apple_reportedly_ipt_complaint/","date":1741198026,"author":"latexr","guid":222,"unread":true,"content":"<p> Apple has reportedly filed a legal complaint with the UK's Investigatory Powers Tribunal (IPT) contesting the British government's order that it must forcibly break the encryption of iCloud data.</p><p>The appeal will be the first of its kind lodged with the IPT, an independent judicial body that <a target=\"_blank\" href=\"https://investigatorypowerstribunal.org.uk/\">oversees</a> legal complaints against potential unlawful actions by a public authority or UK intelligence services, according to the Financial Times, which broke the <a href=\"https://www.ft.com/content/3d8fe709-f17a-44a6-97ae-f1bbe6d0dccd\" rel=\"nofollow\">news</a>.</p><p>The revelation follows a battle between the iGadgetmaker and the UK's Home Office, which has long set its sights on Apple's encrypted cloud-hosted data, arguing it needs a backdoor in order for law enforcement to investigate persons of interest.</p><p>Things came to a head in January when the Home Office issued Apple with a technical capability notice (TCN) under the <a target=\"_blank\" href=\"https://www.theregister.com/2024/04/26/investigatory_powers_bill/\">Investigatory Powers Act</a>, aka the Snooper's Charter, nearly a year after talk of such an order began.</p><p>Despite being \"technical\" by name, it's understood that the notice didn't include any technical instructions for Apple, just an order to allow a so-called backdoor into its iCloud network which could be used to gather data that's otherwise typically out of reach of criminal investigators.</p><p>The Home Office refused to either confirm or deny the existence of the notice when <a href=\"https://www.theregister.com/2025/02/07/home_office_apple_backdoor_order/\">we asked about it</a>, and under the Investigatory Powers Act 2016 Apple is prevented from revealing details about the notice.</p><p>Apple responded by <a href=\"https://www.theregister.com/2025/02/07/home_office_apple_backdoor_order/\">disabling its Advanced Data Protection</a> (ADP) feature for UK users in early February, effectively removing end-to-end encryption (E2EE) for data backed up to iCloud to appease the government without fully complying with the TCN.</p><blockquote><p>We have never built a backdoor or master key to any of our products or services and we never will</p></blockquote><p>Still, it means British officials can feasibly sniff around iCloud accounts, provided they get a court-approved warrant to do so. With ADP disabled, various types of user account data – such as iCloud backups, photos, and notes, but not iMessages and health data – stored in Apple's cloud will not be end-to-end encrypted (E2EE), meaning the contents can be accessed and provided by Apple to investigators upon legal demand. It will also be done without alerting users, assuming someone involved in the process doesn't leak it at any stage.</p><p>\"We are gravely disappointed that the protections provided by ADP will not be available to our customers in the UK given the continuing rise of data breaches and other threats to customer privacy,\" Apple told  at the time.</p><p>\"As we have said many times before, we have never built a backdoor or master key to any of our products or services and we never will,\" it added.</p><p>The Home Office has also previously voiced its ambition to break E2EE for all popular communications platforms in the UK, such as messaging app WhatsApp, although the case with Apple is believed to be its first foray into handing out TCNs to this end.</p><p>The UK's entire approach to pressing ahead with the Investigatory Powers Act and its so-called war on encryption has come under intense scrutiny in recent years.</p><p>Its main arguments in favor of breaking encryption are largely based on the prevention of terror attacks and child sexual exploitation.</p><p>Security minister Dan Jarvis further justified the powers in Parliament <a target=\"_blank\" href=\"https://www.theyworkforyou.com/pbc/2023-24/Investigatory+Powers+(Amendment)+Bill/\">last week</a>, <a target=\"_blank\" href=\"https://hansard.parliament.uk/commons/2025-02-24/debates/9E7881D8-1693-48BA-9407-A180094039B6/HostileStateThreats\">saying</a> requests to access user data under the Act could only be made on an \"exceptional basis, and only when it is necessary and proportionate to do so.\"</p><p>Jarvis's comments came after being questioned by other MPs about the TCN, and seemingly aim to dissuade the public from thinking the government can simply access user data on a whim.</p><p>The security minister didn't offer much in the way of additional insights, whipping out the good old national security defense as a way to avoid further questioning.</p><p>Many who argue against the government's ambitions, such as Big Brother Watch, <a href=\"https://www.theregister.com/2025/02/24/apple_adp_replacements_e2ee/\">say</a> the action taken against Apple is \"outrageous\" and \"draconian\" and may eventually force encrypted messaging technology underground, meaning only criminals would have access to it.</p><p>US President Donald Trump also recently compared the UK's treatment of Apple to the extensive state surveillance methods deployed by China – the two countries' foremost intelligence adversary.</p><p>US director of national intelligence Tulsi Gabbard has ordered a legal review of the TCN issued to Apple out of concern it could be used to gather data on US citizens. Doing so would violate the terms of the US-UK <a href=\"https://www.theregister.com/2022/10/03/us_uk_data_access_agreement/\">Cloud Act Agreement</a>, she argued.</p><p> has asked Apple for further comment. ®</p><h3>Updated to add at 1833 UTC</h3><p>Interestingly enough, the UK government <a target=\"_blank\" rel=\"nofollow\" href=\"https://alecmuffett.com/article/112522\">appears to have scrubbed</a> from the web its previous and now politically inconvenient advice to barristers, solicitors, and others in sensitive professions to use Apple's ADP at-rest end-to-end encryption. Fancy that!</p>","contentLength":4823,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43270079"}],"tags":["dev","hn"]}