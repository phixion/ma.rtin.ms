{"id":"3MxaK2JpEReqbaaoXRjhqtHgzLzs7yD1MzDHmZohMpeP54G","title":"Martin Fowler","displayTitle":"Dev - Martin Fowler","url":"https://martinfowler.com/feed.atom","feedLink":"https://martinfowler.com/feed.atom","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":8,"items":[{"title":"Fragments: February 13","url":"https://martinfowler.com/fragments/2026-02-13.html","date":1770997500,"author":"Martin Fowler","guid":247,"unread":true,"content":"<p>I’ve been busy traveling this week, visiting some clients in the Bay Area and attending The Pragmatic Summit. So I’ve not had as much time as I’d hoped to share more thoughts from the <a href=\"https://martinfowler.com/bliki/FutureOfSoftwareDevelopment.html\">Thoughtworks Future of Software Development Retreat</a>. I’m still working through my notes and posting fragments - here are some more:</p><p>What role do senior developers play as LLMs become established? As befits a gathering of many senior developers, we felt we still have a bright future, focusing more on architectural issues than the messy details of syntax and coding. In some cases, folks who haven’t done much programming in the last decade have found LLMs allow them to get back to that, and managing LLM agents has a lot of similarities to managing junior developers.</p><p>One attendee reported that although their senior developers were very resistant to using LLMs, when those senior developers were involved in an exercise that forced them to do some hands-on work with LLMs, a third of them were instantly converted to being very pro-LLM. That suggests that practical experience is important to give senior folks credible information to judge the value, particularly since there’s been striking improvements to models in just the last couple of months. As was quipped, some negative opinions of LLM capabilities “are so January”.</p><p>There’s been much angst posted in recent months about the fate for junior developers, as people are worried that they will be replaced by untiring agents. This group was more sanguine about this, feeling that junior developers will still be needed, if nothing else because they are open-minded about LLMs and familiar with using them. It’s the mid-level developers who face the greatest challenges. They formed their career without LLMs, but haven’t gained the level of experience yet to fully drive them effectively in the way that senior developers do.</p><p>LLMs could be helpful to junior developers by providing a always-available mentor, capable of teaching them better programming. Juniors should, of course, have a certain skepticism of their AI mentors, but they should be skeptical of fleshy mentors too. Not all of us are as brilliant as I like to think that I am.</p><p>Attendee Margaret-Anne Storey has published a longer post on the problem of <a href=\"https://margaretstorey.com/blog/2026/02/09/cognitive-debt/\">cognitive debt</a>.</p><blockquote><p>I saw this dynamic play out vividly in an entrepreneurship course I taught recently. Student teams were building software products over the semester, moving quickly to ship features and meet milestones. But by weeks 7 or 8, one team hit a wall. They could no longer make even simple changes without breaking something unexpected. When I met with them, the team initially blamed technical debt: messy code, poor architecture, hurried implementations. But as we dug deeper, the real problem emerged: no one on the team could explain why certain design decisions had been made or how different parts of the system were supposed to work together. The code might have been messy, but the bigger issue was that the theory of the system, their shared understanding, had fragmented or disappeared entirely. They had accumulated cognitive debt faster than technical debt, and it paralyzed them.</p></blockquote><p>I think this is a worthwhile topic to think about, but as I ponder it, I look at it in a similar way to how I look at <a href=\"https://martinfowler.com/bliki/TechnicalDebt.html\">Technical Debt</a>. Many people focus on technical debt as the bad stuff that accumulates in a sloppy code base - poor module boundaries, bad naming etc. The term I use for bad stuff like that is , I use the technical debt metaphor as a way to think about how to deal with the costs that the cruft imposes. Either we pay the interest -  making each further change to the code base a bit harder, or we pay down the principal - doing explicit restructuring and refactoring to make the code easier to change.</p><p>What is this separation of the cruft and the debt metaphor in the cognitive realm? I think the equivalent of cruft is ignorance - both of the code and the domain the code is supporting. The debt metaphor then still applies, either it costs more to add new capabilities, or we have to make an explicit investment to gain knowledge. The debt metaphor reminds us that which we do depends on the relative costs between them. With cognitive issues, those costs apply on both the humans and <a href=\"https://martinfowler.com/articles/who-is-llm.html\">The Genie</a>.</p><blockquote><p>The Venn Diagram of Developer Experience and Agent Experience is a circle</p></blockquote><p>Many of the things we advocate for developers also enable LLMs to work more effectively too. Smooth tooling, clear information about the development environment, helps LLMs figure out how create code quickly and correctly. While there is a possibility that The Genie’s Galaxy Brain can comprehend a confusing code base, there’s growing evidence that good modularity and descriptive naming is as good for the transformer as it is for more squishy neural networks. This is getting recognized by software development management, leading to efforts to smooth the path for the LLM. But as Laura observed, it’s sad the this implies that the execs won’t make the effort for humans that they are making for the robots.</p><p>IDEs still have a future, but need to incorporate LLMs into their working. One way is to use LLMs to support things that cannot be done with deterministic methods, such as generating code from natural language documents. But there’s plenty of tasks where you don’t want to use an LLM - they are a horribly inefficient way to rename a function, for example. Another role for LLMs is to help users use them effectively - after all modern IDEs are complex tools, and few users know how to get the most out of them. (As a long-time Emacs user, I sympathize.) An IDE can help the user select when to use an LLM for a task, when to use the deterministic IDE features, and when to choreograph a mix of the two.</p><p>Say I have “person” in my domain and I want to change it to “contact”. It appears in function names, field names, documentation, test cases. A simple search-replace isn’t enough. But rather than have the LLM operate on the entire code base, maybe the LLM chooses to use the IDE’s refactoring capabilities on all the places it sees - essentially orchestrating the IDE’s features. An attendee noted that analysis of renames in an IDE indicated that they occur in clusters like this, so it would be a useful capability.</p><p>Will two-pizza teams shrink to one-pizza teams because LLMs don’t eat pizza - or will we have the same size teams that do much more? I’m inclined to the latter, there’s something about the two-pizza team size that effectively balances the benefits of human collaboration with the costs of coordination.</p><p>That also raises a question about the shape of pair programming, a question that came up during the panel I had with Gergely Orosz and Kent Beck at The Pragmatic Summit. There seems to be a common notion that the best way to work is to have one programmer driving a few (or many) LLM agents. But I wonder if two humans driving a bunch of agents would be better, combining the benefits of pairing with the greater code-generative ability of The Genies.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><blockquote><p>In an eight-month study of how generative AI changed work habits at a U.S.-based technology company with about 200 employees, we found that employees worked at a faster pace, took on a broader scope of tasks, and extended work into more hours of the day, often without being asked to do so.</p><p>While this may sound like a dream come true for leaders, the changes brought about by enthusiastic AI adoption can be unsustainable, causing problems down the line. Once the excitement of experimenting fades, workers can find that their workload has quietly grown and feel stretched from juggling everything that’s suddenly on their plate. That workload creep can in turn lead to cognitive fatigue, burnout, and weakened decision-making. The productivity surge enjoyed at the beginning can give way to lower quality work, turnover, and other problems.</p></blockquote><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><blockquote><p>The part of “everyone becomes a manager” in AI that I didn’t really think about until now was the mental fatigue of context switching and keeping many tasks going at once, which of course is one of the hardest parts of being a manager and now you all get to enjoy it too</p></blockquote><p>There’s an increasing feeling that there’s a shift coming our profession where folks will turn from programmers engaged with the code to supervisory programmers herding a bunch of agents. I do think that supervisory or not, programmers will still be accountable for the code generated under their watch, and it’s an open question whether increasing context-switching will undermine the effectiveness of driving many agents. This would lead to practices that seek to harvest the parallelism of agents while minimizing the context-switching.</p><p>Whatever route we go down, I expect a lot of activity in exploring what makes an effective workflow for supervisory programming in the coming months.</p>","contentLength":9182,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fragments: February 9","url":"https://martinfowler.com/fragments/2026-02-09.html","date":1770665520,"author":"Martin Fowler","guid":246,"unread":true,"content":"<p>Some more thoughts from last week’s open space gathering on the future of software development in the age of AI. I haven’t attributed any comments since we were operating under the <a href=\"https://www.chathamhouse.org/about-us/chatham-house-rule\">Chatham House Rule</a>, but should the sources recognize themselves and would like to be attributed, then get in touch and I’ll edit this post.</p><p>During the opening of the gathering, I commented that I was naturally skeptical of the value of LLMs. After all, the decades have thrown up many tools that have claimed to totally change the nature of software development. Most of these have been little better than snake oil.</p><p>But I am a  - which means I also have to be skeptical of my own skepticism.</p><p>One of our sessions focused on the problem of “cognitive debt”. Usually, as we build a software system, the developers of that system gain an understanding both the underlying domain and the software they are building to support it. But once so much work is sent off to LLMs, does this mean the team no longer learns as much? And if so, what are the consequences of this? Can we rely on <a href=\"https://martinfowler.com/articles/who-is-llm.html\">The Genie</a> to keep track of everything, or should we take active measures to ensure the team understands more of what’s being built and why?</p><p>The <a href=\"https://martinfowler.com/bliki/TestDrivenDevelopment.html\">TDD cycle</a> involves a key (and often under-used) step to refactor the code. This is where the developers consolidate their understanding and embed it into the codebase. Do we need some similar step to ensure we understand what the LLMs are up to?</p><p>When the LLM writes some complex code, ask it to explain how it works. Maybe get it do so in a funky way, such as asking it to explain the code’s behavior in the form of a fairy tale.</p><blockquote><p>LLMs are drug dealers, they give us stuff, but don’t care about the resulting system or the humans that develop and use it.</p></blockquote><p>Who cares about the long-term health of the system when the LLM renews its context with every cycle?</p><p>Programmers are wary of LLMs not just because folks are worried for their jobs, but also because we’re scared that LLMs will remove much of the fun from programming. As I think about this, I consider what I enjoy about programming. One aspect is delivering useful features - which I only see improving as LLMs become more capable.</p><p>But, for me, programming is more than that. Another aspect I enjoy about programming is model building. I enjoy the process of coming up with abstractions that help me reason about the domain the code is supporting - and I am concerned that LLMs will cause me to spend less attention on this model building. It may be, however, that model-building becomes an important part of working effectively with LLMs, a topic <a href=\"https://martinfowler.com/articles/convo-llm-abstractions.html\">Unmesh Joshi and I explored</a> a couple of months ago.</p><p>In the age of LLMs, will there still be such a things as “source code”, and if so, what will it look like? Prompts, and other forms of natural language context can elicit a lot of behavior, and cause a rise in the level of abstraction, but also a <a href=\"https://martinfowler.com/articles/2025-nature-abstraction.html\">sideways move into non-determinism</a>. In all this is there still a role for a persistent statement of non-deterministic behavior?</p><p>Almost a couple of decades ago, I became interested in a class of tools called <a href=\"https://martinfowler.com/articles/languageWorkbench.html\">Language Workbenches</a>. They didn’t have a significant impact on software development, but maybe the rise of LLMs will reintroduce some ideas from them. These tools rely on a <a href=\"https://martinfowler.com/articles/languageWorkbench.html#workbench.gif\">semantic model</a> that the tool persists in some kind of storage medium, that isn’t necessarily textual or comprehensible to humans directly. Instead, for humans to understand it, the tools include projectional editors that create human-readable projections of the model.</p><p>Could this notion of a non-human deterministic representation  become the future source code? One that’s designed to maximize expression with minimal tokens?</p><blockquote><p>Scala was the first example of a lab-leak in software. A language designed for dangerous experiments in type theory escaped into the general developer population.</p></blockquote><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><blockquote><p>I’ve been seeing more and more open source maintainers throwing up their hands over AI generated pull requests. Going so far as to stop accepting PRs from external contributors.</p><p>But yo, what are we doing?! Closing the door on contributors isn’t the answer. Open source maintainers don’t want to hear this, but this is the way people code now, and you need to do your part to prepare your repo for AI coding assistants.</p></blockquote><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><blockquote><p>Last Tuesday my kid came back from school, sat down and asked: “How does ChatGPT actually know what word comes next?” And I thought - great question. Terrible timing, because dinner was almost ready, but great question.</p><p>So I tried to explain it. And failed. Not because it is impossibly hard, but because the usual explanations are either “it is just matrix multiplication” (true but useless) or “it uses attention mechanisms” (cool name, zero information). Neither of those helps a 12-year-old. Or, honestly, most adults. Also, even getting to start my explanation was taking longer than a tiktok, so my kid lost attention span before I could even say “matrix multiplication”. I needed something more visual. More interactive. More fun.</p><p>So here is the version I wish I had at dinner. With drawings. And things you can click on. Because when everything seems abstract, playing with the actual numbers can bring some light.</p></blockquote><p>A helpful guide for any 12-year-old, or a 62-year-old that fears they’re regressing.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p>","contentLength":5770,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Context Engineering for Coding Agents","url":"https://martinfowler.com/articles/exploring-gen-ai/context-engineering-coding-agents.html","date":1770305760,"author":"Martin Fowler","guid":245,"unread":true,"content":"<p>The number of options we have to configure and enrich a coding agent’s\n      context has exploded over the past few months. Claude Code is leading the\n      charge with innovations in this space, but other coding assistants are\n      quickly following suit. Powerful context engineering is becoming a huge\n      part of the developer experience of these tools.  explains the current state of\n      context configuration features, using Claude Code as an example.</p>","contentLength":464,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fragments: February 4","url":"https://martinfowler.com/fragments/2026-02-04.html","date":1770227760,"author":"Martin Fowler","guid":244,"unread":true,"content":"<p>I’ve spent a couple of days at a Thoughtworks-organized event in Deer Valley Utah. It was my favorite kind of event, a really great set of attendees in an <a href=\"https://martinfowler.com/bliki/OpenSpace.html\">Open Space</a> format. These kinds of events are full of ideas, which I do want to share, but I can’t truthfully form them into a coherent narrative for an article about the event. However this fragment format suits them perfectly, so I’ll post a bunch of fragmentary thoughts from the event, both in this post, and in  posts in the next few days.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>We talked about the worry that using AI can cause humans to have less understanding of the systems they are creating. In this discussion one person pointed out that one of the values of <a href=\"https://martinfowler.com/bliki/PairProgramming.html\">Pair Programming</a> is that you have to regularly explain things to your pair. This is an important part of learning - <em>for the person doing the explaining</em>. After all one of the best ways to learn something is to try to teach it.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>One attendee is an SRE for a Very (Very) Large Code Base. He was less worried about people not understanding the code an LLM writes because he already can’t understand the VVLCB he’s responsible for. What he values is that the LLM helps him understand the what the code is doing, and he regularly uses it to navigate to the crucial parts of the code.</p><p>There’s a general point here:</p><p><em>Fully trusting the answer an LLM gives you is foolishness, but it’s wise to use an LLM to help navigate the way to the answer.</em></p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>Elsewhere on the internet, Drew Breunig wonders if software <a href=\"https://www.dbreunig.com/2026/01/08/a-software-library-with-no-code.html\">libraries of the future might be only specs and no code</a>. To explore this idea he built a simple library to convert timestamps into phrases like “3 hours ago”. He used the spec to build implementations in seven languages. The spec is a markdown document of 500 lines and a set of tests in 500 lines of YAML.</p><blockquote><p>“What does software engineering look like when coding is free?”</p><p>I’ve chewed on this question a bit, but this “software library without code” is a tangible thought experiment that helped firm up a few questions and thoughts.</p></blockquote><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p><a href=\"https://www.schneier.com/blog/archives/2026/01/could-chatgpt-convince-you-to-buy-something.html\">Bruce Schneier</a> on the role advertising may play while chatting with LLMs</p><blockquote><p>Imagine you’re conversing with your AI agent about an upcoming vacation. Did it recommend a particular airline or hotel chain because they really are best for you, or does the company get a kickback for every mention?</p></blockquote><p>Recently I heard an ex-Googler explain that advertising was a gilded cage for Google, and they tried very hard to find another business model. The trouble is that it’s very lucrative but also ties you to the advertisers, who are likely to pull out whenever there is an economic downturn. Furthermore they also gain power to influence content - many controversies over “censorship” start with demands from advertisers.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>The news from Minnesota continues to be depressing. The brutality from the masked paramilitaries is getting worse, and their political masters are not just accepting this, but seem eager to let things escalate. Those people with the power to prevent this escalation are either encouraging it, or doing nothing.</p><p>One hopeful sign from all this is the actions of the people of Minnesota. They have resisted peacefully so far, their principal weapons being blowing whistles and filming videos. They demonstrate the neighborliness and support of freedom and law that made America great. I can only hope their spirit inspires others to turn away from the path that we’re currently on. I enjoyed this portrayal of them from <a href=\"https://www.theatlantic.com/ideas/2026/01/the-neighbors-defending-minnesota-from-ice/685769/?gift=zGsHlQiVhVhk3cFVqv--g-tjT7KILRRhUyucHYy86rw&amp;utm_source=copy-link&amp;utm_medium=social&amp;utm_campaign=share\">Adam Serwer</a> (gift link)</p><blockquote><p>In Minnesota, all of the ideological cornerstones of MAGA have been proved false at once. Minnesotans, not the armed thugs of ICE and the Border Patrol, are brave. Minnesotans have shown that their community is socially cohesive—because of its diversity and not in spite of it. Minnesotans have found and loved one another in a world atomized by social media, where empty men have tried to fill their lonely soul with lies about their own inherent superiority. Minnesotans have preserved everything worthwhile about “Western civilization,” while armed brutes try to tear it down by force.</p></blockquote>","contentLength":4804,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bliki: Excessive Bold","url":"https://martinfowler.com/bliki/ExcessiveBold.html","date":1769610000,"author":"Martin Fowler","guid":243,"unread":true,"content":"<p>I'm increasingly seeing a lot of technical and business writing make heavy\n  use of bold font weights, in an attempt to emphasize what the writers think is\n  important. LLMs seem to have picked up and spread this practice widely. But\n  most of this is self-defeating, the more a writer uses typographical emphasis,\n  the less power it has, quickly reaching the point where it loses all its\n  benefits.</p><p>There are various typographical tools that are used to emphasize words and\n  phrases, such as: bold, italic, capitals, and underlines. I find that bold is the one\n  that's getting most of the over-use. Using a lot of capitals is rightly\n  reviled as shouting, and when we see it used widely, it raises our doubts on\n  the quality of the underlying thinking.\n  Underlines have become the signal for hyperlinks, so I rarely see this for\n  emphasis any more. Both capitals and underlines have also been seen as rather\n  cheap forms of highlight, since we could do them with typewriters and\n  handwriting, while bold and italics were only possible after the rise of\n  word-processors. (Although I realize most of my readers are too young to\n  remember when word-processors were novel.)</p><p>Italics are the subtler form of emphasis. When I use them in a paragraph,\n  they don't leap out to the eye. This allows me to use them in long flows of text when\n  I want to set it apart, and when I use it to emphasize a phrase it only makes\n  its presence felt when I'm fully reading the text. For this reason, I prefer\n  to use italics for emphasis, but I only use it rarely, suggesting it's\n   important to put stress on\n  the word should I be speaking the paragraph (and I always try to write in the\n  <a href=\"https://martinfowler.com/bliki/SayYourWriting.html\">way that I speak</a>).</p><p>The greatest value of bold is that draws the eye to the bold text even if the\n  reader isn't reading, but glancing over the page. This is an important\n  property, but one that only works if it's used sparingly. Headings are often\n  done in bold, because the it's important to help the reader navigate a longer\n  document by skimming and looking for headings to find the section I want to read.</p><p>I rarely use bold within a prose paragraph, because of my desire to be\n  parsimonious with bold. One use I do like is to highlight unfamiliar words at\n  the point where I explain them. I got this idea from <a href=\"https://www.amazon.com/gp/product/0534981283/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0534981283&amp;linkCode=as2&amp;tag=martinfowlerc-20\">Giarratano and Riley</a>. I noticed that when the\n  unfamiliar term reappeared, I was often unsure what it meant, but glancing\n  back and finding the bold quickly reminded me. The trick here is to place the\n  bold at point of explanation, which is often, but not always, at its first\n  use. \n</p><p>A common idea is to take an important sentence and bold that, so it leaps\n  out while skimming the article. That can be worthwhile, but as ever with this\n  kind of emphasize, its effectiveness is inversely proportional to how often\n  it's used. It's also usually not the best tool for the job. Callouts usually\n  work better. They do a superior job of drawing the eye, and furthermore they don't\n  need to use the same words as in the prose text. This allows me to word the\n  callout better than it could be if it also had to fit in the flow of the\n  prose.</p><p>A marginal case is where I see bold used in first clause of each item in a\n  bulleted list. In some ways this is acting like a heading for the text in the\n  list. But we don't need a heading for every paragraph, and the presence of the\n  bullets does enough to draw the eye to the items. And bullet-lists are over\n  used too - I always try to write such things as a prose paragraph instead, as\n  prose flows much better than bullets and is thus more pleasant to read. It's\n  important to write in such a way to make it an enjoyable experience for the\n  reader - even, indeed especially, when I'm also trying to explain things for them.</p><p>While writing this, I was <b>tempted to illustrate my point</b> by using  in a paragraph,  and hopefully demonstrating\n  <b>why lots of bold loses the power to emphasize</b> and .\n  But I also wanted to <b>explain my position clearly</b>, and I felt that <b>illustrating\n  the problem</b> would thus . So I've  to a\n  . (And, yes, I  with as much bold as this.)</p>","contentLength":4118,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Assessing internal quality while coding with an agent","url":"https://martinfowler.com/articles/exploring-gen-ai/ccmenu-quality.html","date":1769529000,"author":"Martin Fowler","guid":242,"unread":true,"content":"<p> is the maintainer of CCMenu: a Mac\n      application that shows the status of CI/CD builds in the Mac menu bar. He\n      assesses how using a coding agent affects internal code quality by adding\n      a feature using the agent, and seeing what happens to the code.\n      </p>","contentLength":272,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fragments: January 22","url":"https://martinfowler.com/fragments/2026-01-22.html","date":1769092200,"author":"Martin Fowler","guid":241,"unread":true,"content":"<p>My colleagues here at Thoughtworks have announced <a href=\"https://www.thoughtworks.com/ai/works\">AI/works™</a>, a platform for our work using AI-enabled software development. The platform is in its early days, and is currently intended to support Thoughtworks consultants in their client work. I’m looking forward to sharing what we learn from using and further developing the platform in future months.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>Simon Couch <a href=\"https://www.simonpcouch.com/blog/2026-01-20-cc-impact/\">examines the electricity consumption</a> of using AI. He’s a heavy user: “usually programming for a few hours, and driving 2 or 3 Claude Code instances at a time”. He finds his usage of electricity is orders of magnitude more than typical estimates based on the “typical query”.</p><blockquote><p>On a median day, I estimate I consume 1,300 Wh through Claude Code—4,400 “typical queries” worth.</p></blockquote><p>But it’s still not a massive amount of power - similar to that of running a dishwasher.</p><p>A caveat to this is that this is “napkin math” because we don’t have decent data about how these models use resources. I agree with him that we ought to.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>My namesake Chad Fowler (no relation) considers that the movement to agentic coding creates a similar <a href=\"https://aicoding.leaflet.pub/3mbrvhyye4k2e\">shift in rigor and discipline</a> as appeared in Extreme Programming, dynamic languages, and continuous deployment.</p><p>In Extreme Programming’s case, this meant a lot of discipline around testing, continuous integration, and keeping the code-base healthy. My current view is that with AI-enabled development we need to be rigorous about evaluating the software, both for its observable behavior and its internal quality.</p><blockquote><p>The engineers who thrive in this environment will be the ones who relocate discipline rather than abandon it. They’ll treat generation as a capability that demands more precision in specification, not less. They’ll build evaluation systems that are harder to fool than the ones they replaced. They’ll refuse the temptation to mistake velocity for progress.</p></blockquote><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>There’s been much written about the dreadful events in Minnesota, and I’ve not felt I’ve had anything useful to add to them. But I do want to pass on an excellent post from <a href=\"https://www.noahpinion.blog/p/why-are-federal-agents-gunning-down\">Noah Smith</a> that captures many of my thoughts. He points out that there is a “consistent record of brutality, aggression, dubious legality, and unprofessionalism” from ICE (and CBP) who seem to be turning into MAGA’s <a href=\"https://en.wikipedia.org/wiki/Sturmabteilung\">SD</a>.</p><blockquote><p>Is this America now? A country where unaccountable and poorly trained government agents go door to door, arresting and beating people on pure suspicion, and shooting people who don’t obey their every order or who try to get away? “When a federal officer gives you instructions, you abide by them and then you get to keep your life” is a perfect description of an authoritarian police state. None of this is Constitutional, every bit of it is deeply antithetical to the American values we grew up taking for granted.</p></blockquote><p>My worries about these kinds of developments were what animated me to urge against voting for Trump in the <a href=\"https://martinfowler.com/articles/vote-against-trump.html\">2016 election</a>. Mostly those worries didn’t come to fruition because enough constitutional Republicans were in a position to stop them from happening, so even when Trump attempted a coup in 2020, he wasn’t able to get very far. But now those constitutional Republicans are absent or quiescent. I fear that what we’ve seen in Minneapolis will be a harbinger of worse to come.</p><blockquote><p>But then, after the murderous agent fired three shots — just 30 or 40 feet in front of Callenson — Callenson had the courage and conviction to stay with the scene and keep filming. Not to run away, but instead to follow the scene. To keep filming. To continue documenting with as best clarity as she could, what was unfolding.</p></blockquote><p>The recent activity in  Venezuala reminds me that I’ve long felt that Trump is a Hugo Chávez figure - a charismatic populist who’s keen on wrecking institutions and norms. Trump is old, so won’t be with us for that much longer - but the question is: “who is Trump’s Maduro?”</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>With all the drama at home, we shouldn’t ignore the terrible things that happened in Iran. The people there again suffered again the consequences of an entrenched authoritarian police state.</p>","contentLength":4689,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Conversation: LLMs and the what/how loop","url":"https://martinfowler.com/articles/convo-what-how.html","date":1769006400,"author":"Martin Fowler","guid":240,"unread":true,"content":"<p>A conversation between , , and  on how LLMs help us\n      shape the abstractions in our software. We view our challenge as building\n      systems that survive change, requiring us to manage our cognitive load. We\n      can do this by mapping the “what” of we want our software to do into the\n      “how” of programming languages. This “what” and “how” are built up in a\n      feedback loop. TDD helps us operationalize that loop, and LLMs allow us to\n      explore that loop in an informal and more fluid manner.</p>","contentLength":528,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}