{"id":"6gUbcJtcgqw1wQBapm8qwcP58MMnPvoDmUVDva7XtKUuLQTDpuyDxDo1yehnZDohDQ6a5p","title":"Slashdot: Developers","displayTitle":"Dev - Slashdot - Dev","url":"http://rss.slashdot.org/Slashdot/slashdotDevelopers","feedLink":"https://developers.slashdot.org/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":15,"items":[{"title":"Ubuntu Will Use Rust For Dozens of Core Linux Utilities","url":"https://news.slashdot.org/story/25/11/01/079206/ubuntu-will-use-rust-for-dozens-of-core-linux-utilities?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1762018440,"author":"EditorDavid","guid":245,"unread":true,"content":" Ubuntu \"is adopting the memory-safe Rust language,\" reports ZDNet, citing remarks at this year's Ubuntu Summit from Jon Seager, Canonical's VP of engineering for Ubuntu:\n\n. Seager said the engineering team is focused on replacing key system components with Rust-based alternatives to enhance safety and resilience, starting with Ubuntu 25.10. He stressed that resilience and memory safety, not just performance, are the principal drivers: \"It's the enhanced resilience and safety that is more easily achieved with Rust ports that are most attractive to me\". This move is echoed in Ubuntu's adoption of sudo-rs, the Rust implementation of sudo, with fallback and opt-out mechanisms for users who want to use the old-school sudo command. \n\n\nIn addition to sudo-rs, Ubuntu 26.04 will use the Rust-based uutils/coreutils for Linux's default core utilities. This setup includes ls, cp, mv, and dozens of other basic Unix command-line tools. This Rust reimplementation aims for functional parity with GNU coreutils, with improved safety and maintainability. \n\nOn the desktop front, Ubuntu 26.04 will also bring seamless TPM-backed full disk encryption. If this approach reminds you of Windows BitLocker or MacOS FileVault, it should. That's the idea. \n\nIn other news, Canonical CEO Mark Shuttleworth said \"I'm a believer in the potential of Linux to deliver a desktop that could have wider and universal appeal.\" (Although he also thinks \"the open-source community needs to understand that building desktops for people who aren't engineers is different. We need to understand that the 'simple and just works' is also really important.\") \n\n\nShuttleworth answered questions from Slashdot's readers in 2005 and 2012.","contentLength":1708,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TypeScript Overtakes Python and JavaScript To Claim Top Spot on GitHub","url":"https://developers.slashdot.org/story/25/10/30/1753252/typescript-overtakes-python-and-javascript-to-claim-top-spot-on-github?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1761847200,"author":"msmash","guid":288,"unread":true,"content":"TypeScript overtook Python and JavaScript in August 2025 to become the most used language on GitHub. The shift marked the most significant language change in more than a decade. The language grew by over 1 million contributors in 2025, a 66% increase year over year, and finished August with 2,636,006 monthly contributors. \n\nNearly every major frontend framework now scaffolds projects in TypeScript by default. Next.js 15, Astro 3, SvelteKit 2, Qwik, SolidStart, Angular 18, and Remix all generate TypeScript codebases when developers create new projects. Type systems reduce ambiguity and catch errors from large language models before production. A 2025 academic study found 94% of LLM-generated compilation errors were type-check failures. Tooling like Vite, ts-node, Bun, and I.D.E. autoconfig hide boilerplate setup. Among new repositories created in the past twelve months, TypeScript accounted for 5,394,256 projects. That represented a 78% increase from the prior year.","contentLength":979,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Foundation Rejects Government Grant Over DEI Restrictions","url":"https://developers.slashdot.org/story/25/10/28/211237/python-foundation-rejects-government-grant-over-dei-restrictions?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1761691800,"author":"BeauHD","guid":287,"unread":true,"content":"The Python Software Foundation rejected a $1.5 million U.S. government grant because it required them to renounce all diversity, equity, and inclusion initiatives. \"The non-profit would've used the funding to help prevent supply chain attacks; create a new automated, proactive review process for new PyPI packages; and make the project's work easily transferable to other open-source package managers,\" reports The Register. From the report: The programming non-profit's deputy executive director Loren Crary said in a blog post today that the National Science Founation (NSF) had offered $1.5 million to address structural vulnerabilities in Python and the Python Package Index (PyPI), but the Foundation quickly became dispirited with the terms (PDF) of the grant it would have to follow. \"These terms included affirming the statement that we 'do not, and will not during the term of this financial assistance award, operate any programs that advance or promote DEI [diversity, equity, and inclusion], or discriminatory equity ideology in violation of Federal anti-discrimination laws,'\" Crary noted. \"This restriction would apply not only to the security work directly funded by the grant, but to any and all activity of the PSF as a whole.\"\n \nTo make matters worse, the terms included a provision that if the PSF was found to have voilated that anti-DEI diktat, the NSF reserved the right to claw back any previously disbursed funds, Crary explained. \"This would create a situation where money we'd already spent could be taken back, which would be an enormous, open-ended financial risk,\" the PSF director added. The PSF's mission statement enshrines a commitment to supporting and growing \"a diverse and international community of Python programmers,\" and the Foundation ultimately decided it wasn't willing to compromise on that position, even for what would have been a solid financial boost for the organization. \"The PSF is a relatively small organization, operating with an annual budget of around $5 million per year, with a staff of just 14,\" Crary added, noting that the $1.5 million would have been the largest grant the Foundation had ever received - but it wasn't worth it if the conditions were undermining the PSF's mission. The PSF board voted unanimously to withdraw its grant application.","contentLength":2311,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Does Generative AI Threaten the Open Source Ecosystem?","url":"https://developers.slashdot.org/story/25/10/26/208204/does-generative-ai-threaten-the-open-source-ecosystem?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1761510840,"author":"EditorDavid","guid":286,"unread":true,"content":" \"Snippets of proprietary or copyleft reciprocal code can enter AI-generated outputs, contaminating codebases with material that developers can't realistically audit or license properly.\" \n\n\nThat's the warning from Sean O'Brien, who founded the Yale Privacy Lab at Yale Law School. ZDNet reports:\n\n\n\nOpen software has always counted on its code being regularly replenished. As part of the process of using it, users modify it to improve it. They add features and help to guarantee usability across generations of technology. At the same time, users improve security and patch holes that might put everyone at risk. But O'Brien says, \"When generative AI systems ingest thousands of FOSS projects and regurgitate fragments without any provenance, the cycle of reciprocity collapses. The generated snippet appears originless, stripped of its license, author, and context.\" This means the developer downstream can't meaningfully comply with reciprocal licensing terms because the output cuts the human link between coder and code. Even if an engineer suspects that a block of AI-generated code originated under an open source license, there's no feasible way to identify the source project. The training data has been abstracted into billions of statistical weights, the legal equivalent of a black hole. \n\nThe result is what O'Brien calls \"license amnesia.\" He says, \"Code floats free of its social contract and developers can't give back because they don't know where to send their contributions....\" \n\n\"Once AI training sets subsume the collective work of decades of open collaboration, the global commons idea, substantiated into repos and code all over the world, risks becoming a nonrenewable resource, mined and never replenished,\" says O'Brien. \"The damage isn't limited to legal uncertainty. If FOSS projects can't rely upon the energy and labor of contributors to help them fix and improve their code, let alone patch security issues, fundamentally important components of the software the world relies upon are at risk.\" \n\nO'Brien says, \"The commons was never just about free code. It was about freedom to build together.\" That freedom, and the critical infrastructure that underlies almost all of modern society, is at risk because attribution, ownership, and reciprocity are blurred when AIs siphon up everything on the Internet and launder it (the analogy of money laundering is apt), so that all that code's provenance is obscured.\n\n\n","contentLength":2445,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"28 Years After 'Clippy', Microsoft Upgrades Copilot With Cartoon Assistant 'Micu'","url":"https://developers.slashdot.org/story/25/10/25/0949250/28-years-after-clippy-microsoft-upgrades-copilot-with-cartoon-assistant-micu?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1761410040,"author":"EditorDavid","guid":285,"unread":true,"content":"\"Clippy, the animated paper clip that annoyed Microsoft Office users nearly three decades ago, might have just been ahead of its time,\" writes the Associated Press:\n\n\nMicrosoft introduced a new artificial intelligence character called Mico (pronounced MEE'koh) on Thursday, a floating cartoon face shaped like a blob or flame that will embody the software giant's Copilot virtual assistant and marks the latest attempt by tech companies to imbue their AI chatbots with more of a personality... \"When you talk about something sad, you can see Mico's face change. You can see it dance around and move as it gets excited with you,\" said Jacob Andreou, corporate vice president of product and growth for Microsoft AI, in an interview with The Associated Press. \"It's in this effort of really landing this AI companion that you can really feel.\" \n\nIn the U.S. only so far, Copilot users on laptops and phone apps can speak to Mico, which changes colors, spins around and wears glasses when in \"study\" mode. It's also easy to shut off, which is a big difference from Microsoft's Clippit, better known as Clippy and infamous for its persistence in offering advice on word processing tools when it first appeared on desktop screens in 1997. \"It was not well-attuned to user needs at the time,\" said Bryan Reimer, a research scientist at the Massachusetts Institute of Technology. \"Microsoft pushed it, we resisted it and they got rid of it. I think we're much more ready for things like that today...\" \n\n\nMicrosoft's product releases Thursday include a new option to invite Copilot into a group chat, an idea that resembles how AI has been integrated into social media platforms like Snapchat, where Andreou used to work, or Meta's WhatsApp and Instagram. But Andreou said those interactions have often involved bringing in AI as a joke to \"troll your friends,\" in contrast to Microsoft's designs for an \"intensely collaborative\" AI-assisted workplace.\n","contentLength":1945,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fedora Approves AI-Assisted Contributions","url":"https://developers.slashdot.org/story/25/10/23/2138252/fedora-approves-ai-assisted-contributions?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1761310800,"author":"BeauHD","guid":284,"unread":true,"content":"The Fedora Council has approved a new policy allowing AI-assisted code contributions, provided contributors fully disclose and take responsibility for any AI-generated work. Phoronix reports: AI-assisted code contributions can be used but the contributor must take responsibility for that contribution, it must be transparent in disclosing the use of AI such as with the \"Assisted-by\" tag, and that AI can help in assisting human reviewers/evaluation but must not be the sole or final arbiter. This AI policy also doesn't cover large-scale initiatives which will need to be handled individually with the Fedora Council. [...] The Fedora Council does expect that this policy will need to be updated over time for staying current with AI technologies.","contentLength":749,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"JetBrains Survey Declares PHP Declining, Then Says It Isn't","url":"https://developers.slashdot.org/story/25/10/21/2132259/jetbrains-survey-declares-php-declining-then-says-it-isnt?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1761085500,"author":"msmash","guid":283,"unread":true,"content":"JetBrains released its annual State of the Developer Ecosystem survey in late October, drawing more than twenty-four thousand responses from programmers worldwide. The survey declared that PHP and Ruby are in \"long term decline\" based on usage trends tracked over five years. Shortly after publication, JetBrains posted a separate statement asserting that \"PHP remains a stable, professional, and evolving ecosystem.\" The company offered no explanation for the apparent contradiction, The Register reports. \n\nThe survey's methodology involves weighting responses to account for bias toward JetBrains users and regional distribution factors. The company acknowledges some bias likely remains since its own customers are more inclined to respond. The survey also found that 85% of developers now use AI coding tools.","contentLength":814,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Plan for Improving JavaScript's Trustworthiness on the Web","url":"https://developers.slashdot.org/story/25/10/20/005250/a-plan-for-improving-javascripts-trustworthiness-on-the-web?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1760919600,"author":"EditorDavid","guid":282,"unread":true,"content":"On Cloudflare's blog, a senior research engineer shares a plan for \"improving the trustworthiness of JavaScript on the web.\" \n\n\n\"It is as true today as it was in 2011 that Javascript cryptography is Considered Harmful.\"\n\n\n\nThe main problem is code distribution. Consider an end-to-end-encrypted messaging web application. The application generates cryptographic keys in the client's browser that lets users view and send end-to-end encrypted messages to each other. If the application is compromised, what would stop the malicious actor from simply modifying their Javascript to exfiltrate messages? It is interesting to note that smartphone apps don't have this issue. This is because app stores do a lot of heavy lifting to provide security for the app ecosystem. Specifically, they provide integrity, ensuring that apps being delivered are not tampered with, consistency, ensuring all users get the same app, and transparency, ensuring that the record of versions of an app is truthful and publicly visible. \n\n\n\n\nIt would be nice if we could get these properties for our end-to-end encrypted web application, and the web as a whole, without requiring a single central authority like an app store.\nFurther, such a system would benefit all in-browser uses of cryptography, not just end-to-end-encrypted apps. For example, many web-based confidential LLMs, cryptocurrency wallets, and voting systems use in-browser Javascript cryptography for the last step of their verification chains. In this post, we will provide an early look at such a system, called Web Application Integrity, Consistency, and Transparency (WAICT) that we have helped author. WAICT is a W3C-backed effort among browser vendors, cloud providers, and encrypted communication developers to bring stronger security guarantees to the entire web... We hope to build even wider consensus on the solution design in the near future.... \n\n\nWe would like to have a way of enforcing integrity on an entire site, i.e., every asset under a domain. For this, WAICT defines an integrity manifest, a configuration file that websites can provide to clients. One important item in the manifest is the asset hashes dictionary, mapping a hash belonging to an asset that the browser might load from that domain, to the path of that asset. \n\n\nThe blog post points out that the WEBCAT protocol (created by the Freedom of Press Foundation) \"allows site owners to announce the identities of the developers that have signed the site's integrity manifest, i.e., have signed all the code and other assets that the site is serving to the user... We've made WAICT extensible enough to fit WEBCAT inside and benefit from the transparency components.\" The proposal also envisions a service storing metadata for transparency-enabled sites on the web (along with \"witnesses\" who verify the prefix tree holding the hashes for domain manifests). \n\n\n\"We are still very early in the standardization process,\" with hopes to soon \"begin standardizing the integrity manifest format. And then after that we can start standardizing all the other features. We intend to work on this specification hand-in-hand with browsers and the IETF, and we hope to have some exciting betas soon. In the meantime, you can follow along with our transparency specification draft,/A&gt;, check out the open problems, and share your ideas.\"","contentLength":3348,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI Cofounder Builds New Open Source LLM 'Nanochat' - and Doesn't Use Vibe Coding","url":"https://developers.slashdot.org/story/25/10/19/0022237/openai-cofounder-builds-new-open-source-llm-nanochat---and-doesnt-use-vibe-coding?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1760844840,"author":"EditorDavid","guid":281,"unread":true,"content":"An anonymous reader shared this report from Gizmodo:\n\n\nIt's been over a year since OpenAI cofounder Andrej Karpathy exited the company. In the time since he's been gone, he coined and popularized the term \"vibe coding\" to describe the practice of farming out coding projects to AI tools. But earlier this week, when he released his own open source model called nanochat, he admitted that he wrote the whole thing by hand, vibes be damned. \nNanochat, according to Karpathy, is a \"minimal, from scratch, full-stack training/inference pipeline\" that is designed to let anyone build a large language model with a ChatGPT-style chatbot interface in a matter of hours and for as little as $100. Karpathy said the project contains about 8,000 lines of \"quite clean code,\" which he wrote by hand — not necessarily by choice, but because he found AI tools couldn't do what he needed. \n\"It's basically entirely hand-written (with tab autocomplete),\" he wrote. \"I tried to use claude/codex agents a few times but they just didn't work well enough at all and net unhelpful.\"","contentLength":1064,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GitHub Will Prioritize Migrating To Azure Over Feature Development","url":"https://developers.slashdot.org/story/25/10/14/0833202/github-will-prioritize-migrating-to-azure-over-feature-development?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1760455260,"author":"msmash","guid":280,"unread":true,"content":"An anonymous reader shares a report: After acquiring GitHub in 2018, Microsoft mostly let the developer platform run autonomously. But in recent months, that's changed. With GitHub CEO Thomas Dohmke leaving the company this August, and GitHub being folded more deeply into Microsoft's organizational structure, GitHub lost that independence. Now, according to internal GitHub documents The New Stack has seen, the next step of this deeper integration into the Microsoft structure is moving all of GitHub's infrastructure to Azure, even at the cost of delaying work on new features. \n\n[...] While GitHub had previously started work on migrating parts of its service to Azure, our understanding is that these migrations have been halting and sometimes failed. There are some projects, like its data residency initiative (internally referred to as Project Proxima) that will allow GitHub's enterprise users to store all of their code in Europe, that already solely use Azure's local cloud regions.","contentLength":994,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Great Software Quality Collapse","url":"https://developers.slashdot.org/story/25/10/14/0826220/the-great-software-quality-collapse?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1760452860,"author":"msmash","guid":279,"unread":true,"content":"Engineer Denis Stetskov, writing in a blog: The Apple Calculator leaked 32GB of RAM. Not used. Not allocated. Leaked. A basic calculator app is hemorrhaging more memory than most computers had a decade ago. Twenty years ago, this would have triggered emergency patches and post-mortems. Today, it's just another bug report in the queue. We've normalized software catastrophes to the point where a Calculator leaking 32GB of RAM barely makes the news. This isn't about AI. The quality crisis started years before ChatGPT existed. AI just weaponized existing incompetence. \n\n[...] Here's what engineering leaders don't want to acknowledge: software has physical constraints, and we're hitting all of them simultaneously. Modern software is built on towers of abstractions, each one making development \"easier\" while adding overhead: Today's real chain: React &gt; Electron &gt; Chromium &gt; Docker &gt; Kubernetes &gt; VM &gt; managed DB &gt; API gateways. Each layer adds \"only 20-30%.\" Compound a handful and you're at 2-6x overhead for the same behavior. That's how a Calculator ends up leaking 32GB. Not because someone wanted it to -- but because nobody noticed the cumulative cost until users started complaining. \n\n[...] We're living through the greatest software quality crisis in computing history. A Calculator leaks 32GB of RAM. AI assistants delete production databases. Companies spend $364 billion to avoid fixing fundamental problems. This isn't sustainable. Physics doesn't negotiate. Energy is finite. Hardware has limits. The companies that survive won't be those who can outspend the crisis. There'll be those who remember how to engineer.","contentLength":1636,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Slop? Not This Time. AI Tools Found 50 Real Bugs In cURL","url":"https://developers.slashdot.org/story/25/10/12/0619247/ai-slop-not-this-time-ai-tools-found-50-real-bugs-in-curl?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1760283240,"author":"EditorDavid","guid":278,"unread":true,"content":"The Register reports:\nOver the past two years, the open source curl project has been flooded with bogus bug reports generated by AI models. The deluge prompted project maintainer Daniel Stenberg to publish several blog posts about the issue in an effort to convince bug bounty hunters to show some restraint and not waste contributors' time with invalid issues. Shoddy AI-generated bug reports have been a problem not just for curl, but also for the Python community, Open Collective, and the Mesa Project. \nIt turns out the problem is people rather than technology. Last month, the curl project received dozens of potential issues from Joshua Rogers, a security researcher based in Poland. Rogers identified assorted bugs and vulnerabilities with the help of various AI scanning tools. And his reports were not only valid but appreciated. Stenberg in a Mastodon post last month remarked, \"Actually truly awesome findings.\" In his mailing list update last week, Stenberg said, \"most of them were tiny mistakes and nits in ordinary static code analyzer style, but they were still mistakes that we are better off having addressed. Several of the found issues were quite impressive findings....\" \n\nStenberg told The Register that about 50 bugfixes based on Rogers' reports have been merged. \"In my view, this list of issues achieved with the help of AI tooling shows that AI can be used for good,\" he said in an email. \"Powerful tools in the hand of a clever human is certainly a good combination. It always was...!\" Rogers wrote up a summary of the AI vulnerability scanning tools he tested. He concluded that these tools — Almanax, Corgea, ZeroPath, Gecko, and Amplify — are capable of finding real vulnerabilities in complex code. \n\nThe Register's conclusion? AI tools \"when applied with human intelligence by someone with meaningful domain experience, can be quite helpful.\" \n\njantangring (Slashdot reader #79,804) has published an article on Stenberg's new position, including recently published comments from Stenberg that \"It really looks like these new tools are finding problems that none of the old, established tools detect.\"","contentLength":2137,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What If Vibe Coding Creates More Programming Jobs?","url":"https://developers.slashdot.org/story/25/10/06/031253/what-if-vibe-coding-creates-more-programming-jobs?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1759750440,"author":"EditorDavid","guid":277,"unread":true,"content":"Vibe coding tools \"are transforming the job experience for many tech workers,\" writes the Los Angeles Times. But Gartner analyst Philip Walsh said the research firm's position is that AI won't replace software engineers and will actually create a need for more.\n\n\"There's so much software that isn't created today because we can't prioritize it,\" Walsh said. \"So it's going to drive demand for more software creation, and that's going to drive demand for highly skilled software engineers who can do it...\" The idea that non-technical people in an organization can \"vibe-code\" business-ready software is a misunderstanding [Walsh said]... \"That's simply not happening. The quality is not there. The robustness is not there. The scalability and security of the code is not there,\" Walsh said. \"These tools reward highly skilled technical professionals who already know what 'good' looks like.\" \n\"Economists, however, are also beginning to worry that AI is taking jobs that would otherwise have gone to young or entry-level workers,\" the article points out. \"In a report last month, researchers at Stanford University found \"substantial declines in employment for early-career workers'' — ages 22-25 — in fields most exposed to AI. Stanford researchers also found that AI tools by 2024 were able to solve nearly 72% of coding problems, up from just over 4% a year earlier.\" \n\nAnd yet Cat Wu, project manager of Anthropic's Claude Code, doesn't even use the term vibe coding. \"We definitely want to make it very clear that the responsibility, at the end of the day, is in the hands of the engineers.\"\nWu said she's told her younger sister, who's still in college, that software engineering is still a great career and worth studying. \"When I talk with her about this, I tell her AI will make you a lot faster, but it's still really important to understand the building blocks because the AI doesn't always make the right decisions,\" Wu said. \"A lot of times the human intuition is really important.\"","contentLength":2000,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Are Software Registries Inherently Insecure?","url":"https://developers.slashdot.org/story/25/10/05/2318202/are-software-registries-inherently-insecure?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1759713120,"author":"EditorDavid","guid":276,"unread":true,"content":"\"Recent attacks show that hackers keep using the same tricks to sneak bad code into popular software registries,\" writes long-time Slashdot reader selinux geek, suggesting that \"the real problem is how these registries are built, making these attacks likely to keep happening.\"\n\nAfter all, npm wasn't the only software library hit by a supply chain attack, argues the Linux Security blog. \"PyPI and Docker Hub both faced their own compromises in 2025, and the overlaps are impossible to ignore.\"\n Phishing has always been the low-hanging fruit. In 2025, it wasn't just effective once — it was the entry point for multiple registry breaches, all occurring close together in different ecosystems... The real problem isn't that phishing happened. It's that there weren't enough safeguards to blunt the impact. One stolen password shouldn't be all it takes to poison an entire ecosystem. Yet in 2025, that's exactly how it played out... \n\nEven if every maintainer spotted every lure, registries left gaps that attackers could walk through without much effort. The problem wasn't social engineering this time. It was how little verification stood between an attacker and the \"publish\" button. Weak authentication and missing provenance were the quiet enablers in 2025... Sometimes the registry itself offers the path in. When the failure is at the registry level, admins don't get an alert, a log entry, or any hint that something went wrong. That's what makes it so dangerous. The compromise appears to be a normal update until it reaches the downstream system... It shifts the risk from human error to systemic design. \n\nAnd once that weakly authenticated code gets in, it doesn't always go away quickly, which leads straight into the persistence problem... Once an artifact is published, it spreads into mirrors, caches, and derivative builds. Removing the original upload doesn't erase all the copies... From our perspective at LinuxSecurity, this isn't about slow cleanup; it's about architecture. Registries have no universally reliable kill switch once trust is broken. Even after removal, poisoned base images replicate across mirrors, caches, and derivative builds, meaning developers may keep pulling them in long after the registry itself is \"clean.\" \n\nThe article condlues that \"To us at LinuxSecurity, the real vulnerability isn't phishing emails or stolen tokens — it's the way registries are built. They distribute code without embedding security guarantees. That design ensures supply chain attacks won't be rare anomalies, but recurring events.\"BR&gt; \n\nSo in a world where \"the only safe assumption is that the code you consume may already be compromised,\" they argue, developers should look to controls they can enforce themselves:\n\n Verify artifacts with signatures or provenance tools. Pin dependencies to specific, trusted versions. Generate and track SBOMs so you know exactly what's in your stack. Scan continuously, not just at the point of install.","contentLength":2970,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google's Jules Enters Developers' Toolchains As AI Coding Agent Competition Heats Up","url":"https://developers.slashdot.org/story/25/10/03/2140223/googles-jules-enters-developers-toolchains-as-ai-coding-agent-competition-heats-up?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1759536120,"author":"BeauHD","guid":275,"unread":true,"content":"An anonymous reader quotes a report from TechCrunch: Google is bringing its AI coding agent Jules deeper into developer workflows with a new command-line interface and public API, allowing it to plug into terminals, CI/CD systems, and tools like Slack -- as competition intensifies among tech companies to own the future of software development and make coding more of an AI-assisted task.\n \nUntil now, Jules -- Google's asynchronous coding agent -- was only accessible via its website and GitHub. On Thursday, the company introduced Jules Tools, a command-line interface that brings Jules directly into the developer's terminal. The CLI lets developers interact with the agent using commands, streamlining workflows by eliminating the need to switch between the web interface and GitHub. It allows them to stay within their environment while delegating coding tasks and validating results. \"We want to reduce context switching for developers as much as possible,\" Kathy Korevec, director of product at Google Labs, told TechCrunch.\n \nJules differs from Gemini CLI in that it focuses on \"scoped,\" independent tasks rather than requiring iterative collaboration. Once a user approves a plan, Jules executes it autonomously, while the CLI needs more step-by-step guidance. Jules also has a public API for workflow and IDE integration, plus features like memory, a stacked diff viewer, PR comment handling, and image uploads -- capabilities not present in the CLI. Gemini CLI is limited to terminals and CI/CD pipelines and is better suited for exploratory, highly interactive use.","contentLength":1578,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev","slashdot"]}