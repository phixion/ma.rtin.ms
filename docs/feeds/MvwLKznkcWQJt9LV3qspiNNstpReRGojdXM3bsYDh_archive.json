{"id":"MvwLKznkcWQJt9LV3qspiNNstpReRGojdXM3bsYDh","title":"Kubernetes Blog","displayTitle":"Dev - Kubernetes Blog","url":"https://kubernetes.io/feed.xml","feedLink":"https://kubernetes.io/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":3,"items":[{"title":"Spotlight on SIG etcd","url":"https://kubernetes.io/blog/2025/03/04/sig-etcd-spotlight/","date":1741046400,"author":"","guid":459,"unread":true,"content":"<p><strong>Frederico: Hello, thank you for the time! Let‚Äôs start with some introductions, could you tell us a\nbit about yourself, your role and how you got involved in Kubernetes.</strong></p><p> Hello, I am Benjamin. I am a SIG etcd Tech Lead and one of the etcd maintainers. I\nwork for VMware, which is part of the Broadcom group. I got involved in Kubernetes &amp; etcd &amp; CSI\n(<a href=\"https://github.com/container-storage-interface/spec/blob/master/spec.md\">Container Storage Interface</a>)\nbecause of work and also a big passion for open source. I have been working on Kubernetes &amp; etcd\n(and also CSI) since 2020.</p><p> Hey team, I‚Äôm James, a co-chair for SIG etcd and etcd maintainer. I work at Red Hat as a\nSpecialist Architect helping people adopt cloud native technology. I got involved with the\nKubernetes ecosystem in 2019. Around the end of 2022 I noticed how the etcd community and project\nneeded help so started contributing as often as I could. There is a saying in our community that\n\"you come for the technology, and stay for the people\": for me this is absolutely real, it‚Äôs been a\nwonderful journey so far and I‚Äôm excited to support our community moving forward.</p><p> Hey everyone, I'm Marek, the SIG etcd lead. At Google, I lead the GKE etcd team, ensuring\na stable and reliable experience for all GKE users. My Kubernetes journey began with <a href=\"https://github.com/kubernetes/community/tree/master/sig-instrumentation\">SIG\nInstrumentation</a>, where I\ncreated and led the <a href=\"https://kubernetes.io/blog/2020/09/04/kubernetes-1-19-introducing-structured-logs/\">Kubernetes Structured Logging effort</a>.\nI'm still the main project lead for <a href=\"https://kubernetes-sigs.github.io/metrics-server/\">Kubernetes Metrics Server</a>,\nproviding crucial signals for autoscaling in Kubernetes. I started working on etcd 3 years ago,\nright around the 3.5 release. We faced some challenges, but I'm thrilled to see etcd now the most\nscalable and reliable it's ever been, with the highest contribution numbers in the project's\nhistory. I'm passionate about distributed systems, extreme programming, and testing.</p><p> Hi there, my name is Wenjia, I am the co-chair of SIG etcd and one of the etcd\nmaintainers. I work at Google as an Engineering Manager, working on GKE (Google Kubernetes Engine)\nand GDC (Google Distributed Cloud). I have been working in the area of open source Kubernetes and\netcd since the Kubernetes v1.10 and etcd v3.1 releases. I got involved in Kubernetes because of my\njob, but what keeps me in the space is the charm of the container orchestration technology, and more\nimportantly, the awesome open source community.</p><p><strong>Frederico: Excellent, thank you. I'd like to start with the origin of the SIG itself: SIG etcd is\na very recent SIG, could you quickly go through the history and reasons behind its creation?</strong></p><p>: Absolutely! SIG etcd was formed because etcd is a critical component of Kubernetes,\nserving as its data store. However, etcd was facing challenges like maintainer turnover and\nreliability issues. <a href=\"https://etcd.io/blog/2023/introducing-sig-etcd/\">Creating a dedicated SIG</a>\nallowed us to focus on addressing these problems, improving development and maintenance processes,\nand ensuring etcd evolves in sync with the cloud-native landscape.</p><p><strong>Frederico: And has becoming a SIG worked out as expected? Better yet, are the motivations you just\ndescribed being addressed, and to what extent?</strong></p><p>: It's been a positive change overall. Becoming a SIG has brought more structure and\ntransparency to etcd's development. We've adopted Kubernetes processes like KEPs\n(<a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/README.md\">Kubernetes Enhancement Proposals</a>\nand PRRs (<a href=\"https://github.com/kubernetes/community/blob/master/sig-architecture/production-readiness.md\">Production Readiness Reviews</a>,\nwhich has improved our feature development and release cycle.</p><p><strong>Frederico: On top of those, what would you single out as the major benefit that has resulted from\nbecoming a SIG?</strong></p><p>: The biggest benefits for me was adopting Kubernetes testing infrastructure, tools like\n<a href=\"https://docs.prow.k8s.io/\">Prow</a> and <a href=\"https://testgrid.k8s.io/\">TestGrid</a>. For large projects like\netcd there is just no comparison to the default GitHub tooling. Having known, easy to use, clear\ntools is a major boost to the etcd as it makes it much easier for Kubernetes contributors to also\nhelp etcd.</p><p>: Totally agree, while challenges remain, the SIG structure provides a solid foundation\nfor addressing them and ensuring etcd's continued success as a critical component of the Kubernetes\necosystem.</p><p>The positive impact on the community is another crucial aspect of SIG etcd's success that I‚Äôd like\nto highlight. The Kubernetes SIG structure has created a welcoming environment for etcd\ncontributors, leading to increased participation from the broader Kubernetes community. We have had\ngreater collaboration with other SIGs like <a href=\"https://github.com/kubernetes/community/blob/master/sig-api-machinery/README.md\">SIG API\nMachinery</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-scalability\">SIG Scalability</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-scalability\">SIG Testing</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-cluster-lifecycle\">SIG Cluster Lifecycle</a>, etc.</p><p>This collaboration helps ensure etcd's development aligns with the needs of the wider Kubernetes\necosystem. The formation of the <a href=\"https://github.com/kubernetes/community/blob/master/wg-etcd-operator/README.md\">etcd Operator Working Group</a>\nunder the joint effort between SIG etcd and SIG Cluster Lifecycle exemplifies this successful\ncollaboration, demonstrating a shared commitment to improving etcd's operational aspects within\nKubernetes.</p><p><strong>Frederico: Since you mentioned collaboration, have you seen changes in terms of contributors and\ncommunity involvement in recent months?</strong></p><p>: Yes -- as showing in our\n<a href=\"https://etcd.devstats.cncf.io/d/23/prs-authors-repository-groups?orgId=1&amp;var-period=m&amp;var-repogroup_name=All&amp;from=1422748800000&amp;to=1738454399000\">unique PR author data</a>\nwe recently hit an all time high in March and are trending in a positive direction:</p><p><strong>Frederico: That's quite telling, thank you. In terms of the near future, what are the current\npriorities for SIG etcd?</strong></p><p>: Reliability is always top of mind -‚Äì we need to make sure etcd is rock-solid. We're also\nworking on making etcd easier to use and manage for operators. And we have our sights set on making\netcd a viable standalone solution for infrastructure management, not just for Kubernetes. Oh, and of\ncourse, scaling -‚Äì we need to ensure etcd can handle the growing demands of the cloud-native world.</p><p>: I agree that reliability should always be our top guiding principle. We need to ensure\nnot only correctness but also compatibility. Additionally, we should continuously strive to improve\nthe understandability and maintainability of etcd. Our focus should be on addressing the pain points\nthat the community cares about the most.</p><p><strong>Frederico: Are there any specific SIGs that you work closely with?</strong></p><p>: SIG API Machinery, for sure ‚Äì they own the structure of the data etcd stores, so we're\nconstantly working together. And SIG Cluster Lifecycle ‚Äì etcd is a key part of Kubernetes clusters,\nso we collaborate on the newly created etcd operator Working group.</p><p>: Other than SIG API Machinery and SIG Cluster Lifecycle that Marek mentioned above, SIG\nScalability and SIG Testing is another group that we work closely with.</p><p><strong>Frederico: In a more general sense, how would you list the key challenges for SIG etcd in the\nevolving cloud native landscape?</strong></p><p>: Well, reliability is always a challenge when you're dealing with critical data. The\ncloud-native world is evolving so fast that scaling to meet those demands is a constant effort.</p><p><strong>Frederico: We're almost at the end of our conversation, but for those interested in in etcd, how\ncan they get involved?</strong></p><p>: We'd love to have them! The best way to start is to join our\n<a href=\"https://github.com/kubernetes/community/blob/master/sig-etcd/README.md#meetings\">SIG etcd meetings</a>,\nfollow discussions on the <a href=\"https://groups.google.com/g/etcd-dev\">etcd-dev mailing list</a>, and check\nout our <a href=\"https://github.com/etcd-io/etcd/issues\">GitHub issues</a>. We're always looking for people to\nreview proposals, test code, and contribute to documentation.</p><p>: I love this question üòÄ . There are numerous ways for people interested in contributing\nto SIG etcd to get involved and make a difference. Here are some key areas where you can help:</p><ul><li>: Tackle existing issues in the etcd codebase. Start with issues labeled \"good first\nissue\" or \"help wanted\" to find tasks that are suitable for newcomers.</li><li>: Contribute to the development of new features and enhancements. Check the\netcd roadmap and discussions to see what's being planned and where your skills might fit in.</li><li>: Help ensure the quality of etcd by writing tests, reviewing code\nchanges, and providing feedback.</li><li>: Improve <a href=\"https://etcd.io/docs/\">etcd's documentation</a> by adding new content,\nclarifying existing information, or fixing errors. Clear and comprehensive documentation is\nessential for users and contributors.</li><li>: Answer questions on forums, mailing lists, or <a href=\"https://kubernetes.slack.com/archives/C3HD8ARJ5\">Slack channels</a>.\nHelping others understand and use etcd is a valuable contribution.</li></ul><ul><li>: Start by joining the etcd community on Slack,\nattending SIG meetings, and following the mailing lists. This will\nhelp you get familiar with the project, its processes, and the\npeople involved.</li><li>: If you're new to open source or etcd, consider\nfinding a mentor who can guide you and provide support. Stay tuned!\nOur first cohort of mentorship program was very successful. We will\nhave a new round of mentorship program coming up.</li><li>: Don't be afraid to start with small contributions. Even\nfixing a typo in the documentation or submitting a simple bug fix\ncan be a great way to get involved.</li></ul><p>By contributing to etcd, you'll not only be helping to improve a\ncritical piece of the cloud-native ecosystem but also gaining valuable\nexperience and skills. So, jump in and start contributing!</p><p><strong>Frederico: Excellent, thank you. Lastly, one piece of advice that\nyou'd like to give to other newly formed SIGs?</strong></p><p>: Absolutely! My advice would be to embrace the established\nprocesses of the larger community, prioritize collaboration with other\nSIGs, and focus on building a strong community.</p><p>: Here are some tips I myself found very helpful in my OSS\njourney:</p><ul><li>: Open source development can take time. Don't get\ndiscouraged if your contributions aren't accepted immediately or if\nyou encounter challenges.</li><li>: The etcd community values collaboration and\nrespect. Be mindful of others' opinions and work together to achieve\ncommon goals.</li><li>: Contributing to open source should be\nenjoyable. Find areas that interest you and contribute in ways that\nyou find fulfilling.</li></ul><p><strong>Frederico: A great way to end this spotlight, thank you all!</strong></p><p>For more information and resources, please take a look at :</p>","contentLength":9586,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NFTables mode for kube-proxy","url":"https://kubernetes.io/blog/2025/02/28/nftables-kube-proxy/","date":1740700800,"author":"","guid":458,"unread":true,"content":"<p>A new nftables mode for kube-proxy was introduced as an alpha feature\nin Kubernetes 1.29. Currently in beta, it is expected to be GA as of\n1.33. The new mode fixes long-standing performance problems with the\niptables mode and all users running on systems with reasonably-recent\nkernels are encouraged to try it out. (For compatibility reasons, even\nonce nftables becomes GA, iptables will still be the .)</p><h2>Why nftables? Part 1: data plane latency</h2><p>The iptables API was designed for implementing simple firewalls, and\nhas problems scaling up to support Service proxying in a large\nKubernetes cluster with tens of thousands of Services.</p><p>In general, the ruleset generated by kube-proxy in iptables mode has a\nnumber of iptables rules proportional to the sum of the number of\nServices and the total number of endpoints. In particular, at the top\nlevel of the ruleset, there is one rule to test each possible Service\nIP (and port) that a packet might be addressed to:</p><pre tabindex=\"0\"><code># If the packet is addressed to 172.30.0.41:80, then jump to the chain\n# KUBE-SVC-XPGD46QRK7WJZT7O for further processing\n-A KUBE-SERVICES -m comment --comment \"namespace1/service1:p80 cluster IP\" -m tcp -p tcp -d 172.30.0.41 --dport 80 -j KUBE-SVC-XPGD46QRK7WJZT7O\n# If the packet is addressed to 172.30.0.42:443, then...\n-A KUBE-SERVICES -m comment --comment \"namespace2/service2:p443 cluster IP\" -m tcp -p tcp -d 172.30.0.42 --dport 443 -j KUBE-SVC-GNZBNJ2PO5MGZ6GT\n# etc...\n-A KUBE-SERVICES -m comment --comment \"namespace3/service3:p80 cluster IP\" -m tcp -p tcp -d 172.30.0.43 --dport 80 -j KUBE-SVC-X27LE4BHSL4DOUIK\n</code></pre><p>This means that when a packet comes in, the time it takes the kernel\nto check it against all of the Service rules is  in the number\nof Services. As the number of Services increases, both the average and\nthe worst-case latency for the first packet of a new connection\nincreases (with the difference between best-case, average, and\nworst-case being mostly determined by whether a given Service IP\naddress appears earlier or later in the  chain).</p><p>By contrast, with nftables, the normal way to write a ruleset like\nthis is to have a  rule, using a \"verdict map\" to do the\ndispatch:</p><pre tabindex=\"0\"><code>table ip kube-proxy {\n# The service-ips verdict map indicates the action to take for each matching packet.\nmap service-ips {\ntype ipv4_addr . inet_proto . inet_service : verdict\ncomment \"ClusterIP, ExternalIP and LoadBalancer IP traffic\"\nelements = { 172.30.0.41 . tcp . 80 : goto service-ULMVA6XW-namespace1/service1/tcp/p80,\n172.30.0.42 . tcp . 443 : goto service-42NFTM6N-namespace2/service2/tcp/p443,\n172.30.0.43 . tcp . 80 : goto service-4AT6LBPK-namespace3/service3/tcp/p80,\n... }\n}\n# Now we just need a single rule to process all packets matching an\n# element in the map. (This rule says, \"construct a tuple from the\n# destination IP address, layer 4 protocol, and destination port; look\n# that tuple up in \"service-ips\"; and if there's a match, execute the\n# associated verdict.)\nchain services {\nip daddr . meta l4proto . th dport vmap @service-ips\n}\n...\n}\n</code></pre><p>Since there's only a single rule, with a roughly  map lookup,\npacket processing time is more or less constant regardless of cluster\nsize, and the best/average/worst cases are very similar:</p><p>But note the huge difference in the vertical scale between the\niptables and nftables graphs! In the clusters with 5000 and 10,000\nServices, the p50 (average) latency for nftables is about the same as\nthe p01 (approximately best-case) latency for iptables. In the 30,000\nService cluster, the p99 (approximately worst-case) latency for\nnftables manages to beat out the p01 latency for iptables by a few\nmicroseconds! Here's both sets of data together, but you may have to\nsquint to see the nftables results!:</p><h2>Why nftables? Part 2: control plane latency</h2><p>While the improvements to data plane latency in large clusters are\ngreat, there's another problem with iptables kube-proxy that often\nkeeps users from even being able to grow their clusters to that size:\nthe time it takes kube-proxy to program new iptables rules when\nServices and their endpoints change.</p><p>With both iptables and nftables, the total size of the ruleset as a\nwhole (actual rules, plus associated data) is  in the combined\nnumber of Services and their endpoints. Originally, the iptables\nbackend would rewrite every rule on every update, and with tens of\nthousands of Services, this could grow to be hundreds of thousands of\niptables rules. Starting in Kubernetes 1.26, we began improving\nkube-proxy so that it could skip updating  of the unchanged\nrules in each update, but the limitations of  as an\nAPI meant that it was still always necessary to send an update that's\n in the number of Services (though with a noticeably smaller\nconstant than it used to be). Even with those optimizations, it can\nstill be necessary to make use of kube-proxy's  config\noption to ensure that it doesn't spend every waking second trying to\npush iptables updates.</p><p>The nftables APIs allow for doing much more incremental updates, and\nwhen kube-proxy in nftables mode does an update, the size of the\nupdate is only  in the number of Services and endpoints that\nhave changed since the last sync, regardless of the total number of\nServices and endpoints. The fact that the nftables API allows each\nnftables-using component to have its own private table also means that\nthere is no global lock contention between components like with\niptables. As a result, kube-proxy's nftables updates can be done much\nmore efficiently than with iptables.</p><p>(Unfortunately I don't have cool graphs for this part.)</p><p>All that said, there are a few reasons why you might not want to jump\nright into using the nftables backend for now.</p><p>First, the code is still fairly new. While it has plenty of unit\ntests, performs correctly in our CI system, and has now been used in\nthe real world by multiple users, it has not seen anything close to as\nmuch real-world usage as the iptables backend has, so we can't promise\nthat it is as stable and bug-free.</p><p>Second, the nftables mode will not work on older Linux distributions;\ncurrently it requires a 5.13 or newer kernel. Additionally, because of\nbugs in early versions of the  command line tool, you should not\nrun kube-proxy in nftables mode on nodes that have an old (earlier\nthan 1.0.0) version of  in the host filesystem (or else\nkube-proxy's use of nftables may interfere with other uses of nftables\non the system).</p><p>Third, you may have other networking components in your cluster, such\nas the pod network or NetworkPolicy implementation, that do not yet\nsupport kube-proxy in nftables mode. You should consult the\ndocumentation (or forums, bug tracker, etc.) for any such components\nto see if they have problems with nftables mode. (In many cases they\nwill not; as long as they don't try to directly interact with or\noverride kube-proxy's iptables rules, they shouldn't care whether\nkube-proxy is using iptables or nftables.) Additionally, observability\nand monitoring tools that have not been updated may report less data\nfor kube-proxy in nftables mode than they do for kube-proxy in\niptables mode.</p><p>Finally, kube-proxy in nftables mode is intentionally not 100%\ncompatible with kube-proxy in iptables mode. There are a few old\nkube-proxy features whose default behaviors are less secure, less\nperformant, or less intuitive than we'd like, but where we felt that\nchanging the default would be a compatibility break. Since the\nnftables mode is opt-in, this gave us a chance to fix those bad\ndefaults without breaking users who weren't expecting changes. (In\nparticular, with nftables mode, NodePort Services are now only\nreachable on their nodes' default IPs, as opposed to being reachable\non all IPs, including , with iptables mode.) The\n<a href=\"https://kubernetes.io/docs/reference/networking/virtual-ips/#migrating-from-iptables-mode-to-nftables\">kube-proxy documentation</a> has more information about this, including\ninformation about metrics you can look at to determine if you are\nrelying on any of the changed functionality, and what configuration\noptions are available to get more backward-compatible behavior.</p><p>Ready to try it out? In Kubernetes 1.31 and later, you just need to\npass  to kube-proxy (or set  in\nyour kube-proxy config file).</p><p>You can also convert existing clusters from iptables (or ipvs) mode to\nnftables by updating the kube-proxy configuration and restarting the\nkube-proxy pods. (You do not need to reboot the nodes: when restarting\nin nftables mode, kube-proxy will delete any existing iptables or ipvs\nrules, and likewise, if you later revert back to iptables or ipvs\nmode, it will delete any existing nftables rules.)</p><p>As mentioned above, while nftables is now the  kube-proxy mode,\nit is not the , and we do not yet have a plan for changing\nthat. We will continue to support the iptables mode for a long time.</p><p>The future of the IPVS mode of kube-proxy is less certain: its main\nadvantage over iptables was that it was faster, but certain aspects of\nthe IPVS architecture and APIs were awkward for kube-proxy's purposes\n(for example, the fact that the  device needs to have\n Service IP address assigned to it), and some parts of\nKubernetes Service proxying semantics were difficult to implement\nusing IPVS (particularly the fact that some Services had to have\ndifferent endpoints depending on whether you connected to them from a\nlocal or remote client). And now, the nftables mode has the same\nperformance as IPVS mode (actually, slightly better), without any of\nthe downsides:</p><p>(In theory the IPVS mode also has the advantage of being able to use\nvarious other IPVS functionality, like alternative \"schedulers\" for\nbalancing endpoints. In practice, this ended up not being very useful,\nbecause kube-proxy runs independently on every node, and the IPVS\nschedulers on each node had no way of sharing their state with the\nproxies on other nodes, thus thwarting the effort to balance traffic\nmore cleverly.)</p><p>While the Kubernetes project does not have an immediate plan to drop\nthe IPVS backend, it is probably doomed in the long run, and people\nwho are currently using IPVS mode should try out the nftables mode\ninstead (and file bugs if you think there is missing functionality in\nnftables mode that you can't work around).</p>","contentLength":10096,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Cloud Controller Manager Chicken and Egg Problem","url":"https://kubernetes.io/blog/2025/02/14/cloud-controller-manager-chicken-egg-problem/","date":1739491200,"author":"","guid":457,"unread":true,"content":"<p>Kubernetes 1.31\n<a href=\"https://kubernetes.io/blog/2024/05/20/completing-cloud-provider-migration/\">completed the largest migration in Kubernetes history</a>, removing the in-tree\ncloud provider. While the component migration is now done, this leaves some additional\ncomplexity for users and installer projects (for example, kOps or Cluster API) . We will go\nover those additional steps and failure points and make recommendations for cluster owners.\nThis migration was complex and some logic had to be extracted from the core components,\nbuilding four new subsystems.</p><figure><img src=\"https://kubernetes.io/images/docs/components-of-kubernetes.svg\" alt=\"Components of Kubernetes\"></figure><p>One of the most critical functionalities of the cloud controller manager is the node controller,\nwhich is responsible for the initialization of the nodes.</p><p>As you can see in the following diagram, when the  starts, it registers the Node\nobject with the apiserver, Tainting the node so it can be processed first by the\ncloud-controller-manager. The initial Node is missing the cloud-provider specific information,\nlike the Node Addresses and the Labels with the cloud provider specific information like the\nNode, Region and Instance type information.</p><figure><img src=\"https://kubernetes.io/blog/2025/02/14/cloud-controller-manager-chicken-egg-problem/ccm-chicken-egg-problem-sequence-diagram.svg\" alt=\"Chicken and egg problem sequence diagram\"><figcaption><p>Chicken and egg problem sequence diagram</p></figcaption></figure><p>This new initialization process adds some latency to the node readiness. Previously, the kubelet\nwas able to initialize the node at the same time it created the node. Since the logic has moved\nto the cloud-controller-manager, this can cause a <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/#chicken-and-egg\">chicken and egg problem</a>\nduring the cluster bootstrapping for those Kubernetes architectures that do not deploy the\ncontroller manager as the other components of the control plane, commonly as static pods,\nstandalone binaries or daemonsets/deployments with tolerations to the taints and using\n (more on this below)</p><h2>Examples of the dependency problem</h2><p>As noted above, it is possible during bootstrapping for the cloud-controller-manager to be\nunschedulable and as such the cluster will not initialize properly. The following are a few\nconcrete examples of how this problem can be expressed and the root causes for why they might\noccur.</p><p>These examples assume you are running your cloud-controller-manager using a Kubernetes resource\n(e.g. Deployment, DaemonSet, or similar) to control its lifecycle. Because these methods\nrely on Kubernetes to schedule the cloud-controller-manager, care must be taken to ensure it\nwill schedule properly.</p><h3>Example: Cloud controller manager not scheduling due to uninitialized taint</h3><p>As <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/#running-cloud-controller-manager\">noted in the Kubernetes documentation</a>, when the kubelet is started with the command line\nflag <code>--cloud-provider=external</code>, its corresponding  object will have a no schedule taint\nnamed <code>node.cloudprovider.kubernetes.io/uninitialized</code> added. Because the cloud-controller-manager\nis responsible for removing the no schedule taint, this can create a situation where a\ncloud-controller-manager that is being managed by a Kubernetes resource, such as a \nor , may not be able to schedule.</p><p>If the cloud-controller-manager is not able to be scheduled during the initialization of the\ncontrol plane, then the resulting  objects will all have the\n<code>node.cloudprovider.kubernetes.io/uninitialized</code> no schedule taint. It also means that this taint\nwill not be removed as the cloud-controller-manager is responsible for its removal. If the no\nschedule taint is not removed, then critical workloads, such as the container network interface\ncontrollers, will not be able to schedule, and the cluster will be left in an unhealthy state.</p><h3>Example: Cloud controller manager not scheduling due to not-ready taint</h3><p>The next example would be possible in situations where the container network interface (CNI) is\nwaiting for IP address information from the cloud-controller-manager (CCM), and the CCM has not\ntolerated the taint which would be removed by the CNI.</p><blockquote><p>\"The Node controller detects whether a Node is ready by monitoring its health and adds or removes this taint accordingly.\"</p></blockquote><p>One of the conditions that can lead to a Node resource having this taint is when the container\nnetwork has not yet been initialized on that node. As the cloud-controller-manager is responsible\nfor adding the IP addresses to a Node resource, and the IP addresses are needed by the container\nnetwork controllers to properly configure the container network, it is possible in some\ncircumstances for a node to become stuck as not ready and uninitialized permanently.</p><p>This situation occurs for a similar reason as the first example, although in this case, the\n<code>node.kubernetes.io/not-ready</code> taint is used with the no execute effect and thus will cause the\ncloud-controller-manager not to run on the node with the taint. If the cloud-controller-manager is\nnot able to execute, then it will not initialize the node. It will cascade into the container\nnetwork controllers not being able to run properly, and the node will end up carrying both the\n<code>node.cloudprovider.kubernetes.io/uninitialized</code> and <code>node.kubernetes.io/not-ready</code> taints,\nleaving the cluster in an unhealthy state.</p><p>There is no one ‚Äúcorrect way‚Äù to run a cloud-controller-manager. The details will depend on the\nspecific needs of the cluster administrators and users. When planning your clusters and the\nlifecycle of the cloud-controller-managers please consider the following guidance:</p><p>For cloud-controller-managers running in the same cluster, they are managing.</p><ol><li>Use host network mode, rather than the pod network: in most cases, a cloud controller manager\nwill need to communicate with an API service endpoint associated with the infrastructure.\nSetting ‚ÄúhostNetwork‚Äù to true will ensure that the cloud controller is using the host\nnetworking instead of the container network and, as such, will have the same network access as\nthe host operating system. It will also remove the dependency on the networking plugin. This\nwill ensure that the cloud controller has access to the infrastructure endpoint (always check\nyour networking configuration against your infrastructure provider‚Äôs instructions).</li><li>Use a scalable resource type.  and  are useful for controlling the\nlifecycle of a cloud controller. They allow easy access to running multiple copies for redundancy\nas well as using the Kubernetes scheduling to ensure proper placement in the cluster. When using\nthese primitives to control the lifecycle of your cloud controllers and running multiple\nreplicas, you must remember to enable leader election, or else your controllers will collide\nwith each other which could lead to nodes not being initialized in the cluster.</li><li>Target the controller manager containers to the control plane. There might exist other\ncontrollers which need to run outside the control plane (for example, Azure‚Äôs node manager\ncontroller). Still, the controller managers themselves should be deployed to the control plane.\nUse a node selector or affinity stanza to direct the scheduling of cloud controllers to the\ncontrol plane to ensure that they are running in a protected space. Cloud controllers are vital\nto adding and removing nodes to a cluster as they form a link between Kubernetes and the\nphysical infrastructure. Running them on the control plane will help to ensure that they run\nwith a similar priority as other core cluster controllers and that they have some separation\nfrom non-privileged user workloads.\n<ol><li>It is worth noting that an anti-affinity stanza to prevent cloud controllers from running\non the same host is also very useful to ensure that a single node failure will not degrade\nthe cloud controller performance.</li></ol></li><li>Ensure that the tolerations allow operation. Use tolerations on the manifest for the cloud\ncontroller container to ensure that it will schedule to the correct nodes and that it can run\nin situations where a node is initializing. This means that cloud controllers should tolerate\nthe <code>node.cloudprovider.kubernetes.io/uninitialized</code> taint, and it should also tolerate any\ntaints associated with the control plane (for example, <code>node-role.kubernetes.io/control-plane</code>\nor <code>node-role.kubernetes.io/master</code>). It can also be useful to tolerate the\n<code>node.kubernetes.io/not-ready</code> taint to ensure that the cloud controller can run even when the\nnode is not yet available for health monitoring.</li></ol><p>For cloud-controller-managers that will not be running on the cluster they manage (for example,\nin a hosted control plane on a separate cluster), then the rules are much more constrained by the\ndependencies of the environment of the cluster running the cloud-controller-manager. The advice\nfor running on a self-managed cluster may not be appropriate as the types of conflicts and network\nconstraints will be different. Please consult the architecture and requirements of your topology\nfor these scenarios.</p><p>This is an example of a Kubernetes Deployment highlighting the guidance shown above. It is\nimportant to note that this is for demonstration purposes only, for production uses please\nconsult your cloud provider‚Äôs documentation.</p><pre tabindex=\"0\"><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nlabels:\napp.kubernetes.io/name: cloud-controller-manager\nname: cloud-controller-manager\nnamespace: kube-system\nspec:\nreplicas: 2\nselector:\nmatchLabels:\napp.kubernetes.io/name: cloud-controller-manager\nstrategy:\ntype: Recreate\ntemplate:\nmetadata:\nlabels:\napp.kubernetes.io/name: cloud-controller-manager\nannotations:\nkubernetes.io/description: Cloud controller manager for my infrastructure\nspec:\ncontainers: # the container details will depend on your specific cloud controller manager\n- name: cloud-controller-manager\ncommand:\n- /bin/my-infrastructure-cloud-controller-manager\n- --leader-elect=true\n- -v=1\nimage: registry/my-infrastructure-cloud-controller-manager@latest\nresources:\nrequests:\ncpu: 200m\nmemory: 50Mi\nhostNetwork: true # these Pods are part of the control plane\nnodeSelector:\nnode-role.kubernetes.io/control-plane: \"\"\naffinity:\npodAntiAffinity:\nrequiredDuringSchedulingIgnoredDuringExecution:\n- topologyKey: \"kubernetes.io/hostname\"\nlabelSelector:\nmatchLabels:\napp.kubernetes.io/name: cloud-controller-manager\ntolerations:\n- effect: NoSchedule\nkey: node-role.kubernetes.io/master\noperator: Exists\n- effect: NoExecute\nkey: node.kubernetes.io/unreachable\noperator: Exists\ntolerationSeconds: 120\n- effect: NoExecute\nkey: node.kubernetes.io/not-ready\noperator: Exists\ntolerationSeconds: 120\n- effect: NoSchedule\nkey: node.cloudprovider.kubernetes.io/uninitialized\noperator: Exists\n- effect: NoSchedule\nkey: node.kubernetes.io/not-ready\noperator: Exists\n</code></pre><p>When deciding how to deploy your cloud controller manager it is worth noting that\ncluster-proportional, or resource-based, pod autoscaling is not recommended. Running multiple\nreplicas of a cloud controller manager is good practice for ensuring high-availability and\nredundancy, but does not contribute to better performance. In general, only a single instance\nof a cloud controller manager will be reconciling a cluster at any given time.</p>","contentLength":10702,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev","k8s"]}