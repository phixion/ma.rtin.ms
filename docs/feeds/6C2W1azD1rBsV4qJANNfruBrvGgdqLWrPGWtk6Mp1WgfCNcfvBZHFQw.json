{"id":"6C2W1azD1rBsV4qJANNfruBrvGgdqLWrPGWtk6Mp1WgfCNcfvBZHFQw","title":"The System Design Newsletter","displayTitle":"Dev - System Design Newsletter","url":"https://newsletter.systemdesign.one/feed","feedLink":"https://newsletter.systemdesign.one/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":9,"items":[{"title":"I struggled with system design until I learned these 114 concepts","url":"https://newsletter.systemdesign.one/p/system-design-core-concepts","date":1771086026,"author":"Neo Kim","guid":39,"unread":true,"content":"<p>Following is the second of a premium 3-part newsletter series… If you’re just getting started with system design or want a super strong foundation, then this newsletter is for you.</p><p>On with part 2 of the newsletter:</p><p>Some of these are foundational, and some are quite advanced. ALL of them are super useful to software engineers building distributed systems…</p><p>Curious to know how many were new to you:</p><ol start=\"39\"><li><p>Block vs File vs Object Storage</p></li><li><p>Clock Synchronization Problem</p></li></ol><p>(…and much more in part 3!)</p><ul><li><p>What it is &amp; how it works--in simple words</p></li></ul><p> is the only AI code review tool that has a deep understanding of your codebase, docs, and past decisions, giving you thoughtful feedback that feels like it came from your best engineer.</p><blockquote><p>WebSockets provide full-duplex, bidirectional communication between client &amp; server over a single, long-lived TCP connection.</p></blockquote><p>Unlike HTTP, where the client always initiates requests, WebSockets allow the server to push data to clients in real-time.</p><p>After an initial HTTP handshake, the connection upgrades to the WebSocket protocol. Both the client and the server can then send messages at any time.</p><p>WebSockets is like a phone call where both people can talk and listen simultaneously…</p><p>Compare this to HTTP, which is like sending letters back and forth,,, where you wait for a reply before sending the next message.</p><p>They’re more complex to implement and scale since each connection consumes server resources. Also, load balancing becomes tricky because connections are long-lived and stateful.</p><p>Plus, some proxies/firewalls “block” WebSocket upgrades or long-lived connections, so compatibility can vary.</p><p>Use for real-time apps like chat systems, live sports scores, collaborative editing, online gaming, or stock trading platforms. But avoid for simple request-response patterns where HTTP is enough.</p><blockquote><p>An API gateway is a server that acts as a SINGLE entry point for all client requests to your microservices.</p></blockquote><p>It handles request routing, composition, and protocol translation. Instead of clients calling different microservices directly, they make ‘one call’ to the gateway.</p><p>An API gateway is like a hotel concierge:</p><p>Instead of guests figuring out which department to call, they call the concierge desk. The concierge knows which department to contact and gets back to the guest with answers.</p><p>They can become a bottleneck or a single point of failure if not deployed redundantly. Besides, they increase latency because of the extra network hop. So the gateway itself needs to scale &amp; be highly available.</p><p>Useful in microservices because it provides clients with a single entry point.</p><p>Also, it handles common tasks like authentication, authorization, and rate limiting in one place, and can return different responses for different clients, such as web or mobile apps.</p><blockquote><p>Distributed cache spreads cached data across many cache servers instead of a single cache instance.</p></blockquote><p>Each cache node stores a portion of the data, typically determined by consistent hashing. Popular implementations include Redis Cluster and Memcached.</p><p>Multiple fast-food locations across a city instead of one central kitchen.</p><p>Each location stores popular items for quick service. Total capacity increases by opening more locations, and no single location becomes overwhelmed during rush hour.</p><p>They add operational complexity (partitioning, rebalancing, replication) and can incur overhead during rebalancing/failover. Also, there’s a risk of cache misses when keys get redistributed.</p><p>Plus, debugging becomes harder with many nodes.</p><p>Use a distributed cache in high-traffic sites when one cache server can’t handle the traffic, when the data no longer fits in one machine’s memory, or when you need high availability.</p><p>Start with a single cache server…Move to a distributed cache setup only when you reach scaling or reliability limits.</p><h2><strong>42. Cache Eviction Policies</strong></h2><blockquote><p>Cache eviction policies decide which data to remove when the cache is full and new data needs space.</p></blockquote><ul><li><p>Least Recently Used () removes the data that has NOT been accessed for the longest time.</p></li><li><p>Least Frequently Used () removes the data that is accessed the least often.</p></li><li><p>First In, First Out () removes the oldest data first, based on when it was added.</p></li><li><p>Time To Live () automatically removes data after a fixed time period.</p></li></ul><p>Think of your phone storage:</p><ul><li><p>LRU deletes photos you haven’t opened in a long time.</p></li><li><p>LFU deletes photos you rarely look at.</p></li><li><p>FIFO deletes the oldest photos first.</p></li><li><p>TTL is like a message that automatically disappears after 24 hours.</p></li></ul><p>Different policies work well for different access patterns…</p><ul><li><p>LRU works well when recently accessed data is likely to be used again. Yet it can perform poorly if large amounts of data are accessed only once.</p></li><li><p>LFU works well when frequently accessed data stays popular over time, but it reacts slowly if usage patterns change.</p></li><li><p>FIFO is simple but does not consider how often or recently data is used.</p></li><li><p>TTL ensures data does not stay in the cache forever, but it may remove useful data too early or keep stale data too long.</p></li></ul><p>Each policy has overhead in tracking metadata for eviction decisions.</p><ul><li><p>LRU for general-purpose caching where recent data is likely to be reused.</p></li><li><p>LFU when certain data remains popular for long periods.</p></li><li><p>TTL when data naturally becomes stale after some time, such as API responses or session data.</p></li></ul><p>Most systems combine TTL with LRU or LFU.</p><h2><strong>43. Proxy vs Reverse Proxy</strong></h2><blockquote><p>A forward proxy sits between clients and the Internet. It sends requests to external servers on behalf of the client.</p><p>A reverse proxy sits in front of your servers. It receives requests from clients and forwards them to the correct backend server.</p></blockquote><p>With a forward proxy, client is configured to use it. With a reverse proxy, the client usually doesn’t know it exists.</p><p>A forward proxy is like an assistant who makes calls for you, so the person on the other end doesn’t talk with you directly.</p><p>A reverse proxy is like a company receptionist. Callers think they are contacting the company directly,,, but the receptionist routes the call internally.</p><p>Forward proxies can improve privacy, enforce security policies, and filter traffic. Yet they add extra network hops and can increase latency.</p><p>Reverse proxies provide load balancing, SSL termination, caching, and protection from direct exposure of backend servers. But they must be deployed redundantly to avoid becoming a single point of failure.</p><p>Both require proper configuration to prevent security risks…</p><ul><li><p>Use forward proxies in corporate networks for content filtering, monitoring &amp; privacy control.</p></li><li><p>Use reverse proxies in production systems for load balancing, SSL termination, traffic routing, and protection against attacks.</p></li></ul><p>Most apps use reverse proxies such as Nginx, HAProxy, or cloud load balancers.</p><blockquote><p>Hypertext Transfer Protocol (HTTP) sends data in ‘plain text’.</p><p>Hypertext Transfer Protocol Secure (HTTPS) is HTTP encrypted using Transport Layer Security (TLS).</p></blockquote><p>HTTPS encrypts communication between the client and server, protecting data from eavesdropping and tampering. The server provides a certificate to prove its identity. Modern browsers mark HTTP sites as “Not Secure.”</p><p>HTTP is like sending a postcard. Anyone who intercepts it can read the message.</p><p>HTTPS is like sending a sealed, locked box. Even if someone intercepts it, they cannot read or change what’s inside.</p><p>HTTPS requires managing digital certificates and adds a small performance cost because of the TLS handshake. Yet these costs are minimal compared to the security benefits.</p><p>HTTPS protects against eavesdropping and man-in-the-middle attacks, where attackers intercept or modify traffic.</p><p>HTTPS is also a positive ranking factor for search engines and is required for many modern web features, such as HTTP/2, service workers, and secure cookies.</p><blockquote><p>Transmission Control Protocol (TCP) is a connection-oriented protocol that provides reliable, ordered delivery of data.</p><p>User Datagram Protocol (UDP) is connectionless and sends packets without guaranteeing delivery, order, or protection against duplication.</p></blockquote><p>TCP establishes a connection using a handshake, retransmits lost packets, and performs congestion control.</p><p>UDP sends packets independently with minimal overhead &amp; no built-in reliability. i.e., UDP is faster but less reliable.</p><p>TCP is like certified mail with tracking and delivery confirmation.</p><p>UDP is like sending postcards. They usually arrive, but they might be lost or arrive out of order…</p><p>TCP adds latency due to the handshake, acknowledgments, retransmissions, and head-of-line blocking (where a lost packet delays subsequent packets).</p><p>UDP doesn’t guarantee delivery or order. If reliability is needed,,, the application code must handle it.</p><ul><li><p>Use TCP for web browsing, email, file transfers, database connections, and APIs where accuracy matters more than speed.</p></li><li><p>Use UDP for real-time applications such as video calls, live streaming, and online gaming, where low latency is more important than reliability.</p></li></ul><p>NOTE: DNS typically uses UDP for speed, but it can fall back to TCP for large responses or specific operations.</p><p><em><strong>Reminder: this is a teaser of the subscriber-only post, exclusive to my golden members.</strong></em></p><p>When you upgrade, you’ll get:</p><ul><li><p><strong>Full access to system design case studies</strong></p></li><li><p>FREE access to (coming) Design, Build, Scale newsletter series</p></li><li><p><strong>FREE access to (coming) popular interview question breakdowns</strong></p></li></ul><p>Get 10x the results you currently get with 1/10th the time, energy &amp; effort.</p>","contentLength":9359,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/e9e8cf9a-93be-4a9c-9512-1d9cdb098857_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"Behavioral Interview Playbook for Software Engineers","url":"https://newsletter.systemdesign.one/p/common-behavioral-interview-questions","date":1770888085,"author":"Prasad Rao","guid":38,"unread":true,"content":"<p>You’ve prepared for the technical interview…You’ve solved the system design problem…You’ve written clean code…</p><p>Yet the hiring decision often comes down to something completely different: “your behavioral interview”.</p><p>This is the conversation where the interviewer asks, <em>“Tell me about a time when you disagreed with your manager,”</em> or <em>“Describe a situation where you had to make a decision with incomplete information.”</em></p><p>It’s where they assess not just what you can build, but how you work, how you think, and how you’ll show up in their organization.</p><p> turns search results into predictable JSON with built-in scale, location options, and protection from blocks.</p><p>That’s why engineers use it to ship:</p><ul></ul><p>All without maintaining scrapers or infrastructure.</p><p>Check out his LinkedIn, newsletter, and offerings:</p><ul><li><p> - If you’re preparing for interviews, I highly recommend this course as it focuses specifically on behavioral interviews, setting it apart from other courses. You can use code NEO25 for 25% off.</p></li></ul><p>Ask any experienced interviewer at Big Tech why candidates fail their interviews.</p><p>Their #1 reason is consistent:</p><blockquote><p><em>“Smart technical professionals who can’t clearly articulate their past work. They ramble too much, miss the main points, and can’t explain their decision-making process.”</em></p></blockquote><p>For many engineers, this feels unfair…</p><p>You’re hired to write code, not to tell stories. But behavioral interviews exist for a reason, and understanding that reason changes everything about how you prepare.</p><h4><strong>What We Mean by Behavioral Skills</strong></h4><p>Before we dive deeper, let’s clarify what behavioral skills actually are:</p><p>These are your personal attributes and interpersonal abilities that shape how you work, interact with others, and approach challenges. Unlike technical skills, which are specific to a particular job or industry, behavioral skills are transferable across various roles and sectors.</p><p>You might be an exceptional backend Java programmer, but that skill won’t directly transfer to a data engineer role… Your ability to handle conflict, though? That transfers everywhere. Your capacity to make decisions with incomplete information? That applies in any organization.</p><p>This is why companies prioritize these skills.</p><h4><strong>Why Companies Care About Behavior</strong></h4><p>Technical skills are table stakes.</p><p>Any engineer applying to a senior role can solve problems and write decent code. What separates a senior engineer from a staff/principal engineer, or what prevents someone from getting stuck at the senior level for years? It’s how they operate in ambiguity, how they lead without authority, how they make decisions that affect hundreds of engineers, and how they communicate complexity to non-technical leaders.</p><p>These are behavioral competencies…and they’re harder to assess in a coding or system design interview.</p><p>The primary reason employers focus on behavioral skills is that past behavior is often the best predictor of future performance. This concept, known as <strong>“behavioral consistency,”</strong> is a fundamental principle in psychology and human resources.</p><blockquote><p><em>Behavioral consistency suggests that the way a person has behaved in the past is likely to be consistent with how they will behave in the future, especially in similar situations.</em></p></blockquote><p>By asking about how you’ve handled situations in the past, interviewers get a sense of how you’re likely to act in similar scenarios if hired.</p><p>A behavioral interview is a risk-mitigation tool for the hiring manager.</p><blockquote><p>When they ask about a conflict you resolved, they’re trying to understand:</p><p><em>Do you escalate appropriately?</em></p><p><em>Do you compromise or dig in?</em></p><p><em>Do you think about the other person’s perspective?</em></p></blockquote><p>For example, if you can describe a time when you successfully resolved a conflict with a manager, it suggests you’ll be able to handle such situations in the new role as well. This gives employers confidence in your ability to navigate workplace challenges.</p><p>If you’ve successfully led a team project in the past, you’re likely to demonstrate good leadership skills in future team projects. If you’ve shown creativity in solving problems at your previous job, you’re likely to bring that same innovative thinking to new challenges.</p><h4><strong>How Behavioral Interviews Evaluate Seniority</strong></h4><p>Here’s something most engineers don’t realize: same behavioral question is asked to candidates at different levels, but the bar changes dramatically.</p><p><em>Same question. Completely different answers. The difference is scope, self-awareness, and impact.</em></p><p>Interviewers check behavioral responses for key signs.</p><p>They want to see if you understand complexity. They also look for how well you’ve handled ambiguity. Learning from mistakes is important as well. Finally, you need to communicate all this clearly.</p><p>As you climb the ladder, they want to see that you can make decisions for larger groups. They look for your ability to influence others without authority. Also, they want to know if you consider the organization’s impact, not just technical correctness.</p><p>Behavioral interviews are a gating mechanism:</p><p>Companies use them to calibrate your level. Get them right, and you move up. Get them wrong, and you get downleveled—placed in a role one or two levels below what you applied for.</p><p>Downleveling happens when your behavioral responses don’t match the seniority you’re targeting. You may have the skills for a staff role, but your stories matter. If you sound junior—focusing on your own work instead of the impact, or lacking proof of handling uncertainty or influencing others—then you might get a senior role instead. Same company, same team, potentially 20-30% lower salary, and a much slower path to where you wanted to be.</p><p>This is why behavioral interviews matter more than most engineers realize. They’re not a soft skill afterthought. They’re the primary mechanism through which companies evaluate whether you’re ready for the level you’re targeting.</p><blockquote><p><em>Technical skills get you hired. Behavioral skills get you hired at the right level.</em></p></blockquote><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/common-behavioral-interview-questions?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><h4><strong>What This Playbook Will Do</strong></h4><p>Over the next few sections, you’ll learn how you should be preparing for your behavioral interviews.</p><p>You’ll master the STAR framework—the real version, not the generic one you’ve likely heard. This one actually prevents downleveling. And you’ll see real examples of answers that landed offers at Big Tech companies.</p><p>More importantly, you’ll learn to think like an interviewer. When you understand what they really want to hear, you can tell stories that address their true questions. These aren’t just surface-level questions. They go deeper, focusing on your judgment, impact, and readiness for the role.</p><p>The engineers who excel at behavioral interviews aren’t necessarily the best storytellers. They’re the ones who understand what’s being evaluated and can connect their experiences to those evaluation criteria.</p><p>To start, let’s understand when and how your behavioral skills are evaluated during an interview process.</p><p>Here’s something that surprises most engineers: behavioral skills aren’t just evaluated during the dedicated behavioral interview round. They’re being evaluated from the very first question, often before the technical interview even starts.</p><p>Many candidates believe behavioral assessment happens in a separate block, usually near the end of the interview process.</p><p>In reality, hiring teams are evaluating your behavioral competencies across every single interview. Your ability to be hired at the right level depends on consistent performance across three distinct evaluation moments. Each one needs different preparation.</p><h3><strong>Three Moments When Behavioral Skills Are Evaluated</strong></h3><p>First, there’s the opening conversation…</p><p>This starts with your recruiter call and continues into the first technical interview. Then, behavioral evaluation occurs throughout your technical interviews. Finally, there’s the dedicated behavioral interview round.</p><p>Each moment assesses different aspects of your competencies and requires different strategies.</p><p>Most engineers focus only on the third moment…</p><p>They prepare answers to “<em>Tell me about a time when...”</em> questions but neglect the other two. This is a critical mistake. The interviewer who speaks to you first forms an impression that influences how every other interviewer perceives you. The technical interviewer who watches you explain your architectural choices is simultaneously assessing your judgment and decision-making process. By the time you reach the dedicated behavioral round, the narrative about you is already partially written.</p><p>Let’s look at each moment, what’s being evaluated, and how to prepare…</p><h4><strong>Moment 1: Tell Me About Yourself</strong></h4><p>The question “” appears everywhere.</p><ul><li><p>It’s asked by the recruiter on your initial call.</p></li><li><p>It’s asked by the technical interviewer at the beginning of the coding round.</p></li><li><p>It’s asked by the hiring manager.</p></li><li><p>It’s asked by the panel interviewer before the system design discussion. </p></li></ul><p>Some candidates face this question five times in a single interview loop, sometimes with slightly different framings like <em>“Walk me through your resume”</em> or <em>“Tell me about your background.”</em></p><p>Most engineers completely underestimate its importance. When you’re asked, “ the interviewer isn’t looking for your resume recited out loud.</p><p>They’re assessing several behavioral competencies simultaneously.</p><blockquote><p>Can you communicate concisely?</p><p>Do you highlight impact or just responsibilities?</p><p>Do you show self-awareness about your growth?</p><p>Do you understand what matters for this specific role?</p><p>Can you tell a coherent story about your career progression?</p></blockquote><p>Your answer shapes how the interviewer perceives you before any technical question is asked.</p><p>If you ramble for five minutes without clarity, they’ve already formed an impression... If you jump between random accomplishments without connection, they’re questioning your communication skills… If you focus entirely on what you did without explaining the impact, they’re seeing a junior mindset.</p><p>This first impression compounds throughout the interview.</p><h4><strong>Moment 2: Behavioral Skills During Technical Interviews</strong></h4><p>Many candidates don’t realize that behavioral assessment happens throughout technical interviews, not just when answering explicit behavioral questions.</p><p>During a coding interview, the interviewer might ask, <em>“Why did you choose this data structure?”</em> or <em>“How would you optimize this further?”</em> These are behavioral moments. They’re assessing how you think about tradeoffs, whether you consider constraints, how you handle feedback, and whether you communicate reasoning clearly.</p><p>During a system design interview, when you’re drawing architecture on the whiteboard, behavioral evaluation is happening constantly.</p><blockquote><p>Can you explain your decision-making process?</p><p>Do you consider the viewpoint of your interviewer?</p><p>Do you ask clarifying questions before diving in?</p><p>Do you acknowledge tradeoffs, or do you present your solution as obviously optimal?</p><p>Do you listen when challenged, or do you defend rigidly?</p></blockquote><p>The technical answer is only part of the evaluation. How you arrive at that answer, how you explain your reasoning, and how you discuss tradeoffs all signal your seniority level.</p><p>This is where the behavioral framework from later in this playbook becomes critical.</p><p>You need to communicate not just your solution, but your thinking process. You need to show scope, evidence of learning, and organizational awareness.</p><h4><strong>Moment 3: Dedicated Behavioral Interview Questions</strong></h4><p>It’s where you have the most time and space to demonstrate behavioral competencies in depth.</p><p>It’s where you seal the narrative that’s been building throughout the interview and get hired at the right level. (We will dive into how to prepare for behavioral interviews in this playbook.)</p><p><strong>What This Means for Your Preparation</strong></p><p>You need to prepare for all three moments, not just the behavioral round.</p><p>First, master your  answer.</p><p>This is your opening act. Make it strategic, concise, and tailored to the role. Practice it until it feels natural, not robotic. Know multiple versions for different interview contexts.</p><p>Second, develop the ability to articulate your thinking during technical interviews.</p><p>Learn to explain not just what you decided, but why. Practice talking through your decision-making process, assumptions, and trade-offs. When an interviewer asks a clarifying question or pushes back, view it as a chance to show your thought process. It’s not an attack.</p><p>Third, prepare deep answers for behavioral questions using the frameworks we’ll cover in this playbook.</p><p>Have eight to fifteen strong stories ready. You can adjust them for different questions based on the company you’re interviewing with. Know the underlying behavioral competencies you’re demonstrating with each story.</p><p>The engineers who get hired at the right level aren’t necessarily the smartest in the room. They’re the ones who  across all three moments. They tell a coherent story about their career, their judgment, and their impact from the first question to the last.</p><p>Let’s dive into frameworks for preparing for each of these 3 moments, starting from ”</p><p>When an interviewer asks, <em>“Tell me about yourself,”</em> the interviewer is actually asking, <em>“Tell me why I should hire you?”</em></p><p>So instead of focusing on your entire career experience, you need to focus only on the highlights of your career experience that are most relevant to the job role you’re applying for.</p><p>You need to have a 1-minute elevator pitch for yourself.</p><p>That one minute not only helps you connect with the interviewer but also steers the interview. You subtly drop in the keywords and your strong areas on which you would like the interviewer to probe further.</p><p>I understand keeping it under one minute is extremely difficult. You can have it as 2 min max.</p><h4><strong>Here is the framework you can use to write your introduction:</strong></h4><ol><li><p>Career Summary [keep it to 20 seconds max]</p><ul><li><p>This is your hook to keep the interviewer engaged for the next 1-2 minutes as you power through your introduction.</p></li></ul></li><li><p>Main Body [45-90 seconds]</p><ul><li><p>This section should explain why you are a strong fit for the role. In no particular order or specific time allocation, talk about following:</p><ul></ul></li><li><p>You’ll notice in my example below that I start this section with a recent project, as it aligns with the role's experience requirements. I have not explicitly discussed key skills, but I have woven them into the two project examples I have provided.</p></li></ul></li><li><p>Personal Interest [Optional. Keep it very short]</p><ul><li><p>It’s a nice-to-have section where you can talk about what you do outside of your work.</p></li></ul></li></ol><p>As a mental model, to create your 1-2 mins introduction, you can use this flowchart:</p><h4><strong>Example of an Elevator Pitch</strong></h4><p>Let’s understand how you can put the framework I mentioned into action to write your own introduction using an example.</p><p>Here is the elevator pitch I used in my first technical round at AWS in 2019:</p><blockquote><p><em>I started my career as a .NET developer, and over the last 10 years, I have gained extensive experience in developing and architecting applications using Microsoft workloads stack.</em></p><p><em>In my current project, I’m working as a tech lead helping a UK financial institution in digitally transforming their re-mortgage platform. Their legacy platform was built as a monolithic application in .NET with Winforms as frontend and SQL Server Database as backend. Their team was following the waterfall SDLC. I, along with my team, are helping them adopt agile development methodology and are modernizing their monolithic application by breaking it into microservices and implementing Jenkins CI/CD pipeline.</em></p><p><em>Prior to it, in my previous project, I was involved in building a product called the Compliance Management Reporting System (CMRS). The tech stack was .NET, SQL Server, XSLT, Biztalk, WCF, Winforms /WPF - basically it was all Microsoft stack. I started on the project as a senior developer and then became a track lead. Once that product was launched, I moved from India to London and joined the pre-sales team. I helped pitch the product to multiple financial institutions here and implemented it for them.</em></p><p><em>Outside of work, I enjoy running. Last month I ran the London Marathon. It was tough, but was an amazing experience to train for it and run alongside 40,000 runners.</em></p><p>I’m happy to dive deep into any of my experiences.</p></blockquote><p>The pitch was in no way perfect. But it was specifically tailored for the job I was applying for and also the interviewer’s profile.</p><blockquote><p><em>I applied for the role of Senior Solutions Architect, Microsoft Dev tools. The role was to help AWS customers/partners migrate and modernise Microsoft Workloads (like .NET applications and SQL Server) on AWS.</em></p></blockquote><blockquote><p><em>I looked up the interviewer on LinkedIn. Before joining AWS, they were working as Application Development Lead at one of the Microsoft consulting company and had written a book on cross-platform .NET.</em></p></blockquote><p>I didn’t have experience working with cloud/AWS at the time. My best approach was to leverage my strengths and highlight my experience developing applications on Microsoft workloads. As this was a customer-facing role, I discussed my pre-sales experience.</p><p>And it worked out pretty well…</p><p>Most of the technical questions were on .NET, SQL, application development, microservices, and CI/CD pipelines. In the behavioral question (yes, even in technical interviews, there are behavioral questions), I discussed a pre-sales experience with a major financial custodian.</p><p>It’s easy to understand that an introduction needs to be tailored to the job role, but should it be tailored to the interviewer’s background?</p><p>For example, in my case, the interviewer had a .NET background, so I doubled down on that and mentioned the tech stack. Now, let’s say the interviewer had been from a Java background. I would have focused more on design patterns and my architectural skills rather than the Microsoft tech stack.</p><p>If the interviewer held a managerial or leadership position or came from a business background, I would have emphasized my business acumen and stakeholder management. I wouldn’t focus as much on my technical abilities.</p><p>It’s about finding common ground with the interviewer so the discussion can focus on topics we both know. Yes, it may be tedious, but you need to research the role and the interviewer and tailor your elevator pitch accordingly.</p><p>Next, let’s dive into how to showcase behavioral skills in technical interviews…</p><p>Let me start this section with a personal anecdote.</p><p>In one of my technical interview rounds at AWS in 2019, I was asked, “What is an Idempotent API?”</p><p>My response was in 3 steps:</p><ol><li><p><strong>Answered the technical question asked upfront</strong></p></li></ol><blockquote><p>I explained what an Idempotent API is, showcasing my technical knowledge.</p></blockquote><ol start=\"2\"><li><p><strong>Shared my previous project where I implemented an idempotent API</strong></p></li></ol><blockquote><p>I showcased my actual hands-on work experience without the interviewer even asking me.</p></blockquote><ol start=\"3\"><li><p><strong>Explained my project experience in STAR format</strong></p></li></ol><p>[<em>I’ll cover STAR (Situation Task Action Result) format in the next section</em>]</p><blockquote><p>While explaining my project experience in STAR format, I also explained WHY the idempotent API was required in that scenario. I talked about how the APIs I built were reporting trades worth millions in real-time to regulators and the reason I had to implement them as idempotent.</p><p>This is where I showcased my behavioral skills. I demonstrated I understand the business impact of the technical solutions I build.</p></blockquote><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/common-behavioral-interview-questions?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><h4><strong>The Problem with Pure Technical Answers</strong></h4><p>Many candidates show off their technical knowledge in technical interviews, and most get the technical answers right.</p><p>Let’s say 10 people interview:</p><p>7 of them answered the technical questions correctly. You’re one of those 7. So why should the interviewer pick you?</p><p>How? By sharing your real-world experience and behavioral skills.</p><p>While technical answers showcase that you have knowledge, they don’t paint a complete picture of your ability to succeed in a role.</p><p>For example, all engineers know what an idempotent API is. But how many can connect it to their experience in an interview and share real-world examples to boost the interviewer’s confidence in their skills? You stand out from other candidates by showing your experience and behavioral skills while you answer technical questions.</p><p>This also ensures that your interviewer does not downlevel you.</p><p>Let’s look at a couple of common technical questions…</p><p>I’ll show you how to answer them in a way that also shows off your behavioral skills and experience.</p><h4><strong>Question: “What are microservices, and what are their advantages and disadvantages?”</strong></h4><p><strong>Purely Technical Approach</strong></p><blockquote><p><em>“Microservices are an architectural style where an application is built as a collection of small, independent services. The advantages include scalability, flexibility, and easier maintenance. Disadvantages include increased complexity and potential performance overhead due to network communication.”</em></p></blockquote><p>(This is just an example. You’ll have your own version of a technical answer with much more depth to it!)</p><p><strong>Behavioral Skills Showcase Approach</strong></p><p>After you provide the technical answer, add your personal experience to it.</p><blockquote><p><em>“In fact, in one of my previous projects when I was consulting for a manufacturing company in 2022, I led a team that modernized our e-commerce platform by transitioning from a monolith to microservices.</em></p><p><em>We decided to make this shift because our monolithic application was becoming increasingly difficult to maintain and scale. For instance, deploying even small changes required testing the entire application, leading to a release cycle of 6 weeks.</em></p><p><em>To begin the transition, I initiated and facilitated an event storming session with stakeholders from development, operations, and business teams. This collaborative approach helped us identify natural service boundaries and ensured buy-in from all departments.</em></p><p><em>We started by extracting the product catalog service, as it was relatively self-contained. We faced several challenges, such as increased operational complexity and data consistency issues. I saw these as opportunities for the team to learn and grow. We invested time in upskilling, bringing in external experts for workshops on distributed systems and organizing internal knowledge-sharing sessions.</em></p><p><em>I’m happy to dive deep more into my experience. I’ve seen firsthand in this project the advantages of microservices and the challenges that come along with it.”</em></p></blockquote><p>This response not only demonstrates technical knowledge but also showcases your experience and several behavioral skills:</p><ul><li><p>Leadership: Leading the modernization project</p></li><li><p>Communication: Facilitating sessions with various stakeholders</p></li><li><p>Problem-solving: Addressing challenges that arose during the transition</p></li><li><p>Learning mindset and adaptability: Learning and applying new technologies</p></li></ul><p>Now, let’s look into another question.</p><h4><strong>Question: “What factors would you consider when choosing between SQL and NoSQL databases?”</strong></h4><p><strong>Purely Technical Approach:</strong></p><blockquote><p><em>“When choosing between SQL and NoSQL databases, several factors come into play.</em></p><p><em>Data structures are a primary consideration, with SQL being ideal for structured, relational data, while NoSQL is better suited for unstructured or semi-structured data.</em></p><p><em>Scalability needs often favor NoSQL, which typically scales horizontally more easily.</em></p><p><em>SQL databases offer stronger ACID compliance and excel at complex queries involving joins and transactions. However, NoSQL databases provide greater schema flexibility, allowing for more dynamic data models.</em></p><p><em>Performance requirements are also crucial, as NoSQL can offer faster read/write speeds for certain use cases.</em></p><p><em>Data consistency needs should be evaluated, with SQL providing immediate consistency and some NoSQL databases offering eventual consistency.</em></p><p><em>The choice ultimately depends on the specific requirements and constraints of the project at hand.”</em></p></blockquote><p>This is a good answer and will probably make the cut. But as I mentioned, most candidates will be able to provide this level of answer. You need to strive to go above and beyond.</p><p><strong>Behavioral Skills Showcase Approach:</strong></p><p>I understand you cannot have work experience for every technical question asked in an interview. And that is absolutely fine. Complement the technical answer above with how you would approach such a scenario.</p><blockquote><p><em>“To understand the requirements and constraints, I would organize a requirements gathering session with various stakeholders like the development team, product managers and, if possible, end-users. During this session, I would ask key questions such as:</em></p></blockquote><ul><li><p><em>How structured is the data? Do we need a fixed schema or flexibility for evolving structures?</em></p></li><li><p><em>What are our scalability requirements? What are the expected read/write ratios?</em></p></li><li><p><em>Do we need strong consistency for all operations, or is eventual consistency acceptable for some data?</em></p></li><li><p><em>What are our typical query patterns? Do we need complex joins and transactions?</em></p></li><li><p><em>How frequently will our data model change?</em></p></li></ul><blockquote><p><em>Once we have these answers, I would analyze them in the context of ACID (Atomicity, Consistency, Isolation, Durability) properties typically associated with SQL databases, and BASE (Basically Available, Soft state, Eventually consistent) properties often seen in NoSQL systems.</em></p><p><em>I would also consider the CAP theorem (Consistency, Availability, Partition tolerance) which states that in a distributed system, you can only have two of these three guarantees.</em></p><p><em>And most modern systems often benefit from a polyglot persistence approach, using different databases for different purposes within the same application.</em></p><p><em>PostgreSQL for user accounts and financial transactions, where ACID properties were crucial. MongoDB for storing product catalogs with varying attributes. Redis for caching and real-time analytics</em></p><p><em>This decision cannot be made in isolation. I would consider trade-offs of each approach, challenge assumptions and provide alternative viewpoints.”</em></p></blockquote><p>This response shows several behavioral skills:</p><ul><li><p>Analytical thinking: Systematically considering various factors</p></li><li><p>Stakeholder management: Involving different teams in the decision-making process</p></li><li><p>Communication: Organizing and facilitating requirements gathering and review sessions</p></li><li><p>Decision-making: Weighing pros and cons to arrive at a solution</p></li></ul><p>By answering technical questions in a way that showcases both your technical knowledge and behavioral skills, you present yourself as a well-rounded candidate who can not only do the job but also work effectively within a team and contribute to the company culture.</p><p>Companies are looking for more than just technical expertise. They want employees who can communicate effectively, work collaboratively, adapt to changing circumstances, and drive innovation.</p><p>So, as you prepare for your next technical interview, reflect not just on your technical accomplishments, but also on how you’ve demonstrated these crucial behavioral skills in your work.</p><p>Now, let’s dive into understanding the STAR framework to prepare for your behavioral interviews…</p><p>If you’ve been preparing for job interviews, you’ve likely encountered the STAR format.</p><p>It’s a powerful framework for structuring responses to behavioral questions. However, many candidates use this technique incorrectly, resulting in weak, unconvincing answers.</p><p>In this section, I’ll cover how to avoid common pitfalls and craft compelling STAR responses that will impress your interviewers.</p><p>As I explain the STAR format with an example and then go through more examples in the upcoming sections, I will adopt different personas.</p><p>I’ll start with the persona of a Cloud Solutions Architect, as that’s my current role!</p><p>Let’s have a quick refresher of what STAR stands for:</p><ul><li><p>Situation: Context or background of your example</p></li><li><p>Task: Specific challenge or responsibility you faced</p></li><li><p>Action: Steps you took to address the task</p></li><li><p>Result: Outcomes of your actions</p></li></ul><p>Now, let’s examine each component, identify common mistakes, and learn how to do it right with an example…</p><h3><strong>Situation: Stop Being Vague</strong></h3><p>Situation sets the stage for your story.</p><p>It provides the context and background information necessary for the interviewer to understand the circumstances you were facing. When describing the situation, be specific about:</p><ul><li><p>Where you were working and what your role was</p></li><li><p>Relevant data/metrics to showcase the importance of the situation</p></li></ul><blockquote><p><em>“I was working as a Cloud Solutions Architect, and we had to move our mission-critical workloads to the cloud.”</em></p></blockquote><p>This situation lacks specificity and fails to set the stage effectively. It doesn’t give the interviewer any meaningful context.</p><blockquote><p><em>“I was working as a Senior Cloud Solutions Architect with a Fortune 500 manufacturing company. In Q1 2023, 80% of our mission-critical applications were running on aging on-premises infrastructure, causing frequent outages and limiting our ability to scale. Our CIO had set an aggressive goal to migrate 50% of these applications to the cloud within six months to improve reliability and reduce operational costs.”</em></p></blockquote><p>This approach works because it specifies the exact role and company, provides a clear timeframe, and offers relevant data and metrics that highlight the importance of the situation.</p><h3><strong>Task: Don’t Undersell the Challenge</strong></h3><p>Task describes the specific challenge, problem, or responsibility you were facing in a situation.</p><p>This component should clearly outline:</p><ul><li><p>What you needed to accomplish</p></li><li><p>Goals or objectives you were working towards</p></li><li><p>Urgency and importance of the task</p></li></ul><blockquote><p><em>“The task was to figure out how to move the applications to AWS within the given timeframe and make sure they worked properly.”</em></p></blockquote><p>This description undersells the complexity of the task and fails to convey its importance or urgency.</p><blockquote><p><em>“The task was to identify, prioritize and migrate critical applications to AWS within six months. This required assessing applications, designing a secure architecture, creating a migration plan, minimizing operational disruptions, ensuring high uptime, and reducing costs. The timelines were aggressive, as the urgency was high because our aging infrastructure was putting us at risk of major system failures.”</em></p></blockquote><p>This approach works because it breaks down the task into key components, emphasizes the urgency and importance of the challenge, and demonstrates the scope and complexity of what needs to be accomplished.</p><h3><strong>Action: Get Specific and Show Your Expertise</strong></h3><p>Action is the core of your response.</p><p>It details the steps you took to address the task or challenge. When describing your actions:</p><ul><li><p>Be specific about what you did. Use “I” statements to clarify your personal contributions.</p></li><li><p>Explain your thought process and decision-making</p></li><li><p>Highlight any skills or qualities you demonstrated</p></li></ul><blockquote><p><em>“I looked at our applications and decided to start the migration with our core ERP system as it was most critical. Then I set up the AWS accounts and worked with security, database, networking and other teams to migrate the application. We had to make some application architecture changes to make the apps work in the cloud.”</em></p></blockquote><p>This description is vague, lacks detail, and does not demonstrate any specific skills or expertise.</p><blockquote><p><em>“To begin, I led a cross-functional team in conducting a thorough analysis of our application portfolio. We considered factors such as business criticality, dependencies, and architectural complexity to gain a complete understanding of our existing infrastructure.</em></p><p><em>Based on this assessment, I took the ownership to lead the migration of our core ERP system, which was critical to our manufacturing operations. This migration was also crucial to the overall goal as it would serve as a blueprint for future migrations.</em></p><p><em>I designed a multi-tiered AWS architecture for this application, ensuring high availability and scalability. Security was a top priority, so I collaborated closely with our security team to implement a robust model tailored to the ERP system’s requirements. I worked with the project manager to create a comprehensive project plan, including a phased approach to migrate different modules of the ERP system.</em></p><p><em>To streamline the migration process and reduce manual errors, I developed CloudFormation templates and leveraged AWS Migration Hub for automation. This significantly reduced migration time and improved consistency. Throughout the process, I worked closely with our database team to ensure data integrity and with our networking team to establish secure connectivity between our on-premises systems and AWS.</em></p><p><em>Additionally, I conducted several dry runs and extensive testing to minimize potential disruptions to our manufacturing operations.”</em></p></blockquote><p>In the STAR framework, the Action section is where you should invest the most detail and time.</p><p>Detailing your actions, explaining your choices, and highlighting your technical and leadership capabilities builds a powerful story. It shows your impact and value.</p><h3><strong>Result: Quantify Your Impact</strong></h3><p>Result is the conclusion of your story.</p><p>It describes the outcome of your actions and their impact. When discussing results:</p><ul><li><p>Be specific about what was achieved using quantifiable metrics when possible</p></li><li><p>Explain the positive impact on the company, team, or project</p></li><li><p>Mention any lessons learned or personal growth</p></li></ul><blockquote><p><em>“We managed to move few applications to the cloud within the 6 months. The application is working better in the cloud and we overall reduced the cost of infrastructure of running these applications.”</em></p></blockquote><p>This result lacks specificity and demonstrates no significant impact or value.</p><blockquote><p><em>“We successfully migrated our core ERP system to AWS in four months. The system’s response times decreased by 40%, and we improved scalability, handling a 200% increase in concurrent users during peak periods. We also reduced infrastructure costs for this application by 30%.</em></p><p><em>It took us more time than anticipated, but we learned a lot along the way. Based on the learnings, I created a blueprint, best practices document and SOP for other teams to migrate their respective applications. Using these documents, different teams have migrated 24 more applications so far.</em></p><p><em>Personally, this project deepened my expertise in large-scale cloud migrations and gave me the opportunity to work with multiple stakeholders and cross-functional teams.”</em></p></blockquote><p>This approach works because it shows clear, measurable wins. It explains the good impact on various business areas and highlights your personal growth.</p><p>Now that you understand how to structure your behavioral answers using the STAR format, let’s explore the key themes you should focus on…</p><p>Behavioral interviews can feel overwhelming because of their open-ended nature and the sheer volume of potential questions.</p><p>To streamline your preparation for your next tech company behavioral interview, I’ve organized these questions into eight main themes:</p><h3><strong>1. Customer/User Focus Stories</strong></h3><p>These stories showcase your ability to prioritize and enhance the customer experience. They might include:</p><ul><li><p>Improving user experience</p></li><li><p>Handling customer complaints</p></li><li><p>Going above and beyond for clients</p></li></ul><p>: <em>“Give an example of a time when you had to deal with a challenging customer or user issue.”</em></p><p><strong>What your answer should address:</strong> Describe the problem and why it was difficult to resolve, explain how you understood the customer’s needs, outline the steps you took to address the issue, and discuss the final resolution and how you ensured customer satisfaction.</p><p>The interviewers would like to hear about your ability to deliver results and handle challenges. Think about stories like:</p><ul><li><p>Achievements and accomplishments</p></li><li><p>Overcoming significant challenges</p></li><li><p>Innovative solutions or improvements</p></li></ul><p><em>“Tell me about a time when you significantly exceeded expectations on a project or task.”</em></p><p><strong>What your answer should address:</strong> Explain what the initial goals were and how you went above and beyond, describe the strategies you used to achieve results, and discuss how you measured your success.</p><p>Interviewers are interested in how you handle adversity and grow from experiences. Prepare stories that showcase:</p><ul><li><p>Projects that didn’t meet expectations</p></li><li><p>Mistakes with significant consequences</p></li><li><p>Failures to anticipate major problems or challenges</p></li></ul><p><em>“Tell me about a time when you failed to meet an important goal or deadline at work.”</em></p><p><strong>What your answer should address:</strong> Describe the situation and the factors that contributed to the failure, explain how you handled the aftermath, and discuss the lessons you learned and how you’ve applied them since.</p><p>Interviewers want to assess your interpersonal skills and ability to navigate challenging situations. Prepare examples that showcase:</p><ul><li><p>Dealing with difficult colleagues or clients</p></li><li><p>Resolving team disagreements</p></li><li><p>Navigating workplace dynamics</p></li></ul><p><em>“Describe a situation where you had a conflict with a colleague or team member.”</em></p><p><strong>What your answer should address:</strong> Explain the source of the conflict and how you approached resolving it, describe the steps you took to maintain a professional relationship afterward, and discuss how this experience changed your approach to workplace conflicts.</p><h3><strong>5. Problem-Solving Stories</strong></h3><p>Interviewers aim to understand your analytical thinking and creative approach to challenges. Prepare examples that illustrate:</p><ul><li><p>Tackling complex challenges</p></li><li><p>Making decisions with limited information</p></li><li><p>Implementing process improvements</p></li></ul><p><em>“Give an example of a complex problem you encountered at work that required an innovative solution.”</em></p><p><strong>What your answer should address:</strong> Explain what made this problem particularly challenging, walk through your problem-solving process, describe how you implemented your solution, and discuss the result and how you measured its success.</p><h3><strong>6. Learning/Growth Mindset Stories</strong></h3><p>Interviewers look for examples of your adaptability and commitment to continuous improvement. Share examples that demonstrate:</p><ul><li><p>Learning new skills quickly</p></li><li><p>Handling change or uncertainty</p></li><li><p>Embracing feedback for personal improvement</p></li></ul><p><em>“Describe a time when you had to learn a completely new skill or technology that was crucial for your role or a project.”</em></p><p><strong>What your answer should address:</strong> Explain the situation and why this new skill was necessary, describe the challenges you faced and how you overcame them, and discuss how you applied this new knowledge and what the outcome was.</p><p>These anecdotes showcase your ability to guide, influence, and develop others:</p><ul><li><p>Motivating and inspiring team members</p></li><li><p>Navigating conflicts or difficult decisions</p></li><li><p>Developing and mentoring others</p></li></ul><p><em>“Tell me about a time when you had to lead a team through a challenging situation or project.”</em></p><p><strong>What your answer should address:</strong> Describe the context and the specific leadership challenges you faced, explain how you approached motivating your team and keeping them aligned towards the goal, and discuss the project outcome and how this experience shaped your leadership style.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/common-behavioral-interview-questions?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><h3><strong>8. Time Management Stories</strong></h3><p>Interviewers are looking to assess your ability to organize, prioritize, and deliver under pressure. Consider examples that highlight:</p><ul><li><p>Balancing multiple responsibilities</p></li></ul><p><em> “Describe a period when you had to manage multiple high-priority tasks simultaneously.”</em></p><p><strong>What your answer should address:</strong> Explain what the tasks were and why they were all critical, describe how you prioritized them and your time, discuss the tools or techniques you used to stay organized, and explain how successful you were in meeting your deadlines and what you would do differently if faced with a similar situation.</p><p>For each theme, prepare one or two well-developed stories using the STAR framework.</p><p>Know the underlying behavioral competencies you’re demonstrating with each story. Then you can adapt these stories to different questions you encounter. Also, map the stories to the core values of the company you are interviewing for.</p><blockquote><p><em>Want a free behavioral interview question bank with 40 questions in 8 themes? Subscribe to my newsletter, <a href=\"https://newsletter.bigtechcareers.com/\">Big Tech Careers</a>, and I’ll send it in your welcome kit.</em></p></blockquote><p>Now, let’s examine a strong response from the Learning/Growth Mindset category.</p><p>Many companies value this theme. It shows how quickly you can learn new skills and adapt in a fast-paced environment…</p>","contentLength":39958,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/9cbd9776-19e8-49bd-b7ca-da811d09259e_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"I struggled with system design until I learned these 114 concepts","url":"https://newsletter.systemdesign.one/p/system-design-concepts","date":1770472735,"author":"Neo Kim","guid":37,"unread":true,"content":"<p>Some of these are foundational, and some are quite advanced. ALL of them are super useful to software engineers building scalable systems.</p><p>Curious to know how many were new to you:</p><ol><li><p>Latency vs Throughput vs Bandwidth,</p></li><li><p>Client-Server Architecture,</p></li><li><p>Load Balancing Algorithms,</p></li><li><p>Authentication vs Authorization,</p></li><li><p>Session-based vs Token-based Authentication,</p></li><li><p>OAuth/OAuth2/OpenID Connect,</p></li><li><p>High Availability vs Fault Tolerance,</p></li><li><p>Microservices Architecture,</p></li><li><p>Event-Driven Architecture,</p></li><li><p>Synchronous vs Asynchronous Communication.</p></li></ol><p>(…and many more in parts 2 &amp; 3!)</p><ul><li><p>What it is &amp; how it works--in simple words</p></li><li><p>A real-world analogy (if I found one)</p></li></ul><p> is the only AI code review tool that reflects your team’s standards and judgment, delivering thoughtful feedback that feels like it came from your best engineer.</p><blockquote><p>Scalability is the system’s ability to handle increased load without breaking.</p></blockquote><p>Vertical scaling means adding more power to your existing machine, such as a larger CPU, more RAM, or a faster disk. Horizontal scaling means adding more machines to distribute the work across multiple servers.</p><p>When traffic grows, vertical scaling upgrades a single machine, while horizontal scaling adds more machines to work together.</p><p>Vertical scaling is like upgrading from a small restaurant kitchen to a bigger one with industrial-grade equipment.</p><p>Horizontal scaling is like opening multiple restaurant locations instead of expanding one location.</p><p>Vertical scaling is simpler but hits a ceiling. You can only make one machine so powerful, and it becomes a single point of failure.</p><p>Horizontal scaling can grow infinitely, but it introduces complexity in coordinating multiple machines and keeping data consistent across them.</p><p>Use vertical scaling when you’re starting out or when your application isn’t designed for distribution. Switch to horizontal scaling when you need to handle millions of users, want high availability, or when vertical scaling becomes very expensive.</p><blockquote><p>Availability measures the percentage of time your system is operational &amp; accessible to users.</p></blockquote><p>It’s typically expressed as “nines,” where 99.9% corresponds to about 8.76 hours of downtime per year, while 99.99% corresponds to only 52.6 minutes. Availability is achieved through redundancy, failover mechanisms, and the elimination of single points of failure.</p><p>Availability is like a 24/7 convenience store.</p><p>A store with 99% availability would be closed for 3.65 days per year. A store with 99.999% availability would only be closed for 5 minutes per year.</p><p>Higher availability requires more resources, such as redundant servers, load balancers, complex failover systems, and multi-region deployments. Each additional “nine” gets exponentially more expensive.</p><p>You might also sacrifice consistency for availability (CAP theorem).</p><p>Customer-facing systems, e-commerce platforms, payment processing, or any service where downtime directly costs money or erodes user trust.</p><p>Yet internal tools or batch processing jobs can tolerate lower availability.</p><blockquote><p>Reliability is your system’s ability to perform its intended function correctly over time, even when things go wrong.</p></blockquote><p>A reliable system handles failures gracefully. If a server crashes, requests get rerouted. If data gets corrupted, backups restore it. Reliability includes fault tolerance, data durability, and consistent behavior under various conditions.</p><p>Reliability is like a car that starts every morning, even in winter…</p><p>It doesn’t just work 99% of the time--it safely takes you to the right destination. A highly available but unreliable system is like a taxi that always shows up but sometimes takes you to the wrong address.</p><p>Building reliable systems requires extensive testing, monitoring, error handling, retry logic, and redundancy. This increases development time &amp; operational complexity.</p><p>Prioritize reliability for financial transactions, healthcare systems, data pipelines where data loss is unacceptable, or any system where incorrect behavior is worse than being temporarily unavailable.</p><p>Remember, a personal blog doesn’t need the same reliability as a hospital patient monitoring system.</p><h2><strong>4. Latency vs Throughput vs Bandwidth</strong></h2><blockquote><p>Latency is the time it takes for a single request to travel from client to server and back, measured in milliseconds.</p><p>Throughput is how many requests your system can handle per unit of time, like requests per second.</p><p>Bandwidth is the maximum amount of data that can be transferred over a network connection in a given time, measured in Mbps or Gbps.</p></blockquote><p>These three metrics are related,,, but measure different aspects of performance.</p><ul><li><p>Latency is how long it takes one car to drive from point A to B.</p></li><li><p>Throughput is the number of cars that can complete the journey per hour.</p></li><li><p>Bandwidth is how many lanes a highway has.</p></li></ul><p>You can have an 8-lane highway with high latency over long distances, or a 2-lane road with low latency over short distances.</p><p>Optimizing for one doesn’t automatically improve the others…</p><p>You can increase throughput by adding more servers, but it won’t reduce latency. You can reduce latency by caching or using a CDN, but it doesn’t increase throughput.</p><p>Increasing bandwidth helps with large data transfers but doesn’t reduce latency.</p><p>Focus on low latency for real-time applications such as gaming, video calls, and trading platforms. While optimize throughput for high-traffic APIs and web services. And prioritize bandwidth for video streaming, file transfers, and data-intensive applications.</p><p>Most production systems need to balance all three…</p><h2><strong>5. Client-Server Architecture</strong></h2><blockquote><p>A model where clients, such as users’ devices, browsers, or mobile apps, send requests to servers, which process those requests and send back responses.</p></blockquote><p>The server hosts the business logic, databases, and resources, while clients provide the user interface. This separation allows multiple clients to access the same server resources simultaneously.</p><p>Client-server is like a restaurant: you sit at a table, place your order with a waiter, and the waiter takes it to the kitchen.</p><p>The kitchen prepares your food and sends it back through the waiter. You don’t go into the kitchen yourself…there’s a clear separation of responsibilities.</p><p>This architecture centralizes control and data management, making it easier to maintain and secure. Yet the server could become a bottleneck and a single point of failure. If the server goes down, all clients lose access.</p><p>The server also needs to scale to handle increasing numbers of clients.</p><p>Web applications, mobile apps, email systems, and most modern software.</p><p>It’s the foundation of how the internet works…Consider alternatives such as peer-to-peer file sharing or edge computing when you need to reduce dependence on central servers.</p><blockquote><p>A database is an organized collection of structured data stored electronically and managed by a Database Management System (DBMS).</p></blockquote><p>Databases allow you to create, read, update, and delete data efficiently.</p><p>They handle concurrent access, ensure data integrity through transactions with ACID properties, and provide query languages to retrieve data. Databases can be relational, with tables organized as rows and columns, or non-relational, such as documents, key-value pairs, or graphs.</p><p>A database is like a highly organized library with a sophisticated cataloging system.</p><p>Instead of wandering through aisles hoping to find a book, you use the catalog to locate what you need instantly. The librarian ensures books don’t get lost, handles multiple people checking out books simultaneously, and maintains the organization system.</p><p>Databases provide powerful data management but introduce complexity:</p><p>They require careful schema design, indexing strategies, backup procedures, and monitoring. Poorly designed databases become bottlenecks. Plus, slow queries can bring down your entire application.</p><p>Different database types optimize for different use cases…so choosing the wrong one can ‘hurt’ performance.</p><p>Use databases whenever you need to persist data beyond application restarts, handle concurrent users accessing shared data, maintain data relationships, or query data in flexible ways.</p><p>Almost every production application needs a database…the question is which type fits your use case.</p><blockquote><p>SQL databases organize data in tables with predefined schemas, using rows and columns.</p></blockquote><p>They support complex queries, joins across tables, and ACID transactions. Examples: PostgreSQL &amp; MySQL.</p><blockquote><p>NoSQL databases use flexible schemas and store data as documents, key-value pairs, wide columns, or graphs.</p></blockquote><p>They prioritize scalability and flexibility over strict consistency. Examples: MongoDB, Redis, Cassandra, and Neo4j.</p><p>SQL is like a spreadsheet with strict columns…</p><p>Everyone must follow the same structure, but you can easily combine data from different sheets using formulas.</p><p>NoSQL is like a filing cabinet where each folder can contain different types of documents in different formats…more flexible, but harder to analyze across folders.</p><p>SQL databases offer strong consistency, complex querying, and enforced data integrity. They can scale vertically and horizontally, but distributing data across many machines is often complex because of joins and transactional guarantees.</p><p>While NoSQL databases are built to scale horizontally and handle flexible data models. They often trade strong consistency or full relational features for scale and high availability.</p><p>Most companies use both SQL for transactional data and NoSQL for flexibility and scalability.</p><ul><li><p>Use SQL for financial systems, e-commerce orders, user authentication, or anywhere you need ACID guarantees and complex queries across related data.</p></li><li><p>Use NoSQL for user profiles, product catalogs, real-time analytics, session storage, or when your schema changes frequently.</p></li></ul><p><em><strong>Reminder: this is a teaser of the subscriber-only post, exclusive to my golden members.</strong></em></p><p>When you upgrade, you’ll get:</p><ul><li><p><strong>Full access to system design case studies</strong></p></li><li><p>FREE access to (coming) Design, Build, Scale newsletter series</p></li><li><p><strong>FREE access to (coming) popular interview question breakdowns</strong></p></li></ul><p>Get 10x the results you currently get with 1/10th the time, energy &amp; effort.</p>","contentLength":10057,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/e5da46f5-2df8-48bd-896b-4af2e5ab5b42_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"I struggled to code with AI until I learned this workflow","url":"https://newsletter.systemdesign.one/p/ai-coding-workflow","date":1770031839,"author":"Neo Kim","guid":36,"unread":true,"content":"<blockquote><p>Everyone talks about using AI to write code like it’s a vending machine:</p><p><em>“Paste your problem, get a working solution.”</em></p></blockquote><p>The first time I tried it, I learned the hard way that this is not how it works in real projects…</p><p>The model would confidently suggest code that called functions that didn’t exist, assumed libraries we weren’t using, or skipped constraints that felt obvious to me. The output looked polished.</p><p>The moment I ran it… It fell apart.</p><p>After enough trial and error, I stopped trying to “prompt better” and started working differently. What finally made AI useful wasn’t a magic tool or a clever prompt. It was a simple loop that kept the model on a short leash and kept you in the driver’s seat:</p><p>This newsletter breaks that loop down step by step.</p><p>It’s written for software engineers who are new to AI coding tools and want a practical starting point: not a tour of every product on the market, but a repeatable method you can use tomorrow.</p><p>AI works best as an iterative loop, not a one-shot request. You steer. The model fills in the gaps. And because it does less guessing, you spend less time cleaning up confident mistakes.</p><p>I’m happy to partner with  on this newsletter. Code reviews usually delay feature deliveries and overload reviewers. And I genuinely believe CodeRabbit solves this problem.</p><p>He focuses on making AI more accessible by helping people learn practical AI skills for the industry alongside 500k+ fellow learners.</p><p>If you’re new to using AI for coding, this is the set of habits that prevents most pain.</p><ul><li><p><strong>Treat AI output like a draft, not an answer.</strong> Models can sound certain while being completely wrong, so anything that matters still gets reviewed and verified.</p></li><li><p><strong>Start with context, the way you’d brief a teammate.</strong> If you don’t share constraints, library versions, project rules, and intended behavior, the model will ‘happily’ invent them for you.</p></li><li><p><strong>Ask for a plan before you ask for code.</strong> Plans are cheap to change. Code is expensive to unwind. I’ll usually approve the approach first, then ask for small, step-by-step changes.</p></li><li><p><strong>Use reviews and tests as a safety net.</strong> I still do a normal pull request review and rely on tests to verify behavior and catch edge cases.</p></li></ul><p>Before we dive in, here’s the small vocabulary I’ll use throughout.</p><p>It’s not exhaustive; it’s just enough to keep the rest of the article readable:</p><ul><li><p> (e.g., Cursor, VS Code + GitHub Copilot) is a code editor with AI built in. It can suggest completions, refactor functions, and generate code using your project files as context.</p></li><li><p> (e.g., ChatGPT, Claude, or Gemini) is a conversational AI you interact with in plain language. It’s useful when you’re still figuring out what to do: brainstorming approaches, explaining an error, comparing trade-offs, or sanity-checking a design before you write code.</p></li><li><p> tools (e.g., <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a>) automatically review pull requests using AI, posting summaries and line-by-line suggestions.</p></li><li><p> (e.g., Perplexity) combines chat with web search. It’s what you reach for when you need to verify that a suggested API call is real, that a library feature exists in the version you’re using, or that you’re not about to copy-paste something that expired two releases ago.</p></li></ul><p>Before the workflow, it helps to be honest about what AI coding assistants are and aren’t.</p><p>They’re fantastic when the problem is well-scoped and sitting right in front of them. They’re unreliable the moment you assume they “know” what you didn’t explicitly provide. The workflow is basically a way to stay in the first zone and avoid the second.</p><p>When you give clear requirements, AI is great at drafting functions, refactoring code, scaffolding tests, and talking through error messages.</p><p>But it has a hard boundary: it only knows what it can see in the current context. It doesn’t remember your last chat; it doesn’t know your architecture or conventions, and it won’t reliably warn you when it’s guessing. It just keeps going confidently.</p><p>I’ve seen AI call library functions that don’t exist, use syntax from the wrong version, and ignore constraints I assumed were obvious. The pattern was always the same: the AI didn’t know what I hadn’t told it, so it filled the gaps by inventing something plausible.</p><p>Once I understood this, three principles shaped how I work:</p><p><strong>1. Give more context than you think you need.</strong> Just like I’d brief a colleague who just joined the project, I brief the AI every time. If I don’t share the details, it invents them.</p><p><strong>2. Guide it with specific steps.</strong> AI struggles with “build me a web app,” but does well with “add input validation for these fields, return a clear error message, and write a test that proves invalid input is rejected.” The more specific my request, the better the output.</p><p><strong>3. If it matters, verify it.</strong> Whenever the AI produces security-sensitive logic, a database migration, or an algorithm that must be correct, I review it myself and add tests that prove the behavior.</p><blockquote><p><em>A good way to hold all of this in your head is:</em></p><p>AI is a smart teammate who joined your project five minutes ago.</p><p>They can write quickly, but they don’t know your architecture, your conventions, or your constraints unless you tell them.</p><p>That’s why the mistakes look so predictable: the model isn’t “being dumb,” it’s filling in gaps you didn’t realise you left open.</p></blockquote><p>Once I started seeing it that way, the fix wasn’t a better one-shot prompt.</p><p>It was a repeatable loop that forced me to brief the model, force clarity early, and keep changes small enough to verify.</p><p>I’m not sure if you're aware of this…</p><p>When you open a pull request,  can generate a summary of code changes for the reviewer. It helps them quickly understand complex changes and assess the impact on the codebase.</p><p>Speed up the code review process.</p><p>The loop is the same whether I’m fixing a bug, adding a feature, or cleaning up a messy module.</p><p>It keeps the AI from freelancing, and it keeps me from treating “code that looks plausible” as “code that’s ready to ship.”</p><ol><li><p> I share project background, constraints, and the relevant code so the AI isn’t guessing.</p></li><li><p> I ask for a strategy before any code gets written.</p></li><li><p> I generate or edit code one step at a time, so changes stay small and reviewable.</p></li><li><p> I carefully check the output and often use AI-assisted pull request reviews as a second set of eyes.</p></li><li><p> I run tests, and I’ll often have AI generate new tests that lock in the intended behavior.</p></li><li><p> I debug failures, refine the request, and repeat until the change is solid.</p></li></ol><p>I use different tools at different points in the loop.</p><p>Each one is good at a specific job:</p><ul><li><p>An editor is good at working inside a repo,</p></li><li><p>A chat model is good at thinking in plain language,</p></li><li><p>And review/testing tools are good at catching things I’d miss when I’m tired.</p></li></ul><p>The rest of this newsletter breaks down each step.</p><blockquote><p>The most important step is the first one:</p><p>If the model is guessing about your setup, everything downstream becomes cleanup. So the workflow starts with context.</p></blockquote><p>Most AI mistakes in code have the same root cause.</p><p>The model is guessing in a vacuum. Someone pastes a function, types “fix this,” and acts surprised when the suggestion ignores half the system.</p><p> is the fastest way to make the model hallucinate…</p><p>Without a project background and constraints, it has no choice but to fill gaps with whatever sounds right: ‘functions that don’t exist, syntax from the wrong version, solutions that break conventions elsewhere in the repo’.</p><blockquote><p>So, for anything that is not small, I flip the default: documentation and rules go first. Code goes second.</p></blockquote><p>This is easiest with an AI editor that can automatically pull in files.</p><p>I use Cursor, which lets me highlight code, pull in other files from my project, and ask the AI to do specific work with all of that as context. The pleasant part is I can swap models on the fly: a fast one for quick edits, a heavier reasoning model when I need to solve a tricky bug.</p><p>VS Code with Copilot or Claude Code offers similar features if you prefer to stay in that ecosystem.</p><p>When a task is even , I load three kinds of context:</p><p>I keep an updated README for each project and start most AI sessions by attaching it with a simple opener:</p><pre><code>Read the README below to understand the project. Then I will give you a specific task.</code></pre><p>If the change touches something sensitive (like payments), I include the key files in that first message too. By the time I describe the change, the assistant has already seen the neighborhood.</p><p>I keep a rules file (sometimes called  or ) that bundles project scope, coding style, version constraints (for example, “this service runs on ”), and a few hard rules (“never call this external API in development,” “all dates must be UTC”).</p><p>Some tools support “rules” or “custom instructions” that help me avoid repeating myself in every session.</p><h4><strong>3. Relevant source and signals</strong></h4><p>For bugs or features, I paste the function or file involved along with stack traces or logs.</p><p>A single error line is like a screenshot of one pixel. The assistant needs more than that if I want real reasoning instead of optimistic guessing.</p><p><strong>Here’s a reusable prompt pattern:</strong></p><pre><code>Read @README to understand the project scope, architecture, and constraints.\n\nRead @AGENTS.md to learn the coding style, rules, and constraints for this codebase.\n\nThen read @main.py, @business_logic_1.py, and @business_logic_2.py carefully.\n\nYour task is to update @business_logic_2.py to implement the following changes:\n\n1. &lt;change 1&gt;\n2. &lt;change 2&gt;\n3. &lt;change 3&gt;\n\nFollow the conventions in the README and AGENTS file.\n\nDo not modify other files unless strictly necessary and explain any extra changes you make.</code></pre><p>The structure stays the same every time: context, then rules, then a precise task.</p><p>I swap out the filenames and the change list, but the pattern holds.</p><p>One thing I learned the hard way: <em>more text isn’t always better</em>. The best briefings are short and focused. They explain what the project is for, how the main pieces fit together, and which rules actually matter. If I notice I’m pasting more than a human would reasonably read before starting work, I cut it down.</p><p>One final detail that matters: context should be … not dumped.</p><p>The best briefings are short and decisive, enough to prevent guessing, but not so much that the model loses the signal. If I’m pasting more than a human would reasonably read before starting, I cut it down.</p><h3><strong>Step 2: Plan Before You Code</strong></h3><blockquote><p>Context answers “where am I?”</p><p>It doesn’t answer “what should I build?”</p></blockquote><p>That’s where things usually go sideways.</p><p>If you let AI write code immediately, it often picks a strange approach, optimizes the wrong thing, or quietly ignores constraints.</p><p>I’ve learned to force a two-step process: </p><p>I usually do the planning step in a chat model like Claude, ChatGPT, or Gemini. ChatGPT works well when the problem is fuzzy, and I need structured thinking. Once the design feels reasonable, I switch to an AI editor like Cursor or Claude Code in VS Code, where the implementation happens with the repo open.</p><p><strong>First: Ask for a plan only</strong></p><p>For any non-trivial change, I first describe the feature or bug in plain language. That initial exchange is just about getting the idea into a workable shape:</p><pre><code>Here is the feature I want to build and some context.\n\nHelp me design it.\n\nWhat needs to change?\n\nWhich modules are involved?\n\nWhat are the main steps?</code></pre><p>The key is to stop the AI from jumping straight into code. I’ll often say explicitly, “Do not write any code until I say approved.”</p><p><strong>Then: Approve and implement in small steps</strong></p><p>Once the plan looks reasonable, I approve it and ask the AI to implement one step at a time.</p><p>This is where I usually switch from a chat model to an AI editor like Cursor or VS Code with Copilot, since the implementation happens inside the actual codebase. For each step, I ask the AI to explain what it’s about to change and propose the code for that step only.</p><p>Small steps are easier to review and easier to undo if something goes wrong.</p><p><strong>Here’s a prompt template I reuse:</strong></p><pre><code>You are a senior engineer helping me with a new change.\n\nFirst, read the description of the feature or bug:\n&lt;insert feature or bug description and any relevant context&gt;\n\nStep 1 — Plan only:\n\n- Think step by step and outline a clear plan.\n- List the main steps you would take.\n- Call out important decisions or tradeoffs.\n- Mention edge cases we should keep in mind.\n\nStop after the plan. Do not write any code until I say “approved.”\n\n\nStep 2 — Implement:\n\nOnce I say “approved,” implement the plan one step at a time:\n\n- For each step, explain what you are about to change.\n- Propose the code changes for that step only.\n- Write tests for that step where it makes sense.</code></pre><p>If the AI recommends a library or function I’ve never seen, I’ll verify it actually exists using a search assistant or official docs. Models sometimes hallucinate APIs that sound plausible but don’t exist.</p><p>This pattern is especially useful when I’m working in a new stack or unfamiliar codebase. Instead of reading docs for hours, I ask the AI to explain the stack, sketch a design, and then help me implement it. The AI explains before it writes, so I learn as I go.</p><p>It also helps when a change touches multiple parts of the system, since a plan lets me see the full scope before I make edits everywhere.</p><p>Same with subtle bugs I don’t fully understand. For a slow database query, instead of asking “make this faster,” I ask the AI to reason through why it might be slow and what options exist. Only after that reasoning do I ask for the actual fix.</p><p>Fixing a plan is cheaper than fixing a pile of code. The “approved” step forces me to agree with the approach before the AI starts typing.</p><h3><strong>Step 3: Lightweight Multi-Agent Coding</strong></h3><p>Once I got comfortable with planning before coding, I started using a simple trick that makes AI output more reliable: <em>I split the work into roles</em>.</p><p>This isn’t a complex ‘agent system.’ Most of the time, it’s the same AI model, just prompted differently for each job.</p><p>Sometimes I use different models for different roles: </p><ul><li><p>Claude or ChatGPT for the Planner role (where reasoning matters),</p></li><li><p>Then, a faster model for the Implementer role (where the task is already well-defined and speed matters more).</p></li></ul><p>In Cursor, I can switch models mid-task, which makes this easy.</p><p> Breaks down the task into steps and calls out edge cases. (This is what we covered in Step 2.)</p><p> Writes code strictly based on the approved plan. I prompt it with something like: <code>“Follow the approved plan. Change only the files I list. Keep the change small. If something is unclear, ask before coding.”</code></p><p> Writes tests and edge cases. I prompt it with: <code>“Write a unit test for the happy path. Write at least two edge case tests. If this were a bug fix, write a regression test that would fail before the fix.”</code></p><p> Summarizes what changed and why. I prompt it with: <code>“Summarize changes by file. Explain the logic in plain language. List what could break and how the tests cover it.”</code></p><p>Big prompts encourage messy answers.</p><p>When I ask the AI to plan, implement, test, and explain all at once, the output gets tangled. When I split roles, I get a checklist, then a small change, then tests, then an explanation. Each piece is easier to review.</p><p>Long chats also drift. After enough back-and-forth, the AI forgets earlier context or recycles bad ideas. Short, focused threads stay sharp.</p><blockquote><p><strong>Practical tip: summarise between steps.</strong></p></blockquote><p>When I finish one role, I ask for a short summary before moving to the next. Then I paste that summary into the next prompt. This keeps each step focused and prevents context from getting lost across a long conversation.</p><h3><strong>Step 4: Review the Output</strong></h3><p>AI-generated code needs extra review.</p><p>The model is confident even when it’s wrong, and subtle bugs hide easily in code that looks plausible. This is where I add a layer of automated review before merging anything.</p><p>One way to do this is with an AI code review tool like <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a>, which integrates with GitHub and GitLab. When you open a pull request, it automatically reviews the diff and posts comments directly in the PR thread. This kind of tool catches issues that slip past manual reviews, especially when you’re tired or rushing.</p><p>A tool like <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a> typically gives you two things:</p><ul><li><p>First, a summary of what changed, often with a file-by-file walkthrough. This helps confirm the pull request matches your intent before looking at the details.</p></li><li><p>Second, line-by-line comments with suggestions. These often flag missing error handling, edge cases, potential security issues, and logic bugs like off-by-one errors. It can also run the code through linters and security analyzers during the review.</p></li></ul><p>When you push more commits to the same PR, it reviews the new changes incrementally rather than repeating the entire review.</p><p><strong>An example pull request flow</strong></p><p>Here’s what a typical flow looks like:</p><ol><li><p>Open a PR with a small, focused change.</p></li><li><p>The AI review tool automatically posts comments.</p></li><li><p>Read the comments, fix real issues, and reply to anything that’s noise or missing context.</p></li><li><p>Then do a final human pass before merging.</p></li></ol><p>Not every comment requires action. Sort them into two buckets:</p><ul><li><p> logic errors, missing error handling, security issues</p></li><li><p> style preferences, naming suggestions, alternative approaches</p></li></ul><blockquote><p>If you’re unsure whether something matters, ask yourself: </p><ul><li><p>Would this likely cause a bug?</p></li><li><p>Or would this confuse someone reading the code later?</p></li></ul><p>If yes to either, fix it or add a test.</p></blockquote><p>AI review tools have the same limitations as other AI tools.</p><p>They sometimes flag things that aren’t problems or suggest patterns that don’t match the codebase. The goal is to catch obvious problems early, not to treat every comment as a mandate.</p><p>Always do a final human pass before merging.</p><p>Tests are part of the flow, not a later chore.</p><p>After any change that isn’t small, I ask for tests immediately. I don’t wait until the feature is complete. Tests serve both as verification and as documentation. If the AI can’t write a sensible test for the code it just produced, that’s often a sign the code itself is unclear…</p><p>I request different tests depending on the situation.</p><p>For new functions, I ask for unit tests that cover the happy path and edge cases. When I used AI to build a React component in a stack I barely knew, my immediate follow-up was, “Now write unit tests for this component.” The tests showed me what the component was supposed to do and how it handled different inputs.</p><p>For bug fixes, I ask for a regression test that would have failed before the fix. This proves the fix works and helps prevent the bug from returning later. For changes that touch multiple components or an endpoint, I ask for one minimal integration or end-to-end test.</p><p>I paste a short feature description and ask for a realistic user flow and a few edge cases.</p><pre><code>Write unit tests for this function.\n\nCover the happy path and at least two edge cases.</code></pre><pre><code>Write a regression test for this bug.\n\nThe test should fail before the fix and pass after.</code></pre><p><strong>For integration or end-to-end tests:</strong></p><pre><code>Write a minimal integration test for this feature.\n\nInclude one realistic user flow and a few edge cases.</code></pre><p><strong>For reviewing existing tests:</strong></p><pre><code>Review these tests.\n\nAre there obvious edge cases missing or any weak assertions?</code></pre><p>When I first started using AI for code, I would generate a function and move on.</p><p>Tests came later, if at all. Bugs shipped. And I didn’t always understand what the code was doing. Now I ask for tests right after the code. Reading the test often teaches me more than reading the function. It shows the inputs, the expected outputs, and the edge cases the code is supposed to handle.</p><p>If the generated test doesn’t make sense, I treat that as a signal. Either the code is unclear, or my prompt was incomplete. Either way, I go back before moving forward.</p><h3><strong>Step 6: Debug and Iterate</strong></h3><p>When something breaks… I don’t just paste an error and hope.</p><p>I give the model the same information I’d give a colleague: the error, the function, and enough context to reason through the problem.</p><p>A single error line is rarely enough. The model needs more than that to produce a useful diagnosis.</p><ul><li><p>Error message or stack trace.</p></li><li><p>Function where the error occurs.</p></li><li><p>Relevant surrounding code or types.</p></li><li><p>What I expected to happen and what actually happened.</p></li></ul><p>I avoid pasting only the error with no code, dumping an entire file without pointing to the relevant section, or just saying “it doesn’t work” without describing the failure.</p><p><strong>The prompt I use for debugging </strong>(I usually ask for both the explanation and the fix in one request):</p><pre><code>Here is the function and the error message.\n\nExplain why this is happening.\n\nThen rewrite the function using best practices, while keeping it efficient and readable.</code></pre><p>Asking for both gives me a diagnosis and a fix in one shot. It also helps me learn what went wrong, not just how to patch it.</p><p>If a fix doesn’t work and I keep saying “try again” in the same thread, the suggestions usually get worse. The model circles the same wrong idea with slightly different words.</p><blockquote><p>My rule: if I’ve asked twice and the answers are getting repetitive or worse, I stop.</p><p>I start a fresh chat, restate the problem with better context, and narrow the question.</p></blockquote><p>For example, instead of “fix this function,” I ask, “under what conditions could this variable be null here?” Fresh context plus a smaller question beats a tired thread most of the time.</p><p>Sometimes I realize I don’t understand the problem well enough to evaluate the fix. When that happens, I stop asking for code and start asking for an explanation:</p><pre><code>Do not fix anything yet.\n\nExplain what this function does, step by step.\n\nThen list the most likely failure cases.</code></pre><p>Once I understand the logic, I go back to asking for a targeted fix.</p><p>This avoids the loop of accepting fixes I don’t understand and hoping one of them works.</p><p>brings instant code reviews directly to your terminal, seamlessly integrating with Claude Code, Cursor CLI, and other AI coding agents. While they generate code, CodeRabbit ensures it’s production-ready - catching bugs, security issues, and AI hallucinations before they hit your codebase.</p><h2><strong>Common Failure Modes and Guardrails</strong></h2><p>After enough cycles, I started noticing the same failures repeating.</p><p>Here’s a short checklist I keep in mind:</p><h4><strong>Context drift in long chats</strong></h4><p>Long conversations cause the model to forget earlier decisions.</p><p>The fix: keep conversations short and scoped. One chat for design, one for part A, one for part B. When a thread feels messy, ask the model to summarize where you are, then start a fresh chat with that summary at the top.</p><p>Models are trained on data up to a certain point.</p><p>They sometimes write code for an older version of a library or generate methods that don’t exist. For anything new or fast-moving, I assume the suggestion might be wrong and verify against official docs. I also ask the model to state its assumptions: “Which version are you assuming?”</p><p>If the answer doesn’t match my setup, I rewrite it myself.</p><h4><strong>Off-rails debugging loops</strong></h4><p>Once a model gets stuck on a bad idea, it tends to dig deeper. It proposes variations of the same broken fix, sometimes reintroducing bugs from earlier attempts.</p><p>AI rarely produces well-structured code by default.</p><p>It’s good at “something that runs,” less good at “something I’ll want to maintain in three months.”</p><p>I fix this by baking quality into the request: ask for tests, ask for a summary of what changed and why, and nudge toward structure (“refactor this into smaller functions,” “follow the pattern in file X”).</p><p>This one has nothing to do with the model and everything to do with me.</p><p>If I let AI handle every decision, my own instincts start to dull. I push back by keeping important decisions human-owned, occasionally doing small tasks without AI, and asking the model to teach as well as do: explain its reasoning, compare approaches, and talk through trade-offs.</p><p>The goal is not just “ship faster” but “ship faster and understand what I shipped.”</p><p>The workflow I use comes back to a simple loop:</p><pre><code><strong>Context → Plan → Code → Review → Test → Iterate</strong></code></pre><p>I give the model enough context to see the real problem.</p><ul><li><p>I ask it to plan before writing code.</p></li><li><p>I generate and edit in small steps.</p></li><li><p>I review the output, often with AI-assisted tools.</p></li><li><p>I ask for tests right away.</p></li></ul><p>And when something breaks, I debug, refine, and repeat until it works.</p><p>Tools and models will change. Pricing will change. New products will appear. What survives is your method: how you give context, how you break work into steps, when to use a model, and when to rely on yourself.</p><p>If this newsletter did its job, you now have a clearer picture of what coding with AI looks like in practice.</p><p>Some days it’s a sprint… Some days it’s a wrestling match. But it has changed how I work. I ship features I wouldn’t have attempted before, and I feel less stuck when learning a new stack or working through an unfamiliar codebase.</p><p>The goal is not just to ship faster, but to ship faster and understand what I shipped.</p><p>Anyway, if you want to catch bugs, security flaws, and performance issues asyou write code… try <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a>.</p><p>It brings real-time, AI code reviews straight into VS Code, Cursor, and Windsurf.</p><p>I launched  (newsletter series exclusive to PAID subscribers).</p><p>When you upgrade, you’ll get:</p><ul><li><p><strong>High-level architecture of real-world systems.</strong></p></li><li><p>Deep dive into how popular real-world systems actually work.</p></li><li><p><strong>How real-world systems handle scale, reliability, and performance.</strong></p></li><li><p>10x the results you currently get with 1/10th of your time, energy, and effort.</p></li></ul><h4>🚨 Guest Authors Wanted: System Design &amp; AI Engineering</h4><ul><li><p>You’ll get exposure to 200,000+ tech audience.</p></li><li><p>Along with hands-on support throughout the review &amp; editing process.</p></li></ul><p>Reply to this email with links to your prior work and a brief note on topics you’d like to write about.</p><p><strong>Want to reach 200K+ tech professionals at scale? </strong>📰</p><p>Thank you for supporting this newsletter.</p><p>You are now 200,001+ readers strong, very close to 201k. Let’s try to get 201k readers by 5 February. Consider sharing this post with your friends and get rewards.</p>","contentLength":26039,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/82fd5b97-da72-4489-b2e1-d50add2292cf_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"What a Supermarket Checkout Line Can Teach You About Message Queues","url":"https://newsletter.systemdesign.one/p/what-is-a-message-queue","date":1769862662,"author":"Neo Kim","guid":35,"unread":true,"content":"<ul><li><p><em>Block diagrams created using <a href=\"https://app.eraser.io/auth/sign-up?ref=neo\">Eraser</a>.</em></p></li></ul><blockquote><p>Picture your last grocery trip: you filled your cart &amp; headed to checkout.</p></blockquote><p>Then the big moment arrived—you had to choose a line…Maybe you compared the number of items in other carts. Or you might have observed how quickly each cashier worked. Either way, you were making queue choices.</p><p>These are the same choices found in software systems.</p><p>In today’s newsletter, I’ll teach you how message queues work by comparing them to waiting in grocery store queues. The read time is roughly the time most people spend in line.</p><p>By the end, you’ll understand:</p><ul><li><p>How queue behavior affects performance</p></li><li><p>How to apply these ideas to build better systems</p></li></ul><p> is the AI code review that surfaces real issues and meaningful feedback instead of flooding your PRs with stylistic nitpicks and low-value comments.</p><p>The checkout lines are simple:</p><p>Customers come with their carts and wait. Eventually, they form a line. The first person in the line gets served first. The last one needs to wait for everyone in front of them. This is called <a href=\"https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)\">FIFO</a> (First-In-First-Out) ordering.</p><p>It’s simple, fair, and predictable.</p><p>Software message queues work in the same way.</p><p>Requests arrive &amp; wait in order. Think of an app like Instagram. When many users upload photos simultaneously, the app can’t process them all at once. So each photo upload becomes a message that will be processed later.</p><blockquote><p>There’s a hidden insight here:<strong> queues exist to absorb bursts in demand.</strong></p></blockquote><p>Use a queue when you can’t handle every request right now but still need to handle them later.</p><p>Queue mechanics are simple…</p><ul><li><p>New messages get placed at the back of the queue - this is called .</p></li><li><p>Processed ones leave from the front of the queue - this is called .</p></li></ul><p>This pattern of filling and emptying the queue is what makes it fair and predictable. Just like the supermarket checkout line.</p><p>Use queues to absorb sudden traffic spikes and keep track of what to process later.</p><p>In a supermarket, cashiers are responsible for handling customers…</p><p>Each cashier scans items, processes payments, and completes transactions. They work alone but share the same goal: move customers through checkout.</p><p>In software systems, servers work the same way…</p><p>They pull messages from queues and process them in turn. A queue growing faster than it’s getting processed is a signal to scale servers.</p><p>You can scale in two ways:</p><ul><li><ul><li><p>This means , so the work gets spread across workers</p></li><li><p>It’s like adding a new cashier in a supermarket; customers notice a new line opened and spread out</p></li></ul></li><li><ul><li><p>This means <strong>making the existing servers more powerful</strong></p></li><li><p>It’s like training cashiers in a supermarket; trained cashiers scan the items or process payments faster and serve more customers faster</p></li></ul></li></ul><p>But there’s a catch: <em>servers must confirm they finished processing.</em></p><p>At the supermarket, this is like a cashier calling “Next!” when ready. This is called an acknowledgment in software systems. Without it, the system can’t tell if a message succeeded or failed, so it has to be redelivered.</p><p>Match your processing power to demand by scaling out or scaling up servers.</p><p>Longer lines mean longer waits…</p><p>Too many customers during rush hour makes waits much longer,,, and customers get frustrated. They might leave their carts or choose a different store next time.</p><p>Long queues also hurt performance in software systems:</p><p>Too many requests slow things down. Think of Twitter during big events when millions of tweets flood in. Servers can’t keep up, so users experience slow responses or errors. This is very bad for the business.</p><blockquote><p><em>So how do you make sure you see issues before they happen?</em></p><p>“One approach is to use throughput and latency metrics.”</p></blockquote><p>Throughput means how many customers get handled per hour. Latency means how long it takes to process one customer.</p><p><strong>A good system has high throughput &amp; low latency.</strong></p><p>Store managers watch checkout lines to decide whether to open more lines.</p><p>Likewise, the engineers monitor queue length, throughput, and latency to make scaling decisions. It’s required to understand acceptable limits and scale before the system crashes.</p><ul><li><p>: system can’t handle enough requests at once</p></li><li><p> there aren’t enough servers, or the work isn’t shared evenly</p></li><li><p> add more servers or spread the work</p></li></ul><ul><li><p> requests take too long to finish</p></li><li><p> when code is slow, databases are lagging, or the network is busy</p></li><li><p>make the code faster, use caching, or improve the slow parts</p></li></ul><p>If queues keep growing, it means demand exceeds capacity. Use throughput and latency metrics to identify what to improve.</p><p>Ready for the next technique?</p><p>Supermarket express lines exist to speed up checkout for customers with fewer items.</p><p>They provide a faster option for quick trips and help the store increase throughput.</p><p>This is similar to software using <a href=\"https://learn.microsoft.com/en-us/azure/architecture/patterns/priority-queue\">priority queues,</a> where important messages are moved to the front instead of waiting in line. A priority queue assigns each message a level of importance. The system always processes the highest-priority task first, even if others arrived earlier.</p><p>Priority queues help systems improve performance, but they have downsides:</p><ul><li><p>Lower-priority work can get stuck if urgent jobs never finish</p></li><li><p>Priority queues are hard to debug since there’s no FIFO ordering</p></li><li><p>Managing priorities adds complexity in implementation/maintenance</p></li></ul><p>It’s a classic <strong>tradeoff between simplicity &amp; responsiveness</strong>. It’s best to use priority queues only when speed really matters, and to keep most workflows predictable and fair.</p><p>Priority queues ensure time-sensitive messages aren’t delayed by less critical work.</p>","contentLength":5492,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/238c5926-10c8-491a-94e8-f35427d4a7c0_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"System Design Interview: Design YouTube","url":"https://newsletter.systemdesign.one/p/youtube-system-design","date":1769686253,"author":"Neo Kim","guid":34,"unread":true,"content":"<p>Building a video-sharing platform like YouTube is a ‘classic’ system design interview question.</p><p>YouTube processes over 500 hours of content that is uploaded every minute and serves billions of video streams daily.</p><p>Unlike static file-sharing services, YouTube transforms every upload into dozens of optimized formats, enabling smooth playback across devices from smartphones to 4K TVs, even on slow networks.</p><p>Here are some core challenges that make YouTube interesting from a system design perspective:</p><ul><li><p>Scale: Exabyte-level storage with millions of concurrent viewers</p></li><li><p>Global reach: Low latency for users worldwide</p></li><li><p>Adaptive delivery: Automatic quality adjustment for varying network conditions</p></li><li><p>Processing complexity: Each upload becomes 6+ resolutions × hundreds of segments</p></li><li><p>Read-heavy traffic: This demands aggressive caching</p></li></ul><p>Similar architectural patterns appear in platforms such as Netflix, Twitch, and TikTok, as well as in any platform that serves video at scale.</p><p>Let’s learn how to design YouTube during a system design interview:</p><p><a href=\"https://shorturl.at/YNu9c\">AI Engineer</a> is the #1 Fastest-Growing Job on LinkedIn, with salaries typically ranging from $180,000 to $350,000.</p><p>Co-designed with AI leaders from Microsoft (Eduardo Kassner, Chief Data &amp; AI Officer) and Google (Tomas Pfister, Head of AI Research @ Google Cloud)</p><p><strong>12 months | 100% online | No exams</strong></p><p>Built for working software engineers ready to land AI Engineer positions:</p><ul><li><p>Build a GitHub portfolio of 8 AI projects</p></li><li><p>Bring Your Own Projects or Ideas (BYOP)</p></li><li><p>Live weekly AI masterclasses</p></li></ul><p>Developers from Microsoft, Apple, AWS, and TJ Maxx have already joined the program.</p><p>By graduation, you’ll have the skills, confidence, and credentials to lead AI initiatives. To command top-tier salaries. To shape what comes next.</p><p><strong>Cohort starts February 2.</strong></p><ul><li><p>Candidate: What scale are we designing for? </p></li><li><p>Interviewer: 1 million uploads per day, 100 million DAU</p></li><li><p>Why it matters: Scale drives sharding, partitioning, and caching</p></li><li><p>Interview insight: You show you understand capacity planning</p></li></ul><ul><li><p>Candidate: What’s the read-to-write ratio?</p></li><li><p>Interviewer About 100 views for every 1 upload</p></li><li><p>Why this matters: It’s a read-heavy system, so the design favors streaming</p></li><li><p>Interview insight: You show awareness of workload patterns</p></li></ul><ul><li><p>Candidate: What’s the maximum video file size?</p></li><li><p>Why this matters: Forces you to use multipart uploads and chunking</p></li><li><p>Interview insight: You consider edge cases</p></li></ul><ul><li><p>Candidate: What video formats and resolutions do we support?</p></li><li><p>Interviewer MP4, AVI, MOV, and from 240p to 4K</p></li><li><p>Why this matters: Needs a strong transcoding pipeline with many output renditions</p></li><li><p>Interview insight: Shows attention to real-world constraints</p></li></ul><ul><li><p>Candidate: What’s the target latency for streaming?</p></li><li><p>Interviewer: First frame in under 500ms</p></li><li><p>Why this matters: Requires CDN and adaptive streaming</p></li><li><p>Interview insight: You focus on user experience</p></li></ul><ul><li><p>Candidate: What’s acceptable for upload processing time?</p></li><li><p>Interviewer: Around 10 to 30 minutes</p></li><li><p>Why this matters: Processing can be asynchronous</p></li><li><p>Interview insight: You understand eventual consistency</p></li></ul><ul><li><p>Candidate: Is eventual consistency fine for new uploads?</p></li><li><p>Interviewer: Yes, a short delay is acceptable</p></li><li><p>Why this matters: Availability over strict immediacy</p></li><li><p>Interview insight: You show CAP theorem reasoning</p></li></ul><ul><li><p>Candidate: What’s our uptime target?</p></li><li><p>Why this matters: Need redundancy and failover</p></li><li><p>Interview insight: You think about reliability</p></li></ul><ul><li><p>Candidate: Do we support livestreaming?</p></li><li><p>InterviewerFor this interview, focus on uploads</p></li><li><p>Why this matters:Keeps scope controlled</p></li><li><p>Interview insight:You avoid feature creep</p></li></ul><p>The design must address a massive scale and specific constraints:</p><ul><li><p>Users upload from web and mobile clients</p></li><li><p>System accepts files up to 256 GB</p></li><li><p>Resume interrupted uploads without data loss</p></li><li><p>Store raw media for the transcoding pipeline</p></li></ul><ul><li><p>Smooth playback across regions and devices</p></li><li><p>Quality adjusts automatically to network speed (adaptive bitrate)</p></li><li><p>First frame appears in under 500ms</p></li><li><p>Stability in different connection types</p></li></ul><ul><li><p>Discover content by querying titles and descriptions</p></li><li><p>Return results in manageable chunks (pagination)</p></li><li><p>Support high-cardinality searches (millions of videos)</p></li></ul><h3><strong>Non-Functional Requirements</strong></h3><ul><li><p>Service must remain available during failures</p></li><li><p>New uploads don’t need instant visibility (eventual consistency is okay)</p></li></ul><ul><li><p>Support 1 million uploads/day</p></li><li><p>Handle 100 million daily active users</p></li></ul><ul><li><p>Multipart upload with chunk-level retries</p></li><li><p>Resume capability for interrupted uploads</p></li><li><p>Efficient storage and processing of massive files</p></li><li><p>No progress loss on network failures</p></li></ul><ul><li><p>First frame must appear in under 500ms</p></li><li><p>Video playback must adapt to varying network speeds</p></li><li><p>Buffering should be minimal during normal network conditions</p></li></ul><ul><li><p>Automatic quality adjustment for slow networks</p></li><li><p>Smaller segment sizes for stable playback</p></li><li><p>Bandwidth optimization for developing regions</p></li></ul><p> REST (Representational State Transfer).</p><p> REST is the industry standard for public-facing web services, offering scalability and ease of integration for web and mobile clients.</p><p>Instead of uploading videos through your API servers, clients receive a temporary, signed S3 URL. This prevents your application servers from becoming the bottleneck. And users upload directly to blob storage.</p><p>The search and comments endpoints return results in chunks via cursor-based pagination. This prevents massive queries from locking down the database.</p><p>The client interacts with the system via a RESTful API.</p><blockquote><p>The design follows a strict philosophy: application servers handle lightweight metadata, while heavy video data is offloaded directly to cloud storage and CDNs.</p></blockquote><p> The server reserves a video ID and returns a pre-signed URL, a temporary link that allows the client to upload directly to S3 without touching the app server.</p><p>The application server is almost untouched… Bandwidth goes directly to blob storage.</p><p><code>GET /v1/videos/{video_id}</code></p><p>When a user requests to watch a video, this endpoint returns the video’s metadata and the manifest file URL. The client uses this to begin adaptive bitrate streaming (ABR) from the CDN.</p><p>Manifest file tells the client which video segments and resolutions are available. The CDN handles the actual streaming.</p><p><code>POST /v1/progress/{video_id}</code></p><p>This endpoint tracks the user’s playback position. It’s designed for massive scale (handling millions of writes/second) and prioritizes speed over immediate consistency.</p><p>This endpoint alone handles millions of writes/second. It can’t afford latency. So fire the request; don’t wait for confirmation. Then store in a high-throughput database like DynamoDB.</p><p> Queries the search index to find videos matching a user’s query. This endpoint relies heavily on pagination to return results in manageable chunks.</p><p>Cursor-based pagination prevents massive queries. Each page contains a  token, allowing the client to fetch the next batch without re-querying the entire dataset.</p><p>Cursor-based pagination is more scalable than offset-based pagination. It prevents the “skip 10 million rows” problem.</p>","contentLength":6869,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/9c1649ff-bf23-44fe-8ec8-c2801c668bd6_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"How ChatGPT's New Marketplace Actually Works","url":"https://newsletter.systemdesign.one/p/apps-in-chatgpt","date":1769596266,"author":"Neo Kim","guid":33,"unread":true,"content":"<p>You’ve probably asked ChatGPT to help you book a flight or find a restaurant at some point.</p><p>It gives you a helpful list: airline breakdowns, price ranges, maybe some tips on timing. Then, you leave ChatGPT, open a travel website, and start your search from scratch.</p><p>The conversation helped you think, but it didn’t actually  anything…</p><p>Now imagine you say, “Find me a flight to Tokyo under $500,” and an interactive widget appears inside the chat. You browse options, compare prices, select your seat, and book, all without leaving the conversation.</p><p>Instead of responding with text and sending you elsewhere, ChatGPT can now surface interactive widgets from third-party apps directly in your conversation. OpenAI opened the app store for submissions on 17 December 2025, and with 800 million weekly active users, this may be the next great distribution wave for developers.</p><blockquote><p>But how does it actually work?</p><p>How does a message like “find me a hotel” turn into an interactive booking widget?</p></blockquote><p>In this newsletter, I’ll break down the architecture behind ChatGPT Apps, walk through how tool calls and widgets work together, and cover everything you need to know to build your own.</p><p>We’ll follow one example throughout: <em>building a restaurant finder</em>.</p><p> is the first autonomous software development platform with infinite code context, enabling Fortune 500 companies to ship 5x faster.</p><p>Large enterprises are adopting Blitzy at the beginning of every sprint. While individual developer tools like co-pilots struggle with context and only autocomplete code, Blitzy is engineered specifically for enterprise-scale codebases: clearing years of tech debt and executing large-scale refactors or new feature additions in weeks, not quarters.</p><ul><li><p>- Ingest millions of lines of code, mapping every line-level dependency.</p></li><li><p>- 3,000+ cooperative agents autonomously plan, build, and validate production-ready code using spec and test-driven development at the speed of compute.</p></li><li><p> - Over 80% of the work delivered autonomously, 500% faster.</p></li></ul><p>The future of autonomous software development is here:</p><p>He’s the founder of , an enterprise prototyping and observability platform for ChatGPT Apps. He’s also a popular Maven instructor and former healthtech product manager.</p><h2><strong>How Is This Different From Plugins?</strong></h2><p>If you’ve been following OpenAI for a while, you might think, “Wait, didn’t they already try this with Plugins?”</p><p>ChatGPT Plugins (launched March 2023, deprecated April 2024) were essentially API wrappers. You’d describe your API endpoints, and ChatGPT would call them and return text. The problem was that everything came back as text that ChatGPT had to interpret and re-present to the user. There was no native UI, no interactivity, and no way to create rich experiences.</p><p>They allow users to upload content and shape their conversations, but are difficult to share broadly and don’t give brands control over how they’ll appear in chats.</p><p>ChatGPT Apps take a fundamentally different approach.</p><p>Instead of just calling APIs and returning text, Apps can render full interactive widgets directly in the conversation. You can show a map, display a booking form, or let users interact with a spreadsheet.</p><p>Here’s how the three approaches compare:</p><p>The key insight is that Apps aren’t just “GPTs with UI”; they’re a different architecture entirely.</p><p>The widget runs in a sandboxed iframe with its own state, its own event handling, and direct communication with your backend. ChatGPT orchestrates when to show your app, but once it’s rendered, users interact with your UI directly.</p><blockquote><p>Here’s the simplest way to think about it: a chatbot talks, but an app does.</p></blockquote><p>Ask ChatGPT to book a restaurant, and normally, it explains how. It lists options, gives links, and tells you what to search for. Helpful, but nothing actually changes in the world.</p><p>Now ask ChatGPT with a restaurant app installed, and something different happens.</p><p>An interactive widget appears right in the chat. You can see real availability, browse the menu, pick a time, and confirm your reservation. When you’re done, you have an actual booking, not just information about how to make one.</p><p>Here’s exactly what that would look like:</p><p>The launch partners tell you a lot about where OpenAI sees this going: Booking.com, Canva, Coursera, Expedia, Figma, Spotify, and Zillow.</p><blockquote><p>Users install apps through: <strong>Settings &gt; Apps &amp; Connectors</strong>.</p></blockquote><p>Once installed, ChatGPT can automatically surface your app based on conversation context, or users can tag it manually.</p><p>Before we get into the technical details, it’s worth thinking about what kinds of apps work well in this model.</p><p>ChatGPT apps should be quick and conversational. The goal is not to export your entire web app to ChatGPT. OpenAI says that apps should <a href=\"https://developers.openai.com/blog/what-makes-a-great-chatgpt-app\">show, do, or know</a> something that ChatGPT doesn’t. For example, ChatGPT can’t deliver groceries to your house, but the Instacart app with ChatGPT can.</p><p>Now let’s look at how this all works under the hood.</p><p>Every ChatGPT App is built from three parts that work together:</p><p>The first is the, which is your backend. It tells ChatGPT what your app can do by defining “tools” (functions the model can call) and “resources” (UI templates to render).</p><p>MCP stands for Model Context Protocol, an open standard that Anthropic created and OpenAI has now adopted.</p><p>The second component is the, which is your frontend. It’s HTML that runs on ChatGPT in a sandboxed iframe.</p><p>The third is , which acts as the host. It decides when to call your tools, renders your widgets, and manages the conversation state.</p><p>Let’s look at each component in detail:</p><p>The MCP Server is your backend—it’s where you define what your app can actually do.</p><blockquote><p>It exposes two main things to ChatGPT: tools and resources.</p></blockquote><p> are actions that ChatGPT can call.</p><p>Each tool has a name (like ), a description that helps ChatGPT decide when to use it, an input schema defining which parameters are required, and an output template specifying which UI resource to render the results in.</p><p> are UI templates that ChatGPT renders when tools return data.</p><p>They’re served as HTML bundles (typically React apps compiled to a single file) and rendered inside a sandboxed iframe.</p><p>Here’s what a tool definition might look like for our restaurant finder:</p><pre><code>Tool: search_restaurants\n\nDescription: “Find restaurants by location and cuisine type”\n\nInputs: location (required), cuisine (optional), price_range (optional)\n\nOutput: → ui://widget/restaurant-list.html</code></pre><p>The description is especially important.</p><p>ChatGPT uses it to decide whether your tool is relevant to the user’s request. If your description is vague—like “do restaurant stuff”—ChatGPT won’t know when to invoke it. Be specific about what the tool does and when it should be used.</p><p>Let’s trace what happens when you tell ChatGPT, “Find me Italian restaurants in Brooklyn”.</p><p>Understanding this flow is key to building apps that work well.</p><p>First, ChatGPT checks the available tools from all installed apps.</p><p>It sees your  tool with the description “Search for restaurants by location and cuisine type”. Based on the user’s message, it decides this tool is relevant.</p><p>Next, ChatGPT constructs a tool call:</p><pre><code>{\n\n  “name”: “search_restaurants”,\n\n  “parameters”: {\n\n    “location”: “Brooklyn”,\n    “cuisine”: “Italian”\n\n  }\n\n}</code></pre><p>Your MCP server receives this request, validates the parameters, queries your database (or an external API such as Yelp), and returns the results.</p><p>This includes a reference to your UI template if you have one.</p><pre><code>return {\n\n  content: [\n\n    { type: “text”, text: “Found 12 Italian restaurants in Brooklyn” }\n\n  ],\n\n  structuredContent: {\n\n    restaurants: results\n\n  },\n\n  _meta: {\n\n    “openai/outputTemplate”: “ui://widget/restaurant-list.html”\n\n  }\n\n};</code></pre><ul><li><p>The  field is for ChatGPT. It’s a text summary, so the model knows what happened and can respond intelligently.</p></li><li><p>The  field is for your widget, containing the raw data your UI will display.</p></li><li><p>And the  in  tells ChatGPT to fetch and render your widget HTML.</p></li></ul><p>Finally, ChatGPT fetches your HTML bundle, renders it in a sandboxed iframe, and injects your  via a JavaScript bridge. The user sees an interactive list of restaurants right in their chat.</p><p>The Widget is your frontend widget.</p><p>When your widget loads, ChatGPT injects an  object that gives you access to data and methods for interacting with the system.</p><p>Here’s what you can do with :</p><ul><li><p> — The data returned from your tool call</p></li><li><p> — The parameters that were passed to your tool</p></li><li><p> — Any persisted UI state</p></li><li><p> — Whether the user is in light or dark mode</p></li><li><p> — The user’s locale (e.g., “en-US”)</p></li></ul><ul><li><p> — Call another MCP tool directly</p></li><li><p> — Persist UI state</p></li><li><p> — Send a message back to ChatGPT</p></li><li><p> — Switch between inline, full screen, or picture-in-picture</p></li><li><p> — Open an external URL</p></li></ul><p>This is what makes Apps fundamentally different from Plugins.</p><p>Your widget can trigger new tool calls, save state, and continue the conversation. Users interact directly with your UI, not through ChatGPT’s text interface. When they click on a restaurant to see more details, you have two options for handling that interaction.</p><p>The first option is a .</p><p>Your widget can call tools directly using , which bypasses the model entirely. Your widget requests restaurant details, your server returns the data, and the widget updates immediately. This is fast and efficient for straightforward data fetching.</p><p>The second option is a .</p><p>Your widget can send a follow-up <code>window.openai.sendFollowUpMessage()</code>, which puts the model back in the loop. ChatGPT sees the message, decides what to do next, and might call additional tools or ask clarifying questions.</p><pre><code>// Direct tool call (model not involved)\n\nconst details = await window.openai.callTool(\n\n  ‘get_restaurant_details’,\n  { id: restaurant.id }\n\n);\n\n\n// Follow-up message (model decides next step)\n\nawait window.openai.sendFollowUpMessage({\n\n  prompt: `I want to book ${restaurant.name} for 4 people`\n\n});</code></pre><p>This creates a continuous loop that makes the whole experience feel seamless:</p><blockquote><p>The user speaks, ChatGPT calls a tool, the widget renders, the user interacts with the widget, the widget either calls another tool or sends a message, and the cycle continues.</p></blockquote><p>Widgets can appear in three different formats depending on what makes sense for your app.</p><p> widgets embed directly in the conversation flow. This is the default for all apps, and it works well for things like listings, search results, or quick selections.</p><p> mode takes over the entire viewport. This is better for maps, dashboards, or complex workflows where users need more space to work.</p><p> mode floats the widget while the user continues chatting. This is great for music players, timers, or other persistent tools that the user might want to keep visible while doing other things.</p><pre><code>window.openai.requestDisplayMode({ mode: “fullscreen” });\n\nwindow.openai.requestDisplayMode({ mode: “pip” });</code></pre><p>One constraint to keep in mind: <strong>you can only show one widget per message.</strong></p><p>If someone asks ChatGPT to “book a restaurant and order an Uber,” it will show one app at a time. Users work through these requests sequentially.</p><p>Now that we understand how the pieces fit together, let’s talk about security.</p><p>With four parties involved (ChatGPT, your MCP server, your widget, and external APIs), it’s important to understand where the trust boundaries lie.</p><p>ChatGPT calls your MCP server over HTTPS. Your server should validate that requests are actually coming from ChatGPT. ChatGPT trusts your server to return valid tool responses and UI resources.</p><p>The widget runs in a heavily sandboxed iframe. ChatGPT injects the  bridge, but the widget cannot access ChatGPT’s DOM, cookies, or any data from other apps. This is the strictest boundary.</p><p>Your widget can only make network requests to domains you’ve explicitly declared in your Content Security Policy () configuration. All other requests are blocked.</p><p>Each app’s widget runs in its own isolated sandbox. Apps cannot access each other’s data, state, or DOM. Even if a malicious app tried to extract data from another app, the browser’s same-origin policy prevents it.</p><p>Your widget runs under strict restrictions. It cannot:</p><ul><li><p>Access cookies (it’s on a sandbox origin, not your domain)</p></li><li><p>Use localStorage or sessionStorage</p></li><li><p>Access the parent DOM (ChatGPT’s interface)</p></li><li><p>Submit forms directly (use  instead)</p></li><li><p>Open popups (use  instead)</p></li><li><p>Make network requests except for declared CSP domains</p></li></ul><ul><li><p>Execute JavaScript normally</p></li><li><p>Fetch from CSP-allowed domains</p></li><li><p>Communicate through the  bridge</p></li><li><p>Store UI state via </p></li></ul><p>You declare your allowed connections in your tool’s :</p><pre><code>_meta: {\n\n  “openai/widgetCSP”: {\n\n    “connect_domains”: [”api.yourservice.com”],\n    “resource_domains”: [”cdn.yourservice.com”],\n    “frame_domains”: []  // Nested iframes trigger stricter review\n\n  }\n\n}</code></pre><blockquote><p>The key principle: external API calls should go through your MCP server, not the widget.</p></blockquote><p>Let your widget handle the UI and let your server handle the business logic and sensitive operations.</p>","contentLength":12984,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/dc428a48-c7bd-447c-a6e2-73f723671b11_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"The Entire Computer Science Stack, Explained In 51 Images","url":"https://newsletter.systemdesign.one/p/computer-science-101","date":1769250672,"author":"Neo Kim","guid":32,"unread":true,"content":"<p>Computer Science is frequently taught like a collection of disconnected facts, when it should be a stack of ideas, layered on top of each other.</p><p>We are going to fix it by taking a visual journey through the entire Computer science stack using simple diagrams that create mental models that hopefully stay with you throughout your career.</p><p><a href=\"https://getunblocked.com/code-review/?utm_source=systemdesign&amp;utm_medium=email&amp;utm_campaign=codereview&amp;utm_content=context\">Unblocked</a> is the only AI code review tool that has a deep understanding of your codebase, docs, and past decisions, giving you thoughtful feedback that feels like it came from your best engineer.</p><p>He’s a self-taught software engineer and an emergency physician. He is also the editor and primary author of the newsletters  and </p><p>They will help you learn and understand the fundamentals quickly and easily.</p><p>(You’ll also get a 20% discount when you use the code: NEO20.)</p><p>At the very bottom of every computer you operate is something surprisingly simple.</p><p>It’s a switch with two states: on and off.</p><p>In a computer, a <a href=\"https://en.wikipedia.org/wiki/Transistor\">Transistor</a> acts as a tiny electronic switch that can switch on and off billions of times per second, depending on whether current is flowing through it.</p><p>These two states represent binary information where the ‘on’ state represents a binary 1, while the ‘off’ state represents a binary 0.</p><p>Multiple transistors are put together to create  These are circuits that perform basic Boolean operations on binary inputs and produce a single binary output.</p><p>There are seven basic logic gates:</p><ul><li><p> Outputs 1 only when all inputs are 1</p></li><li><p> Outputs 1 if at least one input is 1</p></li><li><p>Inverts the input signal (outputs 1 for 0 and 0 for 1)</p></li><li><p> Outputs 0 only when all inputs are 1 (inverse of AND gate operation)</p></li><li><p>Outputs 1 only when all inputs are 0 (inverse of OR gate operation)</p></li><li><p><strong>XOR or Exclusive OR gate:</strong> Outputs 1 when inputs are different</p></li><li><p> Outputs 1 when inputs are the same</p></li></ul><p>A is used with these gates; it takes an input and outputs it unchanged. It is used for signal amplification or isolation.</p><p>Logic gates are further combined and integrated onto a single chip (Integrated Circuit, or IC) to perform more complex functions.</p><p>A  is one that can be used to construct any other logic gate.</p><p>Two logic gates belong to this category:</p><p>This means that any computer, regardless of how complex, can be built using only these gates.</p><p>A fun fact: The <a href=\"https://www.righto.com/2019/09/a-computer-built-from-nor-gates-inside.html\">Apollo Guidance Computer (AGC)</a>, used to navigate Apollo missions to the Moon, was built almost entirely from simple 3‑input NOR‑gate ICs.</p><h2><strong>2. The Central Processing Unit (CPU)</strong></h2><p>The Central Processing Unit (CPU) of a computer is built by combining logic-gate-implementing ICs.</p><ol><li><p><strong>Arithmetic Logic Unit (ALU),</strong> which performs mathematical operations (addition, subtraction, multiplication) and logical comparisons (equal to, greater than, less than).</p></li><li><p>which are small, ultra-fast memory components built directly into the CPU that hold data mid-calculation and track which instruction to execute next</p></li><li><p>, which acts as an orchestrator that fetches instructions from memory, decodes them, and coordinates data flow between the ALU, registers, and external memory.</p></li></ol><p>A CPU can execute billions of instructions per second using these components and acts as a computer’s brain.</p><p>Before we move on to the other layers on top of the physical one (hardware), we need to understand what computation means in theory.</p><p>In 1936, <a href=\"https://en.wikipedia.org/wiki/Alan_Turing\">Alan Turing</a> described a theoretical machine, called the Turing Machine, which consists of:</p><ul><li><p>an infinite tape divided into cells, each holding a symbol</p></li><li><p>a read/write head that moves along the tape, and</p></li><li><p>a set of rules that determines the machine’s behavior based on its current state and the symbol being read</p></li></ul><p>Although purely theoretical (since no physical tape is infinite), the concept of a Turing machine tells us that any complex problem can be solved through a sequence of logical operations.</p><p>Furthermore, the <a href=\"https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis\">Church-Turing thesis</a> states that any problem that can be computed can be computed by a Turing machine and, by extension, any general-purpose computer can solve it given enough time and memory.</p><p>Every modern computer is essentially a practical, finite version of the Turing Machine.</p><h2><strong>4. Programming Languages, Compilers &amp; Interpreters</strong></h2><p>Since working directly with binary information is tough, additional abstractions are built on top in the form of programming languages.</p><p>These languages are translated into binary machine instructions that a CPU can execute. This is done using programs called  and .</p><p>A Compiler translates the entire source code of a programming language into a binary executable that the CPU can run directly. Some examples of compiled languages are C, C++, Rust, and Go.</p><p>These produce fast executables because translation occurs once before runtime, but as a caveat, one must recompile their code for each platform (Windows, Mac, Linux) and recompile after every code change.</p><p>Interpreters work differently from this. They read source code, parse it, and execute instructions on the fly without producing a separate executable.</p><p>This allows immediate code execution, with the same code running everywhere. The trade-off is that they are typically slower than compiled code because translation happens during execution.</p><p>Some examples of interpreted languages are Python, JavaScript, and Ruby.</p><p>Data structures are ways of organizing data so that programs can use it efficiently.</p><p>Some of the most important data structures that you must know about are:</p>","contentLength":5313,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/fd7e7ce3-a5d2-4f59-8e90-81beb81dbf67_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"How Uber Payment System Handles 30 Million Transactions Per Day","url":"https://newsletter.systemdesign.one/p/payment-system-design","date":1768906964,"author":"Neo Kim","guid":31,"unread":true,"content":"<p>Here’s what you’ll get inside:</p><ul><li><p><strong>High-level architecture of real-world systems.</strong></p></li><li><p>Deep dive into how popular real-world systems actually work.</p></li><li><p><strong>How real-world systems handle scale, reliability, and performance.</strong></p></li></ul><p>And here’s the best part:</p><p>You’ll get 10x the results you currently get with 1/10 the time, energy &amp; effort.</p><p>We asked this question, then built the backend infrastructure to find out.</p><p>Most research tools are designed for a human to read the output. You ask a question; you get an essay. That works fine when someone is sitting at a screen. But if you’re building systems where another machine consumes the research (compliance pipelines, knowledge graphs, decision engines), your entire architecture and philosophy change.</p><p> is the control plane for building large-scale AI-Backends that make this possible.</p><p>Here’s the interesting part. You don’t just parallelize the work. The agents coordinate:</p><ol><li><p>They identify gaps in collective findings and spawn sub-questions to fill them</p></li><li><p>Parallel streams cross-reference each other to catch contradictions</p></li><li><p>Higher-order synthesis surfaces patterns across sources that no single document reveals</p></li></ol><p>The coordination problem alone is nontrivial.</p><p>Thousands of agents need to avoid duplicate work, share relevant context, and collectively converge on completeness. We borrowed patterns from distributed consensus and applied them to autonomous research workloads.</p><p>The largest deployment we’ve tested: <strong>100,000 agents running simultaneously.</strong> 🚀</p><p>It’s open source under Apache 2.0 and works with any LLM (Claude, Ollama, DeepSeek).</p><p>⭐ Star the repo if you’re building AI backends.</p><p>October 2014 - Prague, Czech Republic.</p><p>Maria has an important meeting in 15 minutes.</p><p>But she doesn’t have cash for a taxi.</p><p>So she opens the ride-sharing app called Uber &amp; requests a ride.</p><p>Although it’s stunning how easily Uber processes payments, handling payments at ‘scale’ is extremely HARD.</p><p>A user adds payment details on the mobile app.</p><p>Yet a mobile device could get stolen, or Uber servers could get breached…</p><p>So it’s highly risky to store sensitive information on mobile devices &amp; Uber servers.</p><p>A single payment has to be split across different trip participants:</p><ul></ul><p>i.e., money cannot simply move directly from rider to driver.</p><p>Payments include “external systems” such as banks, card networks, and payment providers.</p><p>But there’s a risk of network failures, timeouts, and partial outages.</p><p>And this could create a dreadful user experience.</p><p>Here’s how Uber payment architecture works:</p><h3>1. Add Payment Information</h3><p>A user adds payment details, such as credit card number &amp; CVV, to the mobile app.</p><p>Yet it’s RISKY for them to store this data because:</p><ul><li><p>It requires heavy legal compliance</p></li></ul><p>So they use payment provider SDK in the mobile app to collect sensitive details.</p><p>Software development kit () doesn’t send card information to Uber servers.</p><p>Instead, it “securely” collects credit card information and sends it directly to the payment provider, along with contextual metadata. Metadata includes Uber account details, payment method type (card or wallet), and so on.</p><p>Payment provider then returns a unique token,,, which acts as a ‘safe reference’ for the credit card. The token represents the card; think of it as a (reusable) permission to charge the card.</p><p>Plus, the payment provider binds the received metadata to the token to scope its usage and validation.</p><p>From this point on, mobile app uses the token instead of the credit card.</p><p>i.e., Uber or mobile device has NO sensitive data.</p><p>A stolen token is useless because it’s created by the payment provider, tied to Uber’s account and app, and restricted to specific uses (such as charges made only by Uber). So another mobile device or app cannot use it to charge the card.</p><p><em><strong>Reminder: this is a teaser of the subscriber-only newsletter series, exclusive to my golden members.</strong></em></p><p>When you upgrade, you’ll get:</p><ul><li><p><strong>High-level architecture of real-world systems.</strong></p></li><li><p>Deep dive into how popular real-world systems actually work.</p></li><li><p><strong>How real-world systems handle scale, reliability, and performance.</strong></p></li></ul>","contentLength":4051,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/4a390498-ec7b-4baa-b922-a6a91a038f7b_1280x720.png","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}